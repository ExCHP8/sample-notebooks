{"cells": [{"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n# Use watsonx, and `granite-20b-multilingual` to support multiple languages translation"}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "#### Disclaimers\n\n- Use only Projects and Spaces that are available in watsonx context.\n\n\n## Notebook content\n\nThis notebook contains the steps and code to demonstrate support for language translation in watsonx. It introduces commands for defining prompt and model testing.\n\nSome familiarity with Python is helpful. This notebook uses Python 3.10.\n\n#### About IBM `granite-20b-multilingual` model\n\nThe Granite 20 Billion Multilingual (granite-20b-multilingual) model has been trained using over 2.6 trillion tokens and further fine-tuned using a collection of instruction-tuning datasets. The model underwent extensive pre-training utilizing multilingual common crawl data, enabling it to effectively handle the following languages:\n- **English**, \n- **German**, \n- **Spanish**, \n- **French**,\n- **Portuguese**.\n\nThe table below lists the <a href=\"https://github.com/nlp-uoregon/mlmm-evaluation\" target=\"_blank\" rel=\"xMMLU\">xMMLU</a> and <a href=\"https://arxiv.org/pdf/2306.05685.pdf\" target=\"_blank\" rel=\"xMT-Bench\">xMT-Bench</a> benchmarks used to show the performance in 5 languages.\n\n| Benchmark | Average | English | German | Spanish | French | Portuguese |\n|:---------:|:-------:|:-------:|:------:|:-------:|:------:|:----------:|\n| xMMLU     | 38.41   | 40.58   | 37.91  | 38.04   | 37.58  | 37.95      |\n| xMT-Bench | 5.34    | 5.59    | 5.18   | 5.17    | 5.19   | 5.58       |\n\n\nFor additional information about the `granite-20b-multilingual` model, please refer to the provided <a href=\"https://dataplatform.cloud.ibm.com/wx/samples/models/ibm/granite-20b-multilingual?context=wx\" target=\"_blank\" rel=\"link\"> link.</a>\n\n## Learning goal\n\nThe goal of this notebook is to demonstrate how to translate multiple languages using IBM `granite-20b-multilingual` watsonx model based on query provided by the user.\n\n\n## Contents\n\nThis notebook contains the following parts:\n\n- [Setup](#setup)\n- [Foundation Models on watsonx](#models)\n- [Translate the text based on the query](#translate)\n- [Summary](#summary)"}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"setup\"></a>\n## Set up the environment\n\nBefore you use the sample code in this notebook, you must perform the following setup tasks:\n\n-  Create a <a href=\"https://cloud.ibm.com/catalog/services/watson-machine-learning\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/admin/create-services.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>).\n"}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "### Install dependecies"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "!pip install \"ibm-watsonx-ai>=0.2.2\" | tail -n 1", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Defining the WML credentials\nThis cell defines the WML credentials required to work with watsonx Foundation Model inferencing.\n\n**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">documentation</a>."}, {"metadata": {}, "cell_type": "code", "source": "import getpass\n\ncredentials = {\n    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n    \"apikey\": getpass.getpass(\"Please enter your WML api key (hit enter): \")\n}", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Defining the project id\nThe Foundation Model requires project id that provides the context for the call. We will obtain the id from the project in which this notebook runs. Otherwise, please provide the project id."}, {"metadata": {}, "cell_type": "code", "source": "import os\n\ntry:\n    project_id = os.environ[\"PROJECT_ID\"]\nexcept KeyError:\n    project_id = input(\"Please enter your project_id (hit enter): \")", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"models\"></a>\n## Foundation Models on `watsonx.ai`"}, {"metadata": {}, "cell_type": "markdown", "source": "#### List available models\n\nAll available models are listed within the <a href=\"https://ibm.github.io/watsonx-ai-python-sdk/fm_helpers.html#ibm_watsonx_ai.foundation_models.get_model_specs\" target=\"_blank\" rel=\"get_model_specs\">`get_model_specs`</a> function.\n\nAdditionally, models can be passed as `ModelTypes`. For further details, please consult the <a href=\"https://ibm.github.io/watsonx-ai-python-sdk/fm_model.html#ibm_watsonx_ai.foundation_models.utils.enums.ModelTypes\" target=\"_blank\" rel=\"noopener no referrer\">documentation</a>.\n"}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watsonx_ai.foundation_models import get_model_specs\n\n[model[\"model_id\"] for model in get_model_specs(credentials[\"url\"])[\"resources\"]]", "execution_count": 4, "outputs": [{"data": {"text/plain": "['bigcode/starcoder',\n 'bigscience/mt0-xxl',\n 'codellama/codellama-34b-instruct-hf',\n 'eleutherai/gpt-neox-20b',\n 'google/flan-t5-xl',\n 'google/flan-t5-xxl',\n 'google/flan-ul2',\n 'ibm-mistralai/mixtral-8x7b-instruct-v01-q',\n 'ibm/granite-13b-chat-v1',\n 'ibm/granite-13b-chat-v2',\n 'ibm/granite-13b-instruct-v1',\n 'ibm/granite-13b-instruct-v2',\n 'ibm/granite-20b-multilingual',\n 'ibm/mpt-7b-instruct2',\n 'meta-llama/llama-2-13b-chat',\n 'meta-llama/llama-2-70b-chat']"}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}]}, {"metadata": {}, "cell_type": "markdown", "source": "You need to specify `model_id` that will be used for inferencing:"}, {"metadata": {}, "cell_type": "code", "source": "model_id = \"ibm/granite-20b-multilingual\"", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Defining the model parameters\n\nYou might need to adjust model `parameters` for different models or tasks, to do so please refer to <a href=\"https://ibm.github.io/watsonx-ai-python-sdk/fm_model.html#metanames.GenTextParamsMetaNames\" target=\"_blank\" rel=\"noopener no referrer\">documentation</a>."}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\nfrom ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n\nparameters = {\n    GenParams.DECODING_METHOD: DecodingMethods.SAMPLE,\n    GenParams.MAX_NEW_TOKENS: 100,\n    GenParams.MIN_NEW_TOKENS: 1,\n    GenParams.TEMPERATURE: 0.5,\n    GenParams.TOP_K: 50,\n    GenParams.TOP_P: 1,\n    GenParams.STOP_SEQUENCES: [\"\\n\"]\n}", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "**Warning:** Delete `GenParams.STOP_SEQUENCES: [\"\\n\"]` parameter if you intend to utilize the model for multiple translations on one prompt."}, {"metadata": {}, "cell_type": "markdown", "source": "### Initialize the model\nInitialize the `Model` class with previous set params."}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watsonx_ai.foundation_models import ModelInference\n\nmodel = ModelInference(\n    model_id=model_id, \n    params=parameters, \n    credentials=credentials,\n    project_id=project_id)", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Model's details"}, {"metadata": {}, "cell_type": "code", "source": "model.get_details()", "execution_count": 8, "outputs": [{"data": {"text/plain": "{'model_id': 'ibm/granite-20b-multilingual',\n 'label': 'granite-20b-multilingual',\n 'provider': 'IBM',\n 'source': 'IBM',\n 'short_description': 'The Granite model series is a family of IBM-trained, dense decoder-only models, which are particularly well-suited for generative tasks.',\n 'long_description': 'Granite models are designed to be used for a wide range of generative and non-generative tasks with appropriate prompt engineering. They employ a GPT-style decoder-only architecture, with additional innovations from IBM Research and the open community.',\n 'tier': 'class_1',\n 'number_params': '20b',\n 'min_shot_size': 1,\n 'task_ids': ['question_answering',\n  'summarization',\n  'retrieval_augmented_generation',\n  'classification',\n  'generation',\n  'extraction'],\n 'tasks': [{'id': 'question_answering', 'ratings': {'quality': 3}},\n  {'id': 'summarization', 'ratings': {'quality': 4}},\n  {'id': 'retrieval_augmented_generation', 'ratings': {'quality': 3}},\n  {'id': 'classification', 'ratings': {'quality': 4}},\n  {'id': 'generation'},\n  {'id': 'extraction', 'ratings': {'quality': 4}}],\n 'model_limits': {'max_sequence_length': 8192},\n 'limits': {'lite': {'call_time': '5m0s', 'max_output_tokens': 4096},\n  'v2-professional': {'call_time': '5m0s', 'max_output_tokens': 4096},\n  'v2-standard': {'call_time': '5m0s', 'max_output_tokens': 4096}},\n 'lifecycle': [{'id': 'available', 'start_date': '2024-03-14'}]}"}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"translate\"></a>\n\n## Translate the text based on the query\n\n### English to Spanish translation:\n\nDefine query for the model with at least one example, specifically for English to Spanish translation.\n\n**Note:** Model works the best with at least one translation example."}, {"metadata": {}, "cell_type": "code", "source": "english_to_spanish_query = \"\"\"Translate the following text from English to Spanish:\n\nInput: So far, I have not been terribly encouraged by the stance adopted by the Commission.\nOutput: Hasta ahora no me ha animado mucho la postura adoptada por la Comisi\u00f3n.\n\nInput: I am very pleased to see that the joint resolution adopts the suggestion we made.\n\"\"\"", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "**Warning:** ensure that there is a line break (newline) at the conclusion of the prompt."}, {"metadata": {}, "cell_type": "markdown", "source": "### Generat the English to Spanish translation using IBM `granite-20b-multilingual` model."}, {"metadata": {}, "cell_type": "code", "source": "translation_result = model.generate_text(english_to_spanish_query)", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Translation result"}, {"metadata": {}, "cell_type": "code", "source": "print(translation_result)", "execution_count": 11, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Output: Estoy muy contento de ver que la resoluci\u00f3n conjunta adopta la sugerencia que hicimos.\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### English to French translation:\n\nDefine query for the model with at least one example, specifically for English to French translation.\n\n**Note:** Model works the best with at least one translation example."}, {"metadata": {}, "cell_type": "code", "source": "english_to_french_query = \"\"\"Translate the following text from English to French:\n\nInput: Finally, I welcome paragraph 16 which calls for a review of the way we deal with human rights issues in Parliament.\nOutput: Enfin, je me r\u00e9jouis du paragraphe 16 qui appelle \u00e0 une r\u00e9vision de la mani\u00e8re dont nous abordons les questions relatives aux droits de l'homme au sein du Parlement.\n\nInput: I remember very well that we discussed it in a session in Luxembourg.\nOutput: Je me souviens tr\u00e8s bien que nous en avions parl\u00e9 lors d'une s\u00e9ance \u00e0 Luxembourg.\n\nInput: If we do not greatly increase the use of intelligent technology, we will not achieve our targets.\n\"\"\"", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "**Warning:** ensure that there is a line break (newline) at the conclusion of the prompt."}, {"metadata": {}, "cell_type": "markdown", "source": "### Generat the English to French translation using IBM `granite-20b-multilingual` model."}, {"metadata": {}, "cell_type": "code", "source": "translation_result = model.generate_text(english_to_french_query)", "execution_count": 13, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Translation result"}, {"metadata": {}, "cell_type": "code", "source": "print(translation_result)", "execution_count": 14, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Output: Si nous ne faisons pas un usage beaucoup plus important de la technologie intelligente, nous ne parviendrons pas \u00e0 atteindre nos objectifs.\n"}]}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"summary\"></a>\n## Summary and next steps\n\n You successfully completed this notebook!.\n \n You learned how to translate multiple languages with IBM `granite-20b-multilingual` model on watsonx. \n \n Check out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "### Authors: \n\n **Mateusz Szewczyk**, Software Engineer at Watson Machine Learning."}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "Copyright \u00a9 2024 IBM. This notebook and its source code are released under the terms of the MIT License."}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}