{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# German credit risk prediciton with Scikit-learn for model monitoring"}, {"metadata": {}, "cell_type": "markdown", "source": "This notebook should be run in a Watson Studio project, using the latest Python runtime environment. It requires service credentials for the following Cloud services:\n  * Watson Machine Learning V4\n\nThe notebook will train, create and deploy a German Credit Risk model."}, {"metadata": {}, "cell_type": "markdown", "source": "### Learning goals\n\nIn this notebook, you will learn how to:\n\n-  Explore data\n-  Prepare data for training and evaluation\n-  Create a scikit-learn pipeline\n-  Train and evaluate a model\n-  Store a model in the Watson Machine Learning (WML) repository\n-  Deploy and score the model\n\n### Contents\n\n1. [Setup](#setup)\n1. [Explore Data](#explore)\n1. [Create a model](#create_model)\n1. [Publish the model](#publish_model)\n1. [Deploy and score](#deploy_model)\n1. [Clean up](#cleanup)\n1. [Summary](#summary)\n"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"setup\"></a>\n## 1. Set up the environment\n\nBefore you use the sample code in this notebook, you must perform the following setup tasks:\n\n-  Create a <a href=\"https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-service-instance.html\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)."}, {"metadata": {}, "cell_type": "markdown", "source": "### Connection to WML\n\nAuthenticate the Watson Machine Learning service on IBM Cloud. You need to provide platform `api_key` and instance `location`.\n\nYou can use [IBM Cloud CLI](https://cloud.ibm.com/docs/cli/index.html) to retrieve platform API Key and instance location.\n\nAPI Key can be generated in the following way:\n```\nibmcloud login\nibmcloud iam api-key-create API_KEY_NAME\n```\n\nIn result, get the value of `api_key` from the output.\n\n\nLocation of your WML instance can be retrieved in the following way:\n```\nibmcloud login --apikey API_KEY -a https://cloud.ibm.com\nibmcloud resource service-instance WML_INSTANCE_NAME\n```\n\nIn result, get the value of `location` from the output."}, {"metadata": {}, "cell_type": "markdown", "source": "**Tip**: Your `Cloud API key` can be generated by going to the [**Users** section of the Cloud console](https://cloud.ibm.com/iam#/users). From that page, click your name, scroll down to the **API Keys** section, and click **Create an IBM Cloud API key**. Give your key a name and click **Create**, then copy the created key and paste it below. You can also get a service specific url by going to the [**Endpoint URLs** section of the Watson Machine Learning docs](https://cloud.ibm.com/apidocs/machine-learning).  You can check your instance location in your  <a href=\"https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance details.\n\nYou can also get service specific apikey by going to the [**Service IDs** section of the Cloud Console](https://cloud.ibm.com/iam/serviceids).  From that page, click **Create**, then copy the created key and paste it below.\n\n**Action**: Enter your `api_key` and `location` in the following cell."}, {"metadata": {}, "cell_type": "code", "source": "api_key = 'PASTE YOUR PLATFORM API KEY HERE'\nlocation = 'PASTE YOUR INSTANCE LOCATION HERE'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "wml_credentials = {\n    \"apikey\": api_key,\n    \"url\": 'https://' + location + '.ml.cloud.ibm.com'\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Install and import the `ibm-watson-machine-learning` package\n**Note:** `ibm-watson-machine-learning` documentation can be found <a href=\"http://ibm-wml-api-pyclient.mybluemix.net/\" target=\"_blank\" rel=\"noopener no referrer\">here</a>."}, {"metadata": {"tags": []}, "cell_type": "code", "source": "!pip install -U ibm-watson-machine-learning", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning import APIClient\n\nclient = APIClient(wml_credentials)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Working with spaces\n\nFirst of all, you need to create a space that will be used for your work. If you do not have space already created, you can use [Deployment Spaces Dashboard](https://dataplatform.cloud.ibm.com/ml-runtime/spaces) to create one.\n\n- Click New Deployment Space\n- Create an empty space\n- Select Cloud Object Storage\n- Select Watson Machine Learning instance and press Create\n- Copy `space_id` and paste it below\n\n**Tip**: You can also use SDK to prepare the space for your work. More information can be found [here](https://github.com/IBM/watson-machine-learning-samples/blob/master/cloud/notebooks/python_sdk/instance-management/Space%20management.ipynb).\n\n**Action**: Assign space ID below"}, {"metadata": {}, "cell_type": "code", "source": "space_id = 'PASTE YOUR SPACE ID HERE'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "You can use `list` method to print all existing spaces."}, {"metadata": {}, "cell_type": "code", "source": "client.spaces.list(limit=10)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "To be able to interact with all resources available in Watson Machine Learning, you need to set **space** which you will be using."}, {"metadata": {}, "cell_type": "code", "source": "client.set.default_space(space_id)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "In next cells, you will need to paste some credentials to Cloud Object Storage. If you haven't worked with COS yet please visit [getting started with COS tutorial](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-getting-started). \nYou can find `COS_API_KEY_ID` and `COS_RESOURCE_CRN` variables in **_Service Credentials_** in menu of your COS instance. Used COS Service Credentials must be created with _Role_ parameter set as Writer. Later training data file will be loaded to the bucket of your instance and used as training refecence in subsription.  \n`COS_ENDPOINT` variable can be found in **_Endpoint_** field of the menu."}, {"metadata": {}, "cell_type": "code", "source": "COS_API_KEY_ID = \"***\"\nCOS_RESOURCE_CRN = \"***\" \nCOS_ENDPOINT = \"***\"\nIAM_AUTH_ENDPOINT = \"***\"\nBUCKET_NAME = \"***\" ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Run the notebook\n\nAt this point, the notebook is ready to run. You can either run the cells one at a time, or click the **Kernel** option above and select **Restart and Run All** to run all the cells."}, {"metadata": {}, "cell_type": "markdown", "source": "In this section you will learn how to train Scikit-learn model and next deploy it as web-service using Watson Machine Learning service."}, {"metadata": {}, "cell_type": "markdown", "source": "## Load the training data from github"}, {"metadata": {"scrolled": true, "tags": []}, "cell_type": "code", "source": "!rm german_credit_data_biased_training.csv\n!wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/german_credit_data_biased_training.csv", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "import numpy as np\nimport pandas as pd\n\ntraining_data_file_name = \"german_credit_data_biased_training.csv\"\ndata_df = pd.read_csv(training_data_file_name)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Explore data <a name=\"explore\"></a>"}, {"metadata": {}, "cell_type": "code", "source": "data_df.head()", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true, "tags": []}, "cell_type": "code", "source": "print('Columns: ', list(data_df.columns))\nprint('Number of columns: ', len(data_df.columns))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "As you can see, the data contains twenty one fields. `Risk` field is the one you would like to predict using feedback data."}, {"metadata": {"scrolled": true, "tags": []}, "cell_type": "code", "source": "print('Number of records: ', data_df.Risk.count())", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "target_count = data_df.groupby('Risk')['Risk'].count()\ntarget_count", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Visualize data"}, {"metadata": {}, "cell_type": "code", "source": "target_count.plot.pie(figsize=(8, 8));", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Save training data to Cloud Object Storage"}, {"metadata": {}, "cell_type": "code", "source": "import ibm_boto3\nfrom ibm_botocore.client import Config, ClientError\n\ncos_client = ibm_boto3.resource(\"s3\",\n    ibm_api_key_id=COS_API_KEY_ID,\n    ibm_service_instance_id=COS_RESOURCE_CRN,\n    ibm_auth_endpoint=IAM_AUTH_ENDPOINT,\n    config=Config(signature_version=\"oauth\"),\n    endpoint_url=COS_ENDPOINT\n)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "with open(training_data_file_name, \"rb\") as file_data:\n    cos_client.Object(BUCKET_NAME, training_data_file_name).upload_fileobj(\n        Fileobj=file_data\n    )", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Create a model <a name=\"create_model\"></a>\nIn this section you will learn how to:\n\n- Prepare data for training a model\n- Create machine learning pipeline\n- Train a model"}, {"metadata": {}, "cell_type": "code", "source": "MODEL_NAME = \"Scikit German Risk Model WML V4\"\n\nDEPLOYMENT_NAME = \"Scikit German Risk Deployment WML V4\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### You will start with importing required libraries"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "from sklearn.linear_model import SGDClassifier\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Splitting the data into train and test"}, {"metadata": {}, "cell_type": "code", "source": "train_data, test_data = train_test_split(data_df, test_size=0.2)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Preparing the pipeline"}, {"metadata": {}, "cell_type": "code", "source": "features_idx = np.s_[0:-1]\nall_records_idx = np.s_[:]\nfirst_record_idx = np.s_[0]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "In this step you will encode target column labels into numeric values. You can use `inverse_transform` to decode numeric predictions into labels."}, {"metadata": {}, "cell_type": "code", "source": "string_fields = [type(fld) is str for fld in train_data.iloc[first_record_idx, features_idx]]\nct = ColumnTransformer([(\"ohe\", OneHotEncoder(), list(np.array(train_data.columns)[features_idx][string_fields]))])\nclf_linear = SGDClassifier(loss='log', penalty='l2', max_iter=1000, tol=1e-5)\n\npipeline_linear = Pipeline([('ct', ct), ('clf_linear', clf_linear)])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Train a model"}, {"metadata": {}, "cell_type": "code", "source": "risk_model = pipeline_linear.fit(train_data.drop('Risk', axis=1), train_data.Risk)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Evaluate the model"}, {"metadata": {"tags": []}, "cell_type": "code", "source": "from sklearn.metrics import roc_auc_score\n\npredictions = risk_model.predict(test_data.drop('Risk', axis=1))\nindexed_preds = [0 if prediction=='No Risk' else 1 for prediction in predictions]\n\nreal_observations = test_data.Risk.replace('Risk', 1)\nreal_observations = real_observations.replace('No Risk', 0).values\n\nauc = roc_auc_score(real_observations, indexed_preds)\nprint(auc)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Publish the model <a name=\"publish_model\"></a>"}, {"metadata": {}, "cell_type": "markdown", "source": "In this section, the notebook uses the supplied Watson Machine Learning credentials to save the model (including the pipeline) to the WML instance. Previous versions of the model are removed so that the notebook can be run again, resetting all data for another demo."}, {"metadata": {}, "cell_type": "code", "source": "import json", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true, "tags": []}, "cell_type": "code", "source": "software_spec_uid = client.software_specifications.get_id_by_name(\"runtime-22.2-py3.10\")\nprint(\"Software Specification ID: {}\".format(software_spec_uid))\nmodel_props = {\n    client.repository.ModelMetaNames.NAME: \"{}\".format(MODEL_NAME),\n    client.repository.ModelMetaNames.TYPE: 'scikit-learn_1.0',\n    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid\n}", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true, "tags": []}, "cell_type": "code", "source": "print(\"Storing model ...\")\n\npublished_model_details = client.repository.store_model(model=risk_model, meta_props=model_props, training_data=data_df.drop([\"Risk\"], axis=1), training_target=data_df.Risk)\nmodel_uid = client.repository.get_model_id(published_model_details)\nprint(\"Done\")\nprint(\"Model ID: {}\".format(model_uid))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Deploy and score <a name=\"deploy_model\"></a>"}, {"metadata": {}, "cell_type": "markdown", "source": "The next section of the notebook deploys the model as a RESTful web service in Watson Machine Learning. The deployed model will have a scoring URL you can use to send data to the model for predictions."}, {"metadata": {"scrolled": true, "tags": []}, "cell_type": "code", "source": "print(\"Deploying model...\")\nmetadata = {\n    client.deployments.ConfigurationMetaNames.NAME: DEPLOYMENT_NAME,\n    client.deployments.ConfigurationMetaNames.ONLINE: {}\n}\ndeployment = client.deployments.create(model_uid, meta_props=metadata)\ndeployment_uid = client.deployments.get_uid(deployment)\n    \nprint(\"Model id: {}\".format(model_uid))\nprint(\"Deployment id: {}\".format(deployment_uid))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Score the model"}, {"metadata": {}, "cell_type": "code", "source": "fields = [\"CheckingStatus\", \"LoanDuration\", \"CreditHistory\", \"LoanPurpose\", \"LoanAmount\", \"ExistingSavings\",\n                  \"EmploymentDuration\", \"InstallmentPercent\", \"Sex\", \"OthersOnLoan\", \"CurrentResidenceDuration\",\n                  \"OwnsProperty\", \"Age\", \"InstallmentPlans\", \"Housing\", \"ExistingCreditsCount\", \"Job\", \"Dependents\",\n                  \"Telephone\", \"ForeignWorker\"]\nvalues = [\n            [\"no_checking\", 13, \"credits_paid_to_date\", \"car_new\", 1343, \"100_to_500\", \"1_to_4\", 2, \"female\", \"none\", 3,\n             \"savings_insurance\", 46, \"none\", \"own\", 2, \"skilled\", 1, \"none\", \"yes\"],\n            [\"no_checking\", 24, \"prior_payments_delayed\", \"furniture\", 4567, \"500_to_1000\", \"1_to_4\", 4, \"male\", \"none\",\n             4, \"savings_insurance\", 36, \"none\", \"free\", 2, \"management_self-employed\", 1, \"none\", \"yes\"],\n        ]\n\nscoring_payload = {\"input_data\": [{\"fields\": fields, \"values\": values}]}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "predictions = client.deployments.score(deployment_uid, scoring_payload)\npredictions", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"cleanup\"></a>\n##  Clean up "}, {"metadata": {}, "cell_type": "markdown", "source": "If you want to clean up all created assets:\n- experiments\n- trainings\n- pipelines\n- model definitions\n- models\n- functions\n- deployments\n\nplease follow up this sample [notebook](https://github.com/IBM/watson-machine-learning-samples/blob/master/cloud/notebooks/python_sdk/instance-management/Machine%20Learning%20artifacts%20management.ipynb)."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"summary\"></a>\n##  Summary and next steps     "}, {"metadata": {}, "cell_type": "markdown", "source": "You successfully completed this notebook! \n \nYou have finished the hands-on lab for IBM Watson Machine Learning. You created, published and deployed Scikit-Learn german credit risk model. \n\nCheck out our <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-service-instance.html\" target=\"_blank\" rel=\"noopener noreferrer\">Online Documentation</a> for more samples, tutorials, documentation, how-tos, and blog posts. \n\nYou can now run the model monitoring [notebook](Monitor%20credit%20risk%20model%20with%20Watson%20Openscale.ipynb). You need to pass deployed model id in mentioned notebook"}, {"metadata": {}, "cell_type": "markdown", "source": "## Authors\n\nLukasz Cmielowski, PhD, is an Automation Architect and Data Scientist at IBM with a track record of developing enterprise-level applications that substantially increases clients' ability to turn data into actionable knowledge.\n\nSzymon Kucharczyk, Software Engineer at IBM Watson Machine Learning."}, {"metadata": {}, "cell_type": "markdown", "source": "Copyright \u00a9 2020 IBM. This notebook and its source code are released under the terms of the MIT License."}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}