{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
    "# Use watsonx, and `google/flan-ul2` to extract the named entities of  climate fever document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook contains the steps and code to demonstrate support of named entity extraction in watsonx. It introduces commands for data retrieval and model testing.\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.10.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The objective is to explore and utilize the Google Flan-UL2 model for entity extraction.Google Flan-UL2 is a pre-trained language model which can be used for token-level entity extraction tasks. Entity extraction, also known as Named Entity Recognition (NER), involves identifying and classifying named entities (such as persons, organizations, locations, dates, etc.) from unstructured text.\n",
    "\n",
    "Here are the steps we took in this notebook for Named Entity Extractions:\n",
    "- Data Collection and Preprocessing:\n",
    "Collect or obtain a dataset containing text documents \n",
    "- Instructions:\n",
    "Define the task and the prompt: Determine the specific entity extraction task we want the model to perform. Design an appropriate prompt that includes relevant instructions for the model, such as input format and expected output format.\n",
    "- Training Examples:\n",
    "provide training examples in the form of input-output pairs. Each input example consists of a prompt and corresponding tokenized text, while the output is the target entity labels associated with the tokens in the text.\n",
    "- Evaluation:\n",
    "Compare the predicted entity labels with the  pseudo ground truth labels in the test set. Calculate evaluation metrics, such as precision, recall, and F1-score, to assess the performance of the model for entity extraction.(**we do not have ground truth entity extraction data for this dataset, we use an open source package to create a pseudo-ground truth that can be used for demonstration purposes.**)\n",
    "\n",
    "\n",
    "## Learning goal\n",
    "\n",
    "The goal of this notebook is to demonstrate how to use `google/flan-ul2` model to extract named entities for climate change claims.\n",
    "\n",
    "## Use case & dataset\n",
    "A dataset adopting the FEVER methodology that consists of 1535 real-world claims regarding climate-change collected on the internet. Each claim is accompanied by five manually annotated evidence sentences retrieved from the English Wikipedia that support, refute or do not give enough information to validate the claim totalling in 7675 claim-evidence pairs. The dataset features challenging claims that relate multiple facets and disputed cases of claims where both supporting and refuting evidence are present.Named entities are  extracted form the claims using the google/flan-ul2 model. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [Data loading](#data)\n",
    "- [Foundation Models on watsonx](#models)\n",
    "- [Model testing](#predict)\n",
    "- [Score](#score)\n",
    "- [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"setup\"></a>\n",
    "##  Set up the environment\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "-  Create a <a href=\"https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-service-instance.html?context=analytics\" target=\"_blank\" rel=\"noopener no referrer\">here</a>).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install and import the `datasets` and dependecies\n",
    "you need to install below required dependencies to be able to continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets | tail -n 1\n",
    "!pip install requests | tail -n 1\n",
    "!pip install  wget | tail -n 1\n",
    "!pip install ibm-cloud-sdk-core | tail -n 1\n",
    "!pip install scikit-learn\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm | tail -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass, wget\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import requests\n",
    "import spacy\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pandas import value_counts\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from datasets import load_dataset\n",
    "from ibm_cloud_sdk_core import IAMTokenManager\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator, BearerTokenAuthenticator\n",
    "from pandas import value_counts, read_csv, DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import read_json\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferencing class\n",
    "This cell defines a class that makes a REST API call to the watsonx Foundation Model\n",
    "inferencing API that we will use to generate output from the provided input.\n",
    "The class takes the access token created in the previous step, and uses it to\n",
    "make a REST API call with input, model id and model parameters. The response\n",
    "from the API call is returned as the cell output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action:** Provide Watson Machine Learning url to work with wastonx.ai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your WML endpoint url (hit enter): ········\n"
     ]
    }
   ],
   "source": [
    "endpoint_url = getpass.getpass(\"Please enter your WML endpoint url (hit enter): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a `Prompt` class for prompts generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prompt:\n",
    "    def __init__(self, access_token, project_id):\n",
    "        self.access_token = access_token\n",
    "        self.project_id = project_id\n",
    "\n",
    "    def generate(self, input, model_id, parameters):\n",
    "        wml_url = f\"{endpoint_url}/ml/v1-beta/generation/text?version=2023-05-28\"\n",
    "        Headers = {\n",
    "            \"Authorization\": \"Bearer \" + self.access_token,\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Accept\": \"application/json\"\n",
    "        }\n",
    "        data = {\n",
    "            \"model_id\": model_id,\n",
    "            \"input\": input,\n",
    "            \"parameters\": parameters,\n",
    "            \"project_id\": self.project_id\n",
    "        }\n",
    "        response = requests.post(wml_url, json=data, headers=Headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()[\"results\"][0]\n",
    "        else:\n",
    "            return response.text\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### watsonx API connection\n",
    "This cell defines the credentials required to work with watsonx API for Foundation\n",
    "Model inferencing.\n",
    "\n",
    "**Action:** Provide the IBM Cloud personal API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">documentation</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your WML api key (hit enter): ········\n"
     ]
    }
   ],
   "source": [
    "access_token = IAMTokenManager(\n",
    "    apikey = getpass.getpass(\"Please enter your WML api key (hit enter): \"),\n",
    "    url = \"https://iam.cloud.ibm.com/identity/token\"\n",
    ").get_token()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the project id\n",
    "The API requires project id that provides the context for the call. We will obtain\n",
    "the id from the project in which this notebook runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your project_id (hit enter): ········\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    project_id = os.environ[\"PROJECT_ID\"]\n",
    "except KeyError:\n",
    "    project_id = getpass.getpass(\"Please enter your project_id (hit enter): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data\"></a>\n",
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the `climate` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data_clm_fever.csv'\n",
    "url = 'https://raw.githubusercontent.com/kmokht1/Datasets/main/data_clm_fever.csv'\n",
    "if not os.path.isfile(filename): wget.download(url, out=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global warming is driving polar bears toward e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The sun has gone into ‘lockdown’ which could c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The polar bear population has been growing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ironic' study finds more CO2 has slightly cool...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Human additions of CO2 are in the margin of er...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim\n",
       "0  Global warming is driving polar bears toward e...\n",
       "1  The sun has gone into ‘lockdown’ which could c...\n",
       "2        The polar bear population has been growing.\n",
       "3  Ironic' study finds more CO2 has slightly cool...\n",
       "4  Human additions of CO2 are in the margin of er..."
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= read_csv(\"data_clm_fever.csv\", index_col=[0])\n",
    "#data=data[['narrative','product']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, _,_ = train_test_split(data['claim'], \n",
    "                                                    data['claim'],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=33,\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect data sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517     Most likely the primary control knob on climat...\n",
      "863     While there has been a mean rise of a little m...\n",
      "437     \"The IPCC’s Fourth Assessment Report, 2007, ca...\n",
      "228     The bushfires in Australia were caused by arso...\n",
      "1052    “Several of the papers note that the primary i...\n",
      "539     the mild warming of around 0.8 degrees Celsius...\n",
      "560     This means that the world is now 1C warmer tha...\n",
      "246     Our evolving dynamic planet has survived sea l...\n",
      "1045    Temperatures cooled from about 1940 to 1975, a...\n",
      "203     Klaus-Martin Schulte examined all papers publi...\n",
      "Name: claim, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_sample=data_train.reset_index(inplace=False, drop=True)[random.sample(range(0, len(data_train)), 10)]\n",
    "print(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"models\"></a>\n",
    "## Foundation Models on watsonx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bigscience/mt0-xxl', 'eleutherai/gpt-neox-20b', 'google/flan-t5-xxl', 'google/flan-ul2', 'ibm/mpt-7b-instruct2']\n"
     ]
    }
   ],
   "source": [
    "models_json = requests.get(endpoint_url + '/ml/v1-beta/foundation_model_specs?version=2022-08-01&limit=50',\n",
    "                           headers={\n",
    "                                    'Authorization': f'Bearer {access_token}',\n",
    "                                    'Content-Type': 'application/json',\n",
    "                                    'Accept': 'application/json'\n",
    "                            }).json()\n",
    "models_ids = [m['model_id'] for m in models_json['resources']]\n",
    "print(models_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to specify `model_id` that will be used for inferencing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google/flan-ul2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"predict\"></a>\n",
    "##  Analyze named entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define instructions for the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare model inputs\n",
    "\n",
    "for zero-shot example, use below zero_shot_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence example 1 is:\n",
      " Most likely the primary control knob [on climate change] is the ocean waters and this environment that we live in.\n",
      "\n",
      "The sentence example 2 is:\n",
      " The Rio Grande is a classic “feast or famine” river, with a dry year or two typically followed by a couple of wet years that allow for recovery.\n",
      "\n",
      "The sentence example 3 is:\n",
      " Days of near-100-degree-Fahrenheit temperatures cooked the Mountain West in early July, and a scorching heat wave lingered over the Pacific Northwest in early August.”\n",
      "\n",
      "The sentence example 4 is:\n",
      " In our lifetime, there has been no correlation between carbon dioxide emissions and temperature\n",
      "\n",
      "The sentence example 5 is:\n",
      " There is no way for us to prevent the world’s CO2 emissions    from doubling by 2100\"\n",
      "\n",
      "The sentence example 6 is:\n",
      " Wu et al (2010) use a new method to calculate ice sheet mass balance.\n",
      "\n",
      "The sentence example 7 is:\n",
      " In the last 35 years of global warming, sun and climate have been going in opposite directions.\n",
      "\n",
      "The sentence example 8 is:\n",
      " Australia has more solar coverage than any other continent.\n",
      "\n",
      "The sentence example 9 is:\n",
      " Polar bears are in danger of extinction as well as many other species.\n",
      "\n",
      "The sentence example 10 is:\n",
      " The United States has been restricting soot emissions  in Draconian fashion since the Clean Air Act of 1963.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zero_shot_inputs = [{\"input\": text} for text in data_test]\n",
    "for i in range(10):\n",
    "    print(f\"The sentence example {i+1} is:\\n {zero_shot_inputs[i]['input']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare model inputs\n",
    "\n",
    "for few-shot examples, use below few_shot_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence example 1 is:\n",
      " Most likely the primary control knob [on climate change] is the ocean waters and this environment that we live in.\n",
      "\n",
      "The sentence example 2 is:\n",
      " The Rio Grande is a classic “feast or famine” river, with a dry year or two typically followed by a couple of wet years that allow for recovery.\n",
      "\n",
      "The sentence example 3 is:\n",
      " Days of near-100-degree-Fahrenheit temperatures cooked the Mountain West in early July, and a scorching heat wave lingered over the Pacific Northwest in early August.”\n",
      "\n",
      "The sentence example 4 is:\n",
      " In our lifetime, there has been no correlation between carbon dioxide emissions and temperature\n",
      "\n",
      "The sentence example 5 is:\n",
      " There is no way for us to prevent the world’s CO2 emissions    from doubling by 2100\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "few_shot_inputs_ = [{\"input\": text} for text in data_test.values]\n",
    "for i in range(5):\n",
    "    print(f\"The sentence example {i+1} is:\\n {few_shot_inputs_[i]['input']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the dictionaries of the inputs: for demonstration purposes, we provide the examples using an open source entity extraction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each document in the dataset\n",
    "example_dic ={}\n",
    "example_dic_list=[]\n",
    "\n",
    "for document in data_sample:\n",
    "    \n",
    "    doc = nlp(document.strip())  # Process the document with spacy NLP pipeline\n",
    "    if (len(doc.ents) != 0):\n",
    "        example_dic ={}\n",
    "        example_dic['document']=document\n",
    "        for i, ent in enumerate(doc.ents):\n",
    "            example_dic[f'phrase_{i}']=ent.text\n",
    "            example_dic[f'label_{i}']=ent.label_\n",
    "            \n",
    "        example_dic_list.append(example_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"document\": \"While there has been a mean rise of a little more than 3mm per year worldwide since the 1990s, in the last decade, the NOAA Virginia Key tide gauge just south of Miami Beach has measured a 9mm rise annually.\\u201d\",\n",
      "        \"phrase_0\": \"a little more than 3mm per year\",\n",
      "        \"label_0\": \"DATE\",\n",
      "        \"phrase_1\": \"the 1990s\",\n",
      "        \"label_1\": \"DATE\",\n",
      "        \"phrase_2\": \"the last decade\",\n",
      "        \"label_2\": \"DATE\",\n",
      "        \"phrase_3\": \"the NOAA Virginia Key\",\n",
      "        \"label_3\": \"ORG\",\n",
      "        \"phrase_4\": \"Miami Beach\",\n",
      "        \"label_4\": \"GPE\",\n",
      "        \"phrase_5\": \"9mm\",\n",
      "        \"label_5\": \"QUANTITY\",\n",
      "        \"phrase_6\": \"annually\",\n",
      "        \"label_6\": \"DATE\"\n",
      "    },\n",
      "    {\n",
      "        \"document\": \"\\\"The IPCC\\u2019s Fourth Assessment Report, 2007, carries in three places a graph in which the Hadley Center\\u2019s global mean surface temperature anomaly dataset from 1850-2005 is displayed with four arbitrarily-chosen trend-lines overlaid upon it.\",\n",
      "        \"phrase_0\": \"2007\",\n",
      "        \"label_0\": \"DATE\",\n",
      "        \"phrase_1\": \"three\",\n",
      "        \"label_1\": \"CARDINAL\",\n",
      "        \"phrase_2\": \"the Hadley Center\\u2019s\",\n",
      "        \"label_2\": \"ORG\",\n",
      "        \"phrase_3\": \"anomaly\",\n",
      "        \"label_3\": \"GPE\",\n",
      "        \"phrase_4\": \"1850-2005\",\n",
      "        \"label_4\": \"DATE\",\n",
      "        \"phrase_5\": \"four\",\n",
      "        \"label_5\": \"CARDINAL\"\n",
      "    },\n",
      "    {\n",
      "        \"document\": \"The bushfires in Australia were caused by arsonists and a series of lightning strikes, not 'climate change'.\",\n",
      "        \"phrase_0\": \"Australia\",\n",
      "        \"label_0\": \"GPE\"\n",
      "    },\n",
      "    {\n",
      "        \"document\": \"the mild warming of around 0.8 degrees Celsius that the planet has experienced since the middle of the 19th century\",\n",
      "        \"phrase_0\": \"0.8 degrees\",\n",
      "        \"label_0\": \"QUANTITY\",\n",
      "        \"phrase_1\": \"the middle of the 19th century\",\n",
      "        \"label_1\": \"DATE\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "json_formatted_str = json.dumps(example_dic_list[:4], indent=4)\n",
    "print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating text format from the above dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples=[]\n",
    "for i in range(len(example_dic_list)):\n",
    "    examples.append('document: \\n'+example_dic_list[i]['document']+'\\n')\n",
    "    di=copy.deepcopy(example_dic_list[i])\n",
    "    del di['document']\n",
    "    examples.append('\\n')\n",
    "    examples.append(str(di))\n",
    "    examples.append('\\n\\n\\n')\n",
    "examples_input=''.join(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: \n",
      "While there has been a mean rise of a little more than 3mm per year worldwide since the 1990s, in the last decade, the NOAA Virginia Key tide gauge just south of Miami Beach has measured a 9mm rise annually.”\n",
      "\n",
      "{'phrase_0': 'a little more than 3mm per year', 'label_0': 'DATE', 'phrase_1': 'the 1990s', 'label_1': 'DATE', 'phrase_2': 'the last decade', 'label_2': 'DATE', 'phrase_3': 'the NOAA Virginia Key', 'label_3': 'ORG', 'phrase_4': 'Miami Beach', 'label_4': 'GPE', 'phrase_5': '9mm', 'label_5': 'QUANTITY', 'phrase_6': 'annually', 'label_6': 'DATE'}\n",
      "\n",
      "\n",
      "document: \n",
      "\"The IPCC’s Fourth Assessment Report, 2007, carries in three places a graph in which the Hadley Center’s global mean surface temperature anomaly dataset from 1850-2005 is displayed with four arbitrarily-chosen trend-lines overlaid upon it.\n",
      "\n",
      "{'phrase_0': '2007', 'label_0': 'DATE', 'phrase_1': 'three', 'label_1': 'CARDINAL', 'phrase_2': 'the Hadley Center’s', 'label_2': 'ORG', 'phrase_3': 'anomaly', 'label_3': 'GPE', 'phrase_4': '1850-2005', 'label_4': 'DATE', 'phrase_5': 'four', 'label_5': 'CARDINAL'}\n",
      "\n",
      "\n",
      "document: \n",
      "The bushfires in Australia were caused by arsonists and a series of lightning strikes, not 'climate change'.\n",
      "\n",
      "{'phrase_0': 'Australia', 'label_0': 'GPE'}\n",
      "\n",
      "\n",
      "document: \n",
      "the mild warming of around 0.8 degrees Celsius that the planet has experienced since the middle of the 19th century\n",
      "\n",
      "{'phrase_0': '0.8 degrees', 'label_0': 'QUANTITY', 'phrase_1': 'the middle of the 19th century', 'label_1': 'DATE'}\n",
      "\n",
      "\n",
      "document: \n",
      "This means that the world is now 1C warmer than it was in pre-industrial times\n",
      "\n",
      "{'phrase_0': '1C', 'label_0': 'CARDINAL'}\n",
      "\n",
      "\n",
      "document: \n",
      "Our evolving dynamic planet has survived sea level changes of hundreds of metres\n",
      "\n",
      "{'phrase_0': 'hundreds of metres', 'label_0': 'QUANTITY'}\n",
      "\n",
      "\n",
      "document: \n",
      "Temperatures cooled from about 1940 to 1975, and then they rose from about ’75 to about 2005 or so, and since then they’ve been flat or cooling.\n",
      "\n",
      "{'phrase_0': 'about 1940 to 1975', 'label_0': 'DATE', 'phrase_1': 'about ’75 to about 2005', 'label_1': 'CARDINAL'}\n",
      "\n",
      "\n",
      "document: \n",
      "Klaus-Martin Schulte examined all papers published from 2004 to February 2007.\n",
      "\n",
      "{'phrase_0': 'Klaus-Martin Schulte', 'label_0': 'PERSON', 'phrase_1': '2004', 'label_1': 'DATE'}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(examples_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model parameters\n",
    "We need to provide a set of model parameters that will influence the\n",
    "result:Based on decoding strategy that we have for the models, the parameters can change.\n",
    "\n",
    "There are two decoding strategies: 1-Greedy 2-Sampling.\n",
    "\n",
    "We usually use Greedy for complaint classification, Summarization,Extraction and Q&A\n",
    "\n",
    "We usually use Sampling for content generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GREEDY PAREMETER CONFIGURATION\n",
    "\n",
    "parameters = {\n",
    "         \"decoding_method\": \"greedy\",\n",
    "         \"random_seed\": 33,\n",
    "         \"repetition_penalty\":1,\n",
    "         \"min_new_tokens\": 1,\n",
    "         \"max_new_tokens\": 150\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the named entities of climate claim document using `google/flan-ul2` model.\n",
    "\n",
    "\n",
    "**Note:** You might need to adjust model `parameters` for different models or tasks, to do so please refer to <a href=\"https://ibm.github.io/watson-machine-learning-sdk/model.html#metanames.GenTextParamsMetaNames\" target=\"_blank\" rel=\"noopener no referrer\">documentation</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the `Promtp` class.\n",
    "\n",
    "**Hint:** Your authentication token might expire, if so please regenerate the `access_token` reinitialize the `Promtp` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = Prompt(access_token, project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of all possible NERs: As we do not have ground truth entity extraction data for this dataset, we use an open source package to get the list of named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n"
     ]
    }
   ],
   "source": [
    "list_of_NERS=nlp.get_pipe('ner').labels\n",
    "print(list_of_NERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction=\"\"\"\n",
    "Accurately identify and classify named entities in text. The list of possible labels are:['CARDINAL','DATE','EVENT','FAC','GPE','LANGUAGE','LAW',\n",
    "'LOC','MONEY','NORP','ORDINAL','ORG','PERCENT','PERSON','PRODUCT','QUANTITY','TIME','WORK_OF_ART'].\n",
    "\n",
    "Return your responses in dictionary format. for the each found item, provide the \"phrase\" and\n",
    "the corresponding \"label\" along with their number as dictionary keys separated by numbers. \n",
    "Encapsulate the phrases and labels in single quotation mark. \n",
    "For instance, 'phrase_0':'London', 'label_0':'LOC', 'phrase_1':'Mount Everest', 'label_1':'LOC', and so on.\n",
    "Use the following training examples as follows:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accurately identify and classify named entities in text. The list of possible labels are:['CARDINAL','DATE','EVENT','FAC','GPE','LANGUAGE','LAW',\n",
      "'LOC','MONEY','NORP','ORDINAL','ORG','PERCENT','PERSON','PRODUCT','QUANTITY','TIME','WORK_OF_ART'].\n",
      "\n",
      "Return your responses in dictionary format. for the each found item, provide the \"phrase\" and\n",
      "the corresponding \"label\" along with their number as dictionary keys separated by numbers. \n",
      "Encapsulate the phrases and labels in single quotation mark. \n",
      "For instance, 'phrase_0':'London', 'label_0':'LOC', 'phrase_1':'Mount Everest', 'label_1':'LOC', and so on.\n",
      "Use the following training examples as follows:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for inp in few_shot_inputs_[:40]:\n",
    "    results.append(prompt.generate(\" \".join([instruction+examples_input+ \"document:\" +inp['input']]), model_id, parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"generated_text\": \"'phrase_0': 'the primary control knob', 'label_0': 'ORG', 'phrase_1': '[on climate change]', 'label_1': 'ORG', 'phrase_2': 'this environment that we live in', 'label_2': 'ORG', 'phrase_3': 'control knob', 'label_3': 'ORG', 'phrase_4': '[on climate change]', 'label_4': 'ORG', '\",\n",
      "        \"generated_token_count\": 150,\n",
      "        \"input_token_count\": 1176,\n",
      "        \"stop_reason\": \"MAX_TOKENS\"\n",
      "    },\n",
      "    {\n",
      "        \"generated_text\": \"'phrase_0': 'Rio Grande', 'label_0': 'LOC'\",\n",
      "        \"generated_token_count\": 31,\n",
      "        \"input_token_count\": 1191,\n",
      "        \"stop_reason\": \"EOS_TOKEN\"\n",
      "    },\n",
      "    {\n",
      "        \"generated_text\": \"'phrase_0': 'Mountain West', 'label_0': 'LOC', 'phrase_1': 'Pacific Northwest', 'label_1': 'LOC', 'phrase_2': 'early July', 'label_2': 'DATE', 'phrase_3': 'early August', 'label_3': 'DATE'\",\n",
      "        \"generated_token_count\": 115,\n",
      "        \"input_token_count\": 1191,\n",
      "        \"stop_reason\": \"EOS_TOKEN\"\n",
      "    },\n",
      "    {\n",
      "        \"generated_text\": \"'phrase_0': 'carbon dioxide emissions', 'label_0': 'QUANTITY', 'phrase_1': 'temperature', 'label_1': 'QUANTITY'\",\n",
      "        \"generated_token_count\": 59,\n",
      "        \"input_token_count\": 1167,\n",
      "        \"stop_reason\": \"EOS_TOKEN\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "json_formatted_str = json.dumps(results[:4], indent=4)\n",
    "print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Document #0:\n",
      "Most likely the primary control knob [on climate change] is the ocean waters and this environment that we live in.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'the primary control knob', 'label_0': 'ORG', 'phrase_1': '[on climate change]', 'label_1': 'ORG', 'phrase_2': 'this environment that we live in', 'label_2': 'ORG', 'phrase_3': 'control knob', 'label_3': 'ORG', 'phrase_4': '[on climate change]', 'label_4': 'ORG', '\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #1:\n",
      "The Rio Grande is a classic “feast or famine” river, with a dry year or two typically followed by a couple of wet years that allow for recovery.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'Rio Grande', 'label_0': 'LOC'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #2:\n",
      "Days of near-100-degree-Fahrenheit temperatures cooked the Mountain West in early July, and a scorching heat wave lingered over the Pacific Northwest in early August.”\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'Mountain West', 'label_0': 'LOC', 'phrase_1': 'Pacific Northwest', 'label_1': 'LOC', 'phrase_2': 'early July', 'label_2': 'DATE', 'phrase_3': 'early August', 'label_3': 'DATE'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #3:\n",
      "In our lifetime, there has been no correlation between carbon dioxide emissions and temperature\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'carbon dioxide emissions', 'label_0': 'QUANTITY', 'phrase_1': 'temperature', 'label_1': 'QUANTITY'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #4:\n",
      "There is no way for us to prevent the world’s CO2 emissions    from doubling by 2100\"\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'world’s CO2 emissions', 'label_0': 'QUANTITY', 'phrase_1': 'from doubling by 2100', 'label_1': 'DATE', 'phrase_2': 'by 2100', 'label_2': 'QUANTITY', 'phrase_3': 'There is no way for us to prevent the world’s CO2 emissions from doubling by 2100', 'label_3': 'QUANTITY', 'phrase_4': 'There\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #5:\n",
      "Wu et al (2010) use a new method to calculate ice sheet mass balance.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'Wu et al', 'label_0': 'PERSON', 'phrase_1': '(2010)', 'label_1': 'DATE'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #6:\n",
      "In the last 35 years of global warming, sun and climate have been going in opposite directions.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'sun and climate', 'label_0': 'ORG', 'phrase_1': 'going in opposite directions', 'label_1': 'ORG', 'phrase_2': 'last 35 years', 'label_2': 'DATE', 'phrase_3': 'global warming', 'label_3': 'DATE', 'phrase_4': 'sun and climate', 'label_4': 'ORG', 'phrase_5'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #7:\n",
      "Australia has more solar coverage than any other continent.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'Australia', 'label_0': 'LOC'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #8:\n",
      "Polar bears are in danger of extinction as well as many other species.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'Polar bears', 'label_0': 'ORG', 'phrase_1': 'many other species', 'label_1': 'ORG'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #9:\n",
      "The United States has been restricting soot emissions  in Draconian fashion since the Clean Air Act of 1963.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'United States', 'label_0': 'LOC', 'phrase_1': 'Clean Air Act', 'label_1': 'LAW', 'phrase_2': 'since', 'label_2': '1963'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #10:\n",
      "The costs of inaction far outweigh the costs of mitigation.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'costs of inaction', 'label_0': 'COST', 'phrase_1': 'costs of mitigation', 'label_1': 'COST'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #11:\n",
      "“In their award winning book, ‘Taken By Storm’ (2007), Canadian researchers Christopher Essex and Ross McKitrick explain: ‘Temperature is not an amount of something [like height or weight].\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'Taken By Storm’ ', 'label_0': 'BOOK', 'phrase_1': 'Canadian researchers Christopher Essex and Ross McKitrick', 'label_1': 'PERSON', 'phrase_2': 'Canadian researchers Christopher Essex and Ross McKitrick', 'label_2': 'PERSON', 'phrase_3': 'Temperature is not an amount of something [like height or weight]', 'label_3': 'QUANTITY'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #12:\n",
      "Greg Hunt CSIRO research shows carbon emissions can be reduced by 20 per cent over 40 years using nature, soils and trees.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'Greg Hunt CSIRO', 'label_0': 'ORG', 'phrase_1': 'research shows carbon emissions can be reduced by 20 per cent over 40 years using nature, soils and trees'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #13:\n",
      "With that in mind, they propose a plausible and terrifying “2050 scenario” whereby humanity could face irreversible collapse in just three decades.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': '2050 scenario', 'label_0': 'ORG', 'phrase_1': '2050 scenario', 'label_1': 'ORG', 'phrase_2': '2050 scenario', 'label_2': 'ORG', 'phrase_3': '2050 scenario', 'label_3': 'ORG', 'phrase_4': '2050 scenario', 'label_4': 'ORG', 'phrase_5': '\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #14:\n",
      "No known natural forcing fits the fingerprints of observed warming except anthropogenic greenhouse gases.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'anthropogenic', 'label_0': 'FAC', 'phrase_1': 'greenhouse gases', 'label_1': 'FAC'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #15:\n",
      "We know the Northwest Passage had been open before.\"\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'the Northwest Passage', 'label_0': 'LOC', 'phrase_1': 'had been open before', 'label_1': 'before'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #16:\n",
      "Mass coral bleaching is a new phenomenon and was never observed before the 1980s as global warming ramped up.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'Mass coral bleaching', 'label_0': 'EVENT', 'phrase_1': 'new phenomenon', 'label_1': 'FAC', 'phrase_2': 'global warming ramped up', 'label_2': 'GPE', 'phrase_3': 'before the 1980s', 'label_3': 'DATE', 'phrase_4': 'before the 1980s', 'label_4': 'QUANTITY'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #17:\n",
      "[S]unspot activity on the surface of our star has dropped to a new low.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': '[s]unspot activity', 'label_0': 'FAC', 'phrase_1': 'the surface of our star', 'label_1': 'LOC', 'phrase_2': 'new low', 'label_2': 'QUANTITY'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #18:\n",
      "Carbon dioxide is a trace gas.”\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'Carbon dioxide', 'label_0': 'PRODUCT', 'phrase_1': 'trace gas', 'label_1': 'QUANTITY'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #19:\n",
      "Arctic sea ice has been steadily thinning, even in the last few years while the surface ice (eg - sea ice extent) increased slightly.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'Arctic sea ice', 'label_0': 'LOC', 'phrase_1': 'thinning', 'label_1': 'QUANTITY', 'phrase_2': 'surface ice', 'label_2': 'QUANTITY', 'phrase_3': 'sea ice extent', 'label_3': 'QUANTITY', 'phrase_4': 'increased slightly', 'label_4': 'QUANTITY\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #20:\n",
      "The consensus among scientists and policy-makers is that we’ll pass this point of no return if the global mean temperature rises by more than two degrees Celsius.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'scientists and policy-makers', 'label_0': 'PERSON', 'phrase_1': 'point of no return', 'label_1': 'QUANTITY', 'phrase_2': 'global mean temperature', 'label_2': 'CARDINAL', 'phrase_3': 'rises by more than two degrees Celsius', 'label_3': 'QUANTITY', 'phrase_4': 'Celsius', 'label_4'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #21:\n",
      "Over the last 30-40 years 80% of coral in the Caribbean have been destroyed and 50% in Indonesia and the Pacific.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'carribean', 'label_0': 'LOC', 'phrase_1': 'Indonesia', 'label_1': 'LOC', 'phrase_2': 'Pacific', 'label_2': 'LOC', 'phrase_3': '80%', 'label_3': 'QUANTITY'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #22:\n",
      "There are about 120,000 solar energy jobs in the United States, but only 1,700 of them are in Georgia.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'United States', 'label_0': 'LOC', 'phrase_1': 'Georgia', 'label_1': 'LOC'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #23:\n",
      "All the indicators show that global warming is still happening.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'global warming', 'label_0': 'EVENT'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #24:\n",
      "While there are isolated cases of growing glaciers, the overwhelming trend in glaciers worldwide is retreat.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'grow glaciers', 'label_0': 'LOC', 'phrase_1': 'grow glaciers', 'label_1': 'LOC', 'phrase_2': 'grow glaciers', 'label_2': 'LOC', 'phrase_3': 'grow glaciers', 'label_3': 'LOC', 'phrase_4': 'grow glaciers', 'label_4': 'LOC', 'phrase_\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #25:\n",
      "\"The 30 major droughts of the 20th century were likely natural in all respects; and, hence, they are \"indicative of what could also happen in the future,\" as Narisma\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': \"The 30 major droughts of the 20th century were likely natural in all respects; and, hence, they are \"indicative of what could also happen in the future,\" as narisma', 'label_0': 'PERSON', 'label_1': 'ORG', 'label_2': 'PERCENT', 'label_3': 'ORG', 'label_4': 'PERCENT', 'label_5': 'PERSON', 'label_6': 'PERSON\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #26:\n",
      "Previous IPCC reports tended to assume that clouds would have a neutral impact because the warming and cooling feedbacks would cancel each other out.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'IPCC', 'label_0': 'ORG', 'phrase_1': 'reports', 'label_1': 'EVENT', 'phrase_2': 'would cancel each other out', 'label_2': 'warming and cooling feedbacks'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #27:\n",
      "Measurements indicating that 2017 had relatively more sea ice in the Arctic and less melting of glacial ice in Greenland casts scientific doubt on the reality of global warming.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'Arctic', 'label_0': 'LOC', 'phrase_1': 'Greenland', 'label_1': 'LOC', 'phrase_2': 'melting', 'label_2': 'LOC', 'phrase_3': 'global warming', 'label_3': 'LOC', 'phrase_4': 'scientific doubt', 'label_4': 'LOC', 'phrase_5': '\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #28:\n",
      "It has never been shown that human emissions of carbon dioxide drive global warming.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'human emissions of carbon dioxide drive global warming', 'label_0': 'QUANTITY', 'phrase_1': 'human emissions of carbon dioxide drive global warming', 'label_1': 'QUANTITY'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #29:\n",
      "cutting speed limits could slow climate change\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'cutting speed limits could slow climate change', 'label_0': 'QUANTITY', 'phrase_1': 'climate change', 'label_1': 'QUANTITY'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #30:\n",
      "Research has found a human influence on the climate of the past several decades ...\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'human influence', 'label_0': 'ORG', 'phrase_1': 'climate', 'label_1': 'ORG', 'phrase_2': 'past several decades', 'label_2': 'ORG', 'phrase_3': 'Research', 'label_3': 'ORG', 'phrase_4': 'human', 'label_4': 'ORG', 'phrase_5': 'climate',\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #31:\n",
      "By 2100 the seas will rise another 6 inches or so—a far cry from Al Gore’s alarming numbers\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'Al Gore’s', 'label_0': 'PERSON', 'phrase_1': 'alarming numbers', 'label_1': 'PERSON', 'phrase_2': '6 inches', 'label_2': 'QUANTITY', 'phrase_3': '2100', 'label_3': 'DATE', 'phrase_4': 'the seas will rise another 6 inches or so', 'label_4': 'DATE'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #32:\n",
      "Multiple lines of independent evidence indicate humidity is rising and provides positive feedback.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'multiple lines of independent evidence', 'label_0': 'ORG', 'phrase_1': 'indicate humidity is rising and provides positive feedback', 'label_1': 'QUANTITY'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #33:\n",
      "a study that totally debunks the whole concept of man-made Global Warming\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'Global Warming', 'label_0': 'GPE', 'phrase_1': 'man-made', 'label_1': 'GPE', 'phrase_2': 'concept', 'label_2': 'GPE', 'phrase_3': 'whole', 'label_3': 'GPE', 'phrase_4': 'concept', 'label_4': 'GPE', 'phrase_5': 'whole'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #34:\n",
      "Claims have recently surfaced in the blogosphere that an increasing number of scientists are warning of an imminent global cooling, some even going so far as to call it a \"growing consensus\".\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'blogosphere', 'label_0': 'LOC', 'phrase_1': 'an increasing number of scientists', 'label_1': 'PERSON', 'phrase_2': 'a \"growing consensus\"', 'label_2': 'PERSON', 'phrase_3': 'an imminent global cooling', 'label_3': 'QUANTITY', 'phrase_4': 'scientists', 'label_4': 'PERSON', 'phrase\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #35:\n",
      "The extent of climate change’s influence on the jet stream is an intense subject of research.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'climate change’s influence', 'label_0': 'ORG', 'phrase_1': 'jet stream', 'label_1': 'REGION', 'phrase_2': 'research', 'label_2': 'ORG', 'phrase_3': 'intense', 'label_3': 'ORG', 'phrase_4': 'subject', 'label_4': 'ORG', 'phrase_5':\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #36:\n",
      "CO2 limits won't cool the planet.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'CO2 limits', 'label_0': 'ORG', 'phrase_1': 'cool the planet', 'label_1': 'ORG'\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #37:\n",
      "“Global warming alarmists’ preferred electricity source – wind power – kills nearly 1 million bats every year (to say nothing of the more than 500,000 birds killed every year) in the United States alone.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'Global warming alarmists', 'label_0': 'PERSON', 'phrase_1': 'wind power', 'label_1': 'ORG', 'phrase_2': 'kills nearly 1 million bats every year', 'label_2': 'QUANTITY', 'phrase_3': 'United States', 'label_3': 'LOC', 'phrase_4': 'kills every year', 'label_4': 'QUANTITY\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #38:\n",
      "They concluded that trends toward rising climate damages were mainly due to increased population and economic activity in the path of storms, that it was not currently possible to determine the portion of damages attributable to greenhouse gases, and that they didn’t expect that situation to change in the near future.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'they', 'label_0': 'PERSON', 'phrase_1': 'trends toward rising climate damages', 'label_1': 'QUANTITY', 'phrase_2': 'economic activity in the path of storms', 'label_2': 'ORG', 'phrase_3': 'attributable to greenhouse gases', 'label_3': 'PERCENT', 'phrase_4': 'that situation to change in the near future', 'label_4':\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Document #39:\n",
      "Humans are too insignificant to affect global climate.\n",
      "Raw results from LLM model:\n",
      "  'phrase_0': 'Humans', 'label_0': 'PERSON', 'phrase_1': 'affect global climate', 'label_1': 'PERSON'\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results)):\n",
    "    print('--------------------------------------------------')\n",
    "    print(f\"Document #{i}:\\n{few_shot_inputs_[i]['input']}\")\n",
    "    print(f'Raw results from LLM model:\\n ',results[i]['generated_text'])\n",
    "    print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to extract `y_true` by performing NER using **Spacy** package as the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each document in the few_shot_inputs_\n",
    "fsi ={}\n",
    "fsi_list_for_ground_truth=[]\n",
    "\n",
    "for document in few_shot_inputs_[:40]:\n",
    "    doc = nlp(document['input'].strip())  # Process the document with spacy NLP pipeline\n",
    "    if (len(doc.ents) != 0):\n",
    "        fsi ={}\n",
    "        fsi['document']=document['input']\n",
    "        for i, ent in enumerate(doc.ents):\n",
    "            fsi[f'phrase_{i}']=ent.text\n",
    "            fsi[f'label_{i}']=ent.label_\n",
    "        \n",
    "            \n",
    "        fsi_list_for_ground_truth.append(fsi)\n",
    "    else:\n",
    "        fsi_list_for_ground_truth.append({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {},\n",
      "    {\n",
      "        \"document\": \"The Rio Grande is a classic \\u201cfeast or famine\\u201d river, with a dry year or two typically followed by a couple of wet years that allow for recovery.\",\n",
      "        \"phrase_0\": \"The Rio Grande\",\n",
      "        \"label_0\": \"ORG\",\n",
      "        \"phrase_1\": \"a dry year\",\n",
      "        \"label_1\": \"DATE\",\n",
      "        \"phrase_2\": \"two\",\n",
      "        \"label_2\": \"CARDINAL\",\n",
      "        \"phrase_3\": \"a couple of wet years\",\n",
      "        \"label_3\": \"DATE\"\n",
      "    },\n",
      "    {\n",
      "        \"document\": \"Days of near-100-degree-Fahrenheit temperatures cooked the Mountain West in early July, and a scorching heat wave lingered over the Pacific Northwest in early August.\\u201d\",\n",
      "        \"phrase_0\": \"the Mountain West\",\n",
      "        \"label_0\": \"LOC\",\n",
      "        \"phrase_1\": \"early July\",\n",
      "        \"label_1\": \"DATE\",\n",
      "        \"phrase_2\": \"the Pacific Northwest\",\n",
      "        \"label_2\": \"LOC\",\n",
      "        \"phrase_3\": \"early August\",\n",
      "        \"label_3\": \"DATE\"\n",
      "    },\n",
      "    {}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "json_formatted_str = json.dumps(fsi_list_for_ground_truth[:4], indent=4)\n",
    "print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post processing the results so that they can be compared with the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dictionary_from_results(s):\n",
    "    \n",
    "    ss2=s.split(', ')\n",
    "    \n",
    "    pc=0\n",
    "    lc=0\n",
    "    for w in ss2:\n",
    "        if 'phrase_' in w:\n",
    "            pc+=1\n",
    "        if 'label_' in w:\n",
    "            lc+=1\n",
    "    if ((pc==lc) and ((pc%2)==0) and ((lc%2)==0)):\n",
    "        return (eval(\"{\"+s+\"}\"))\n",
    "    \n",
    "    elif((pc%2)!=0 or ((lc%2)!=0)):\n",
    "       \n",
    "        lim = min(pc,lc)\n",
    "        wlim = 2*lim\n",
    "        return (eval('{'+','.join(ss2[:wlim])+'}'))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function finds common words in two given phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_words(string1, string2):\n",
    "    words1 = set(string1.lower().split())\n",
    "    words2 = set(string2.lower().split())\n",
    "    common_words = words1.intersection(words2)\n",
    "    return list(common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function removes unnecessary \"the\" and \"a\" from the given phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_words(string):\n",
    "    words_to_drop = ['the', 'a']\n",
    "    pattern = r'\\b(?:{})\\b'.format('|'.join(words_to_drop))\n",
    "    cleaned_string = re.sub(pattern, '', string, flags=re.IGNORECASE)\n",
    "    return cleaned_string.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function handles imbalanced quotation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polish_results(r):\n",
    "    \n",
    "    sp=r.split(',')\n",
    "    \n",
    "    nw=[]\n",
    "    for w in sp:\n",
    "        b=''\n",
    "        b=w.replace('\"', '').replace(\"'\", \"\")\n",
    "        nw.append(b)\n",
    "    \n",
    "    msl=[]\n",
    "    for w in nw:\n",
    "        ns=w.split(\":\")\n",
    "        nss=[]\n",
    "        for i in range(len(ns)):\n",
    "            ns[i]=ns[i].lstrip()\n",
    "        nss.append(\"'\"+ns[0]+\"'\"+':'+\"'\"+ns[1]+\"'\")\n",
    "\n",
    "        ms=''.join(nss)\n",
    "        msl.append(ms)\n",
    "\n",
    "    res=','.join(msl)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the model can be compared to ground truth labels. The code below handles this task by comparing the identified phrases, which are common in both ground truth and model results. This task is done by ignoring the order which phrases appear in both ground truth and LLMs results and comparing the lenght of common words in both of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=[]\n",
    "y_pred=[]\n",
    "\n",
    "for i in range(len(fsi_list_for_ground_truth)):\n",
    "    \n",
    "    try:\n",
    "        keys=fsi_list_for_ground_truth[i].keys()\n",
    "        if (len(keys) !=0):\n",
    "            temp_s = copy.deepcopy(fsi_list_for_ground_truth[i])\n",
    "            del temp_s['document']\n",
    "            \n",
    "            \n",
    "            ground_truth_keys = list(temp_s.keys())\n",
    "            ground_truth_values = list(temp_s.values())\n",
    "            \n",
    "            model_results=extract_dictionary_from_results(polish_results(results[i]['generated_text']))\n",
    "            \n",
    "            model_res_keys=list(model_results.keys())\n",
    "            model_res_values=list(model_results.values())\n",
    "            \n",
    "          \n",
    "            \n",
    "            for k in ground_truth_keys:\n",
    "                if ('phrase_' in k):\n",
    "                    \n",
    "                    phrase=temp_s[k]\n",
    "                    \n",
    "                    for v in model_res_values:\n",
    "                        if (len(find_common_words(drop_words(phrase),drop_words(v)))/len(phrase.split())>0.5):\n",
    "                            ground_truth_label = temp_s['label_'+(ground_truth_keys[ground_truth_values.index(phrase)].strip('phrase_'))]\n",
    "                            model_res_label=model_results['label_'+(model_res_keys[model_res_values.index(v)].strip('phrase_'))]\n",
    "                            \n",
    "                            if (model_res_label==ground_truth_label):\n",
    "                                y_true.append(1)\n",
    "                                y_pred.append(1)\n",
    "                            else:\n",
    "                                y_true.append(1)\n",
    "                                y_pred.append(0)\n",
    "                            \n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "        \n",
    "len_y_true = len(y_true)\n",
    "len_y_pred = len(y_pred)\n",
    "\n",
    "fsi_ners=copy.deepcopy(fsi_list_for_ground_truth)\n",
    "\n",
    "try:\n",
    "    del fsi_ners['document']\n",
    "    \n",
    "except:\n",
    "    pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_y_true = len(y_true)\n",
    "len_y_pred = len(y_pred)\n",
    "\n",
    "for i in range(len(fsi_list_for_ground_truth)):\n",
    "    fsi_ners=copy.deepcopy(fsi_list_for_ground_truth[i])\n",
    "    try:\n",
    "        del fsi_ners['document']\n",
    "       \n",
    "        \n",
    "        model_ners=extract_dictionary_from_results(results[i]['generated_text'])\n",
    "       \n",
    "        \n",
    "        if (len(fsi_ners)>len(model_ners)):\n",
    "            diff = len(fsi_ners)-len(model_ners)\n",
    "            \n",
    "            for j in range(len(diff)):\n",
    "                y_true.append(1)\n",
    "                y_pred.append(0)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.40      0.57        40\n",
      "\n",
      "    accuracy                           0.40        40\n",
      "   macro avg       0.50      0.20      0.29        40\n",
      "weighted avg       1.00      0.40      0.57        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=y_pred,y_true=y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's only apply for single entity of Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINGLE ENTITY\n",
    "Single entity case: We tried a single entity extraction as well. It is essential to consider the quality of the extraction process. If the objective is to extract multiple entity types and the accuracy is not good enough,you may want to experiment with a smaller set of entity types at a time to see whether the accuracy can be improved (as there are more examples of that entity type that can fit in the context of the model, compared to the case of many entity types). \n",
    "\n",
    "Here, we are trying to experiment with a single entity type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_label = 'LOC'\n",
    "desc = 'location'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_replacement_dictionary={'GPE':'LOC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction=f\"\"\"\n",
    "Accurately identify and classify the \n",
    "NERs of type {desc} ({specific_label}).\n",
    "\n",
    "Return your responses in dictionary format. for the each item you found, provide the \"phrase\" and\n",
    "the corresponding \"label\" along with their number as dictionary key separated by numbers. \n",
    "Increment the 'phrase_' and 'label_' for the next NER.Each 'phrase_' should be coupled with a 'label_'.\n",
    "Make sure to encapsulate the found phrases and labels in single quotation mark.\n",
    "For instance, 'phrase_0':'London', 'label_0':'LOC', 'phrase_1':'Mount Everest', 'label_1':'LOC', and so on.\n",
    "Use the following training examples as follows:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accurately identify and classify the \n",
      "NERs of type location (LOC).\n",
      "\n",
      "Return your responses in dictionary format. for the each item you found, provide the \"phrase\" and\n",
      "the corresponding \"label\" along with their number as dictionary key separated by numbers. \n",
      "Increment the 'phrase_' and 'label_' for the next NER.Each 'phrase_' should be coupled with a 'label_'.\n",
      "Make sure to encapsulate the found phrases and labels in single quotation mark.\n",
      "For instance, 'phrase_0':'London', 'label_0':'LOC', 'phrase_1':'Mount Everest', 'label_1':'LOC', and so on.\n",
      "Use the following training examples as follows:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function replaces the ground truth lables with the desired one as mentioned in the replacement dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_label_values(examples,label_replacement_dictionary):\n",
    "    examples_cp = copy.deepcopy(examples)\n",
    "    for i in range(len(examples_cp)):\n",
    "        keys = list(examples_cp[i].keys())\n",
    "        for k in keys:\n",
    "            if 'label_' in k:\n",
    "                for rl in label_replacement_dictionary.keys():\n",
    "                    if (examples_cp[i][k] == rl):\n",
    "                        examples_cp[i][k]=label_replacement_dictionary[rl]\n",
    "    return examples_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_processed_examples = replace_label_values(example_dic_list,label_replacement_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"document\": \"While there has been a mean rise of a little more than 3mm per year worldwide since the 1990s, in the last decade, the NOAA Virginia Key tide gauge just south of Miami Beach has measured a 9mm rise annually.\\u201d\",\n",
      "        \"phrase_0\": \"a little more than 3mm per year\",\n",
      "        \"label_0\": \"DATE\",\n",
      "        \"phrase_1\": \"the 1990s\",\n",
      "        \"label_1\": \"DATE\",\n",
      "        \"phrase_2\": \"the last decade\",\n",
      "        \"label_2\": \"DATE\",\n",
      "        \"phrase_3\": \"the NOAA Virginia Key\",\n",
      "        \"label_3\": \"ORG\",\n",
      "        \"phrase_4\": \"Miami Beach\",\n",
      "        \"label_4\": \"LOC\",\n",
      "        \"phrase_5\": \"9mm\",\n",
      "        \"label_5\": \"QUANTITY\",\n",
      "        \"phrase_6\": \"annually\",\n",
      "        \"label_6\": \"DATE\"\n",
      "    },\n",
      "    {\n",
      "        \"document\": \"\\\"The IPCC\\u2019s Fourth Assessment Report, 2007, carries in three places a graph in which the Hadley Center\\u2019s global mean surface temperature anomaly dataset from 1850-2005 is displayed with four arbitrarily-chosen trend-lines overlaid upon it.\",\n",
      "        \"phrase_0\": \"2007\",\n",
      "        \"label_0\": \"DATE\",\n",
      "        \"phrase_1\": \"three\",\n",
      "        \"label_1\": \"CARDINAL\",\n",
      "        \"phrase_2\": \"the Hadley Center\\u2019s\",\n",
      "        \"label_2\": \"ORG\",\n",
      "        \"phrase_3\": \"anomaly\",\n",
      "        \"label_3\": \"LOC\",\n",
      "        \"phrase_4\": \"1850-2005\",\n",
      "        \"label_4\": \"DATE\",\n",
      "        \"phrase_5\": \"four\",\n",
      "        \"label_5\": \"CARDINAL\"\n",
      "    },\n",
      "    {\n",
      "        \"document\": \"The bushfires in Australia were caused by arsonists and a series of lightning strikes, not 'climate change'.\",\n",
      "        \"phrase_0\": \"Australia\",\n",
      "        \"label_0\": \"LOC\"\n",
      "    },\n",
      "    {\n",
      "        \"document\": \"the mild warming of around 0.8 degrees Celsius that the planet has experienced since the middle of the 19th century\",\n",
      "        \"phrase_0\": \"0.8 degrees\",\n",
      "        \"label_0\": \"QUANTITY\",\n",
      "        \"phrase_1\": \"the middle of the 19th century\",\n",
      "        \"label_1\": \"DATE\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "json_formatted_str = json.dumps(post_processed_examples[:4], indent=4)\n",
    "print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_only_certain_labels(examples, specific_label):\n",
    "    list_of_modified_examples=[]\n",
    "    for e in examples:\n",
    "        e_cp = copy.deepcopy(e)\n",
    "        keys = list(e_cp.keys())\n",
    "        \n",
    "        for k in keys:\n",
    "            if 'label_' in k:\n",
    "                numeric_val = k.split('label_')[1]\n",
    "                #print('NV=',numeric_val)\n",
    "                if (e_cp[k]!=specific_label):\n",
    "                    del e_cp[k]\n",
    "                    del e_cp['phrase_'+numeric_val]\n",
    "        \n",
    "        if(len(e_cp)>1):\n",
    "            list_of_modified_examples.append(e_cp)\n",
    "    \n",
    "    return list_of_modified_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_examples_list = keep_only_certain_labels(post_processed_examples, specific_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"document\": \"While there has been a mean rise of a little more than 3mm per year worldwide since the 1990s, in the last decade, the NOAA Virginia Key tide gauge just south of Miami Beach has measured a 9mm rise annually.\\u201d\",\n",
      "        \"phrase_4\": \"Miami Beach\",\n",
      "        \"label_4\": \"LOC\"\n",
      "    },\n",
      "    {\n",
      "        \"document\": \"\\\"The IPCC\\u2019s Fourth Assessment Report, 2007, carries in three places a graph in which the Hadley Center\\u2019s global mean surface temperature anomaly dataset from 1850-2005 is displayed with four arbitrarily-chosen trend-lines overlaid upon it.\",\n",
      "        \"phrase_3\": \"anomaly\",\n",
      "        \"label_3\": \"LOC\"\n",
      "    },\n",
      "    {\n",
      "        \"document\": \"The bushfires in Australia were caused by arsonists and a series of lightning strikes, not 'climate change'.\",\n",
      "        \"phrase_0\": \"Australia\",\n",
      "        \"label_0\": \"LOC\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "json_formatted_str = json.dumps(modified_examples_list, indent=4)\n",
    "print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(modified_examples_list)):\n",
    "    examples.append('document: \\n'+modified_examples_list[i]['document']+'\\n')\n",
    "    di=copy.deepcopy(modified_examples_list[i])\n",
    "    del di['document']\n",
    "    examples.append('\\n')\n",
    "    examples.append(str(di))\n",
    "    examples.append('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_input=''.join(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: \n",
      "While there has been a mean rise of a little more than 3mm per year worldwide since the 1990s, in the last decade, the NOAA Virginia Key tide gauge just south of Miami Beach has measured a 9mm rise annually.”\n",
      "\n",
      "{'phrase_4': 'Miami Beach', 'label_4': 'LOC'}\n",
      "\n",
      "\n",
      "document: \n",
      "\"The IPCC’s Fourth Assessment Report, 2007, carries in three places a graph in which the Hadley Center’s global mean surface temperature anomaly dataset from 1850-2005 is displayed with four arbitrarily-chosen trend-lines overlaid upon it.\n",
      "\n",
      "{'phrase_3': 'anomaly', 'label_3': 'LOC'}\n",
      "\n",
      "\n",
      "document: \n",
      "The bushfires in Australia were caused by arsonists and a series of lightning strikes, not 'climate change'.\n",
      "\n",
      "{'phrase_0': 'Australia', 'label_0': 'LOC'}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(examples_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for inp in few_shot_inputs_[:40]:\n",
    "    results.append(prompt.generate(\" \".join([instruction+examples_input+ \"document:\" +inp['input']]), model_id, parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"generated_text\": \"phrase_0: \\\"the ocean waters and this environment that we live in.\\\", 'label_0': 'LOC'\",\n",
      "        \"generated_token_count\": 32,\n",
      "        \"input_token_count\": 442,\n",
      "        \"stop_reason\": \"EOS_TOKEN\"\n",
      "    },\n",
      "    {\n",
      "        \"generated_text\": \"phrase_0: \\\"The Rio Grande\\\" , 'label_0': 'LOC'\",\n",
      "        \"generated_token_count\": 26,\n",
      "        \"input_token_count\": 457,\n",
      "        \"stop_reason\": \"EOS_TOKEN\"\n",
      "    },\n",
      "    {\n",
      "        \"generated_text\": \"'phrase_0': 'Mountain West', 'label_0': 'LOC', 'phrase_1': 'Pacific Northwest', 'label_1': 'LOC'\",\n",
      "        \"generated_token_count\": 59,\n",
      "        \"input_token_count\": 457,\n",
      "        \"stop_reason\": \"EOS_TOKEN\"\n",
      "    },\n",
      "    {\n",
      "        \"generated_text\": \"'phrase_0': 'in our lifetime', 'label_0': 'LOC'\",\n",
      "        \"generated_token_count\": 30,\n",
      "        \"input_token_count\": 433,\n",
      "        \"stop_reason\": \"EOS_TOKEN\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "json_formatted_str = json.dumps(results[:4], indent=4)\n",
    "print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polish_results(r):\n",
    "    \n",
    "    sp=r.split(',')\n",
    "    \n",
    "    nw=[]\n",
    "    for w in sp:\n",
    "        b=''\n",
    "        b=w.replace('\"', '').replace(\"'\", \"\")\n",
    "        nw.append(b)\n",
    "        \n",
    "    msl=[]\n",
    "    for w in nw:\n",
    "        ns=w.split(\":\")\n",
    "        nss=[]\n",
    "        for i in range(len(ns)):\n",
    "            ns[i]=ns[i].lstrip()\n",
    "        nss.append(\"'\"+ns[0]+\"'\"+':'+\"'\"+ns[1]+\"'\")\n",
    "\n",
    "        ms=''.join(nss)\n",
    "        msl.append(ms)\n",
    "\n",
    "    res=','.join(msl)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'phrase_0':'Mountain West','label_0':'LOC','phrase_1':'Pacific Northwest','label_1':'LOC'\n"
     ]
    }
   ],
   "source": [
    "print(polish_results(results[2]['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'phrase_0': 'Mountain West', 'label_0': 'LOC', 'phrase_1': 'Pacific Northwest', 'label_1': 'LOC'}\n"
     ]
    }
   ],
   "source": [
    "print(extract_dictionary_from_results(polish_results(results[2]['generated_text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'phrase_0': 'the ocean waters and this environment that we live in.', 'label_0': 'LOC'}\n"
     ]
    }
   ],
   "source": [
    "print(extract_dictionary_from_results(polish_results(results[0]['generated_text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=[]\n",
    "y_pred=[]\n",
    "\n",
    "for i in range(len(fsi_list_for_ground_truth)):\n",
    "    try:\n",
    "        keys=fsi_list_for_ground_truth[i].keys()\n",
    "        if (len(keys) !=0):\n",
    "            temp_s = copy.deepcopy(fsi_list_for_ground_truth[i])\n",
    "            del temp_s['document']\n",
    "      \n",
    "            \n",
    "            ground_truth_keys = list(temp_s.keys())\n",
    "            ground_truth_values = list(temp_s.values())\n",
    "            \n",
    "            model_results=extract_dictionary_from_results(polish_results(results[i]['generated_text']))\n",
    "            \n",
    "            model_res_keys=list(model_results.keys())\n",
    "            model_res_values=list(model_results.values())\n",
    "            \n",
    "            \n",
    "            \n",
    "            for k in ground_truth_keys:\n",
    "                if ('phrase_' in k):\n",
    "                  \n",
    "                    phrase=temp_s[k]\n",
    "                   \n",
    "                    for v in model_res_values:\n",
    "                        if (len(find_common_words(drop_words(phrase),drop_words(v)))/len(phrase.split())>0.5):\n",
    "\n",
    "                            ground_truth_label = temp_s['label_'+(ground_truth_keys[ground_truth_values.index(phrase)].strip('phrase_'))]\n",
    "                            \n",
    "                            if (ground_truth_label==specific_label):\n",
    "                                model_res_label=model_results['label_'+(model_res_keys[model_res_values.index(v)].strip('phrase_'))]\n",
    "\n",
    "                                if (model_res_label==ground_truth_label):\n",
    "                                    y_true.append(1)\n",
    "                                    y_pred.append(1)\n",
    "                                else:\n",
    "                                    y_true.append(1)\n",
    "                                    y_pred.append(0)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "        \n",
    "len_y_true = len(y_true)\n",
    "len_y_pred = len(y_pred)\n",
    "\n",
    "fsi_ners=copy.deepcopy(fsi_list_for_ground_truth)\n",
    "\n",
    "try:\n",
    "    del fsi_ners['document']\n",
    "    \n",
    "except:\n",
    "    pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_y_true = len(y_true)\n",
    "len_y_pred = len(y_pred)\n",
    "\n",
    "for i in range(len(fsi_list_for_ground_truth)):\n",
    "    fsi_ners=copy.deepcopy(fsi_list_for_ground_truth[i])\n",
    "    try:\n",
    "        del fsi_ners['document']\n",
    "        \n",
    "        \n",
    "        model_ners=extract_dictionary_from_results(results[i]['generated_text'])\n",
    "       \n",
    "        \n",
    "        if (len(fsi_ners)>len(model_ners)):\n",
    "            diff = len(fsi_ners)-len(model_ners)\n",
    "            \n",
    "            for j in range(len(diff)):\n",
    "                y_true.append(1)\n",
    "                y_pred.append(0)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00         5\n",
      "   macro avg       1.00      1.00      1.00         5\n",
      "weighted avg       1.00      1.00      1.00         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=y_pred,y_true=y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"summary\"></a>\n",
    "## Summary and next steps\n",
    "\n",
    " You successfully completed this notebook!.\n",
    " \n",
    " You learned how to extract named entities with Google's `google/flan-ul2` on watsonx. \n",
    " \n",
    " Check out our _<a href=\"https://ibm.github.io/watson-machine-learning-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Author: Kahila Mokhtari**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright © 2023 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
