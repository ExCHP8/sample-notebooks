{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Parquet Modular Encryption Example\n## Key Management by Application"}, {"metadata": {}, "cell_type": "markdown", "source": "Learn to encrypt parquet files and read encrypted parquet files with a pre-configured IBM Analytics Engine. \n\nThis notebook demonstrates the new parquet modular encryption that IBM supports, for the purpose of encrypting columns, sections or sensitive parts of data, such as Personal Information (PI). For the purposes of this tutorial, you will learn how to encrypt sample blood test data in parquet format, and learn to read and write such encrypted data by using [Key management by application](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-key-management-application). The contents of this notebook is written for Scala 2.11 and requires at least Spark 2.3."}, {"metadata": {}, "cell_type": "markdown", "source": "### Table of Contents:\n* [1. Setup the environment](#cell0)\n* [2. Generate the data](#cell1)\n* [3. Write the encrypted data](#cell2)\n* [4. Read the encrypted data](#cell3)\n* [Summary](#summary)\n* [Authors](#authors)"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"cell0\"></a>\n## Setup the environment"}, {"metadata": {}, "cell_type": "markdown", "source": "<div class=\"alert alert-block alert-warning\">\n    A standard IBM Analytics Engine (IAE) will not be useful for parquet modular encryption. You must configure your IAE according to the <a href=\"https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-parquet-encryption\">Analytics Engine Parquet Encryption</a> documentation before you run the rest of the notebook.\n</div>"}, {"metadata": {}, "cell_type": "markdown", "source": "1. After you have a configured IAE, have your Spark classpaths point to the Parquet jar files as instructed [here](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-parquet-encryption#running-ibm-analytics-engine-with-parquet-encryption). \n1. Before you add this notebook to your project, associate your configured IAE with the project you are running this notebook in. \n1. When you create the notebook, choose it as the environment engine for the notebook."}, {"metadata": {}, "cell_type": "markdown", "source": "Define the path to the folder with encrypted parquet files:"}, {"metadata": {}, "cell_type": "code", "source": "val encryptedParquetFullName = \"/tmp/bloodtests.parquet.encrypted\" // Change to your encrypted files path", "execution_count": 1, "outputs": [{"output_type": "display_data", "data": {"text/plain": "encryptedParquetFullName = /tmp/bloodtests.parquet.encrypted\n"}, "metadata": {}}, {"output_type": "execute_result", "execution_count": 1, "data": {"text/plain": "/tmp/bloodtests.parquet.encrypted"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "The application would manage the keys in the Key Management service. Enter the setup keys for Parquet Encryption in the following cell. To learn more about provision of the master keys, see the documentation [here](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-key-management-application)."}, {"metadata": {}, "cell_type": "code", "source": "sc.hadoopConfiguration.set(\"encryption.key.list\",\n      \"key1: AAECAwQFBgcICQoLDA0ODw==, key2: AAECAAECAAECAAECAAECAA==\") // Fill in your personal setup keys", "execution_count": 2, "outputs": [{"output_type": "display_data", "data": {"text/plain": "Waiting for a Spark session to start..."}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"cell1\"></a>\n## Generate the data"}, {"metadata": {}, "cell_type": "code", "source": "val dataRange = (1 to 40).toList\nval bloodTestList = dataRange.map(i => (i, (i * 2)))", "execution_count": 3, "outputs": [{"output_type": "display_data", "data": {"text/plain": "dataRange = List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40)\nbloodTestList = List((1,2), (2,4), (3,6), (4,8), (5,10), (6,12), (7,14), (8,16), (9,18), (10,20), (11,22), (12,24), (13,26), (14,28), (15,30), (16,32), (17,34), (18,36), (19,38), (20,40), (21,42), (22,44), (23,46), (24,48), (25,50), (26,52), (27,54), (28,56), (29,58), (30,60), (31,62), (32,64), (33,66), (34,68), (35,70), (36,72), (37,74), (38,76), (39,78), (40,80))\n"}, "metadata": {}}, {"output_type": "execute_result", "execution_count": 3, "data": {"text/plain": "List((1,2), (2,4), (3,6), (4,8), (5,10), (6,12), (7,14), (8,16), (9,18), (10,20), (11,22), (12,24), (13,26), (14,28), (15,30), (16,32), (17,34), (18,36), (19,38), (20,40), (21,42), (22,44), (23,46), (24,48), (25,50), (26,52), (27,54), (28,56), (29,58), (30,60), (31,62), (32,64), (33,66), (34,68), (35,70), (36,72), (37,74), (38,76), (39,78), (40,80))"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"cell2\"></a>\n## Write the encrypted data"}, {"metadata": {}, "cell_type": "markdown", "source": "Write the encrypted data with the following code."}, {"metadata": {}, "cell_type": "code", "source": "bloodTestList.toDF(\"id\", \"value\").write\n        // Configure which columns to encrypt with which keys\n      .option(\"encryption.column.keys\", \"key1: id\")\n      .option(\"encryption.footer.key\", \"key2\")\n      .mode(\"overwrite\").parquet(encryptedParquetFullName)", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"cell3\"></a>\n## Read the encrypted data"}, {"metadata": {}, "cell_type": "markdown", "source": "Read the actual encrypted data in its decrypted form with the following code."}, {"metadata": {}, "cell_type": "code", "source": "val encrypedDataDF = spark.read.parquet(encryptedParquetFullName)\nencrypedDataDF.createOrReplaceTempView(\"bloodtests\")\nval queryResult = spark.sql(\"SELECT id, value FROM bloodtests\")\nqueryResult.show(10, false)", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "Hive Session ID = de6e3c91-1a04-4b60-a7b4-da7226e5b266\n+---+-----+\n|id |value|\n+---+-----+\n|1  |2    |\n|2  |4    |\n|3  |6    |\n|4  |8    |\n|5  |10   |\n|6  |12   |\n|7  |14   |\n|8  |16   |\n|9  |18   |\n|10 |20   |\n+---+-----+\nonly showing top 10 rows\n\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "encrypedDataDF = [id: int, value: int]\nqueryResult = [id: int, value: int]\n"}, "metadata": {}}, {"output_type": "execute_result", "execution_count": 5, "data": {"text/plain": "[id: int, value: int]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Make sure files were written with parquet encryption (in encrypted footer mode):"}, {"metadata": {}, "cell_type": "code", "source": "import scala.sys.process._\nval parquetPartitionFile = Seq(\"hdfs\", \"dfs\", \"-ls\", \"-S\", \"-C\", encryptedParquetFullName).!!.split(\"\\\\s+\")(0)\nSeq(\"hdfs\", \"dfs\", \"-tail\", parquetPartitionFile) #| \"tail -c 4\" !", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "PARE", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "parquetPartitionFile = /tmp/bloodtests.parquet.encrypted/part-00000-dcf7f17a-3065-49b5-8aef-56422d4402b6-c000.snappy.parquet\n"}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "warning: there was one feature warning; re-run with -feature for details\n"}, "metadata": {}}, {"output_type": "execute_result", "execution_count": 6, "data": {"text/plain": "0"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "If you have done everything correctly, the output of the cell above should be <em>\"PARE\"</em>."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"summary\"></a>\n## Summary\n\nCongratulations! You have successfully completed this notebook and learned to associate a configured IAE to your notebook, and learned to read and write encrypted parquet files and learned more how to deal with the integrity and protection of sensitive data."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"authors\"></a>\n### Authors\n\n**Maya Anderson** is a Cloud Storage Researcher at IBM.  "}, {"metadata": {}, "cell_type": "markdown", "source": "Copyright \u00a9 2020 IBM. This notebook and its source code are released under the terms of the MIT License."}, {"metadata": {}, "cell_type": "markdown", "source": "<div style='background:#F5F7FA; height:110px; padding: 2em; font-size:14px;'>\n<span style='font-size:18px;color:#152935;'>Love this notebook? </span>\n<span style='font-size:15px;color:#152935;float:right;margin-right:40px;'>Don't have an account yet?</span><br>\n<span style='color:#5A6872;'>Share it with your colleagues and help them discover the power of Watson Studio!</span>\n<span style='border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;'><a href='https://ibm.co/wsnotebooks' target='_blank' style='color: #3d70b2;text-decoration: none;'>Sign Up</a></span><br>\n</div>"}], "metadata": {"kernelspec": {"name": "scala-spark23", "display_name": "Scala 2.11 with Spark 2.3 (YARN Client Mode)", "language": "scala"}, "language_info": {"mimetype": "text/x-scala", "name": "scala", "pygments_lexer": "scala", "version": "2.11.8", "file_extension": ".scala", "codemirror_mode": "text/x-scala"}}, "nbformat": 4, "nbformat_minor": 1}