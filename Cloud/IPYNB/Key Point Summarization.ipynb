{"cells":[{"cell_type":"markdown","metadata":{"id":"ecc90601-6af3-42d2-891c-f6e375feff5f"},"source":["# Key Point Summarization\n","## Extracting meaningful insights from reviews, surveys, and customer feedback\n","\n","When dealing with large collections of text representing people's opinions, such as product reviews, survey responses, customer feedback, or social media posts, understanding the key issues within the data can be challenging. Manually reviewing thousands of comments is time-consuming and cost-prohibitive.\n","Existing automated approaches often fall short, typically limited to identifying recurring phrases or concepts and gauging overall sentiment. While useful, these methods often fail to provide detailed, actionable insights.\n","Key Point Summarization maps the input texts to a set of automatically-extracted short sentences and phrases, termed Key Points, which provide a concise plain-text summary of the data. The prevalence of each key point may be quantified as the number of its matching sentences.\n","\n","In this tutorial, you will gain hands-on experience using Key Point Summarization (KPS) to analyze and derive insights from free-text feedback.\n","The data we will use is [a community survey conducted in the city of Austin](https://data.austintexas.gov/dataset/Community-Survey/s2py-ceb7). In this survey, the citizens of Austin were asked \"If there was ONE thing you could share with the Mayor regarding the City of Austin (any comment, suggestion, etc.), what would it be?\".\n","\n","KPS utilizes fine-tuned language models for data analysis. Therefore, an environment based on runtime 24.1 and with a GPU is required to run this tutorial effectively.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Learning goal\n","\n","The goal of this notebook is to demonstrate how Key Points Summarization can be used for extracting meaningful insights from reviews, surveys and customer feedback"]},{"cell_type":"markdown","metadata":{},"source":["## Contents\n","\n","This notebook contains the following parts:\n","\n","- [Initialization and data loading for analysis](#setup)\n","- [Examining and saving results](#exam)\n"]},{"cell_type":"markdown","metadata":{"id":"601c5872-b567-495f-b492-7a48db2a19d9"},"source":["<a id=\"setup\"></a>\n","## Initialization and data loading for analysis\n","First thing we need to do is run the KPS backend. This service runs in the background and performs the analysis."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4c5b65cf-e0a6-4086-8d0f-7111b0892576"},"outputs":[],"source":["from keypoint_matching.BackendRunnerWatsonStudio import BackendRunnerWatsonStudio\n","runner = BackendRunnerWatsonStudio()\n","runner.start_backend()"]},{"cell_type":"markdown","metadata":{"id":"96d20d28-cf9d-498f-a192-e08fcb59b90b"},"source":["Now we can create a client that connects to the backend and uses it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"32e75917-1e40-4b72-b303-ae51af9ed93a"},"outputs":[],"source":["from key_points_summarization_api.api.clients.keypoints_client import KpsClientWatsonStudio\n","client = KpsClientWatsonStudio()"]},{"cell_type":"markdown","metadata":{"id":"815ff146-2b7b-4102-b32d-ebe356ee6743"},"source":["Lets run self_check and make sure all is configured correctly and working.\n","self_check outputs\n","{'status': 'UP'} when all is working or {'status': 'DOWN'} if a problem is detected. We can also see if GPUs are used or not."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0957814b-b52f-4232-a5e5-97b35e9b2fcf"},"outputs":[],"source":["client.run_self_check()"]},{"cell_type":"markdown","metadata":{"id":"84f20062-ad75-440e-8209-f5c9b2370c09"},"source":["Let's read the data from dataset_austin.csv file, which holds the Austin survey dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2cc0da0d-34bc-4004-8ceb-c244063b43c0"},"outputs":[],"source":["import pandas as pd\n","\n","def get_comments_texts():\n","    url = \"https://raw.githubusercontent.com/IBMDataScience/sample-notebooks/master/Files/Data/dataset_austin.csv\"\n","    df = pd.read_csv(url)\n","    texts = [str(text) for text in df['text'].tolist()]\n","    texts = [text for text in texts if len(text)<3000]\n","    return texts"]},{"cell_type":"markdown","metadata":{"id":"144a740b-903d-4d17-9267-363a5b70cb05"},"source":["Let's first load the data into a list of strings and limit the number of comments for quick analysis:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ececd78a-01d9-4b69-b7da-68600bd174f7"},"outputs":[],"source":["texts = get_comments_texts()\n","print(f'There are {len(texts)} comments in the dataset')\n","\n","limit_comments = 500\n","texts = texts[:limit_comments]\n","print(f'Analysing {len(texts)} comments')"]},{"cell_type":"markdown","metadata":{"id":"9936bacf-6791-4c20-a250-817bd36bf7b7"},"source":["## Creating a summarization\n","We will now analyze the comments using the `client.run_full_kps_flow` method. This may take a little while. The more comments we have, the longer it will take.\n","\n","Comments are analyzed in the scope of a domain. The data is temporarily stored in a domain. \n","A user can create several domains, one for each dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b8181239-1589-44d3-aef3-082f653e93a3","scrolled":true},"outputs":[],"source":["domain = f'austin_test'  # describes the dataset\n","kps_result = client.run_full_kps_flow(domain, texts)"]},{"cell_type":"markdown","metadata":{"id":"f9942ebc-8232-45ac-a9a3-b029c99cd4db"},"source":["<a id=\"exam\"></a>\n","## Examining and saving results\n","Results are now available. Lets print a summary of the analysis."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5f270a18-b8c6-45dd-a84b-8a9da1bf50e0"},"outputs":[],"source":["kps_result.print_result(n_sentences_per_kp = 3, title = \"Austin sample\", n_top_kps = 40)"]},{"cell_type":"markdown","metadata":{"id":"13adfef5-dcc4-4395-9a0d-94b2467f9d73"},"source":["We can also export the results into files (summary file, full analysis, as well as a user-friendly DOCX report)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b269e8c9-0570-4362-b8db-bc694a3dcd42"},"outputs":[],"source":["import os\n","output_dir = f'./kps_results/{domain}/'\n","os.makedirs(output_dir, exist_ok = True)\n","kps_result.export_to_all_outputs(output_dir=output_dir, result_name=domain)\n","!ls -al {output_dir}"]},{"cell_type":"markdown","metadata":{"id":"eba54180-37f8-4287-8459-8037b2702679"},"source":["When we're done, we can stop the backend for a clean termination."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"790e6216-7300-445b-b0ee-1d950c1f4df1","scrolled":true},"outputs":[],"source":["runner.stop_backend()"]},{"cell_type":"markdown","metadata":{},"source":["### Authors:\n","**Yoav Katz**\n","**Roy Bar-Haim**\n","**Yoav Kantor**\n","**Lilach Edelstein**"]},{"cell_type":"markdown","metadata":{},"source":["Copyright Â© 2024 IBM. This notebook and its source code are released under the terms of the MIT License."]}],"metadata":{"kernelspec":{"display_name":"Python 3.11","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
