{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Use AutoAI and batch deployment to predict credit risk with Watson Machine Learning REST API"}, {"metadata": {}, "cell_type": "markdown", "source": "This notebook contains steps and code to demonstrate support of AutoAI experiments in Watson Machine Learning Service. It introduces commands for getting data, training experiments, persisting pipelines, publishing models, deploying models and scoring.\n\nSome familiarity with cURL is helpful. This notebook uses cURL examples.\n\n\n## Learning goals\n\nThe learning goals of this notebook are:\n\n-  Working with Watson Machine Learning experiments to train AutoAI models.\n-  Downloading computed models to local storage.\n-  Batch deployment and scoring of trained model.\n\n\n## Contents\n\nThis notebook contains the following parts:\n\n1. [Setup](#setup)  \n2. [Experiment definition](#experiment_definition)  \n3. [Experiment Run](#run)  \n4. [Historical runs](#runs)  \n5. [Deploy and Score](#deploy_and_score)  \n6. [Cleaning](#cleaning) \n7. [Summary and next steps](#summary)"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"setup\"></a>\n## 1. Set up the environment\n\nBefore you use the sample code in this notebook, you must perform the following setup tasks:\n\n-  Create a <a href=\"https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.ibm.com/docs/content/analyze-data/wml-setup.html\" target=\"_blank\" rel=\"noopener no referrer\">here</a>).\n-  Create a <a href=\"https://console.bluemix.net/catalog/infrastructure/cloud-object-storage\" target=\"_blank\" rel=\"noopener no referrer\">Cloud Object Storage (COS)</a> instance (a lite plan is offered and information about how to order storage can be found <a href=\"https://console.bluemix.net/docs/services/cloud-object-storage/basics/order-storage.html#order-storage\" target=\"_blank\" rel=\"noopener no referrer\">here</a>). <br/>**Note: When using Watson Studio, you already have a COS instance associated with the project you are running the notebook in.**"}, {"metadata": {}, "cell_type": "markdown", "source": "You can find your COS credentials in COS instance dashboard under the **Service credentials** tab.\nGo to the **Endpoint** tab in the COS instance's dashboard to get the endpoint information.\n\nAuthenticate the Watson Machine Learning service on IBM Cloud.\n\nYour Cloud API key can be generated by going to the [**Users** section of the Cloud console](https://cloud.ibm.com/iam#/users). From that page, click your name, scroll down to the **API Keys** section, and click **Create an IBM Cloud API key**. Give your key a name and click **Create**, then copy the created key and paste it below.  \n\n**NOTE:** You can also get service specific apikey by going to the [**Service IDs** section of the Cloud Console](https://cloud.ibm.com/iam/serviceids).  From that page, click **Create**, then copy the created key and paste it below.  \n\n**Action:** Fill below information to get started with this notebook.\n"}, {"metadata": {}, "cell_type": "code", "source": "%env API_KEY=...\n%env WML_ENDPOINT_URL=...\n%env WML_INSTANCE_CRN=\"fill out only if you want to create a new space\"\n%env WML_INSTANCE_NAME=...\n\n%env COS_CRN=\"fill out only if you want to create a new space\"\n%env COS_ENDPOINT=...\n%env COS_BUCKET=...\n%env COS_ACCESS_KEY_ID=...\n%env COS_SECRET_ACCESS_KEY=...\n%env COS_API_KEY=...\n\n%env SPACE_ID=\"fill out only if you have space already created\"\n\n%env DATAPLATFORM_URL=https://api.dataplatform.cloud.ibm.com   \n%env AUTH_ENDPOINT=https://iam.cloud.ibm.com/oidc/token", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"wml_token\"></a>\n### Getting WML authorization token for further cURL calls"}, {"metadata": {}, "cell_type": "markdown", "source": "<a href=\"https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-curl#curl-token\" target=\"_blank\" rel=\"noopener no referrer\">Example of cURL call to get WML token</a>"}, {"metadata": {}, "cell_type": "code", "source": "%%bash --out token\n\ncurl -sk -X POST \\\n    --header \"Content-Type: application/x-www-form-urlencoded\" \\\n    --header \"Accept: application/json\" \\\n    --data-urlencode \"grant_type=urn:ibm:params:oauth:grant-type:apikey\" \\\n    --data-urlencode \"apikey=$API_KEY\" \\\n    \"$AUTH_ENDPOINT\" \\\n    | cut -d '\"' -f 4", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%env TOKEN=$token ", "execution_count": 3, "outputs": [{"name": "stdout", "output_type": "stream", "text": "env: TOKEN=eyJraWQiOiIyMDIwMDgyMjE2NTYiLCJhbGciOiJSUzI1NiJ9.eyJpYW1faWQiOiJJQk1pZC01NTAwMDY3TkpEIiwiaWQiOiJJQk1pZC01NTAwMDY3TkpEIiwicmVhbG1pZCI6IklCTWlkIiwianRpIjoiMzZlNDlkY2YtYzA2Yy00YWVhLTkzOTAtMjAwMGY1NWYzZmQ2IiwiaWRlbnRpZmllciI6IjU1MDAwNjdOSkQiLCJnaXZlbl9uYW1lIjoiSmFuIiwiZmFtaWx5X25hbWUiOiJTb2x0eXNpayIsIm5hbWUiOiJKYW4gU29sdHlzaWsiLCJlbWFpbCI6Ikphbi5Tb2x0eXNpa0BpYm0uY29tIiwic3ViIjoiSmFuLlNvbHR5c2lrQGlibS5jb20iLCJhY2NvdW50Ijp7InZhbGlkIjp0cnVlLCJic3MiOiIxY2Y5ZjBlYjZhZjQ0NTlmOTQ3ODcxYmQzM2I0NzMxOCIsImZyb3plbiI6dHJ1ZX0sImlhdCI6MTU5ODQyNzk1OSwiZXhwIjoxNTk4NDMxNTU5LCJpc3MiOiJodHRwczovL2lhbS50ZXN0LmNsb3VkLmlibS5jb20vb2lkYy90b2tlbiIsImdyYW50X3R5cGUiOiJ1cm46aWJtOnBhcmFtczpvYXV0aDpncmFudC10eXBlOmFwaWtleSIsInNjb3BlIjoiaWJtIG9wZW5pZCIsImNsaWVudF9pZCI6ImRlZmF1bHQiLCJhY3IiOjEsImFtciI6WyJwd2QiXX0.GoCKPO7QWvDzS3B7ENUPhtJARE3ofME8BTAgPF_UF3-qriyz7OtDRZMjOzHFiBXG7bFWUovNDktsgVlCJOrgshYmxziob7qYjb9iWa7yYEnrJrYt0wdz5-HYBdkMQxukTTta69_RlMpotzLlwvc43Q0aanIHlSEzOIISbngVReh0nBCqtxSbT7VMucyJPZPdnsYhA3STox4Si8TdDDaGl49OFy0-VJQdf_k0M6t3IYahc8lYEFXSE0BYCZH5JXLQwIfOK1GnFKAThlBe7h2u7mH_AI_pjt5yh0Ku3UZ85cv_xPC3E11fbhQpnh_qugnukzRuNwT4TAvQe9yxHatF-w\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"space_creation\"></a>\n### Space creation\n**Tip:** If you do not have `space` already created, please convert below three cells to `code` and run them.\n\nFirst of all, you need to create a `space` that will be used in all of your further cURL calls. \nIf you do not have `space` already created, below is the cURL call to create one."}, {"metadata": {}, "cell_type": "markdown", "source": "<a href=\"https://cpd-spaces-api.eu-gb.cf.appdomain.cloud/#/Spaces/spaces_create\" \ntarget=\"_blank\" rel=\"noopener no referrer\">Space creation</a>"}, {"metadata": {}, "cell_type": "raw", "source": "%%bash --out space_id\n\ncurl -sk -X POST \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    --data '{\"name\": \"curl_DL\", \"storage\": {\"type\": \"bmcos_object_storage\", \"resource_crn\": \"'\"$COS_CRN\"'\"}, \"compute\": [{\"name\": \"'\"$WML_INSTANCE_NAME\"'\", \"crn\": \"'\"$WML_INSTANCE_CRN\"'\", \"type\": \"machine_learning\"}]}' \\\n    \"$DATAPLATFORM_URL/v2/spaces\" \\\n     | grep '\"id\": ' | awk -F '\"' '{ print $4 }'"}, {"metadata": {}, "cell_type": "raw", "source": "space_id = space_id.split('\\n')[1]\n%env SPACE_ID=$space_id"}, {"metadata": {}, "cell_type": "markdown", "source": "Space creation is asynchronous. This means that you need to check space creation status after creation call.\nMake sure that your newly created space is `active`."}, {"metadata": {}, "cell_type": "markdown", "source": "<a href=\"https://cpd-spaces-api.eu-gb.cf.appdomain.cloud/#/Spaces/spaces_get\" \ntarget=\"_blank\" rel=\"noopener no referrer\">Get space information</a>"}, {"metadata": {}, "cell_type": "raw", "source": "%%bash\n\n!curl -sk -X GET \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    \"$DATAPLATFORM_URL/v2/spaces/$SPACE_ID\""}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"experiment_definition\"></a>\n## 2. Experiment / optimizer configuration\n\nProvide input information for AutoAI experiment / optimizer:\n- `name` - experiment name\n- `learning_type` - type of the problem\n- `label` - target column name\n- `scorer_for_ranking` - optimization metric\n- `holdout_param` - percentage of training data to use as a holdout [0 - 1]\n- `daub_include_only_estimators` - list of estimators to use"}, {"metadata": {}, "cell_type": "markdown", "source": "You can modify `parameters` section of the following cURL call to change AutoAI experiment settings."}, {"metadata": {}, "cell_type": "code", "source": "%%bash --out pipeline_payload\n\nPIPELINE_PAYLOAD='{\"space_id\": \"'\"$SPACE_ID\"'\", \"name\": \"Credit Risk Prediction - AutoAI\", \"description\": \"\", \"document\": {\"doc_type\": \"pipeline\", \"version\": \"2.0\", \"pipelines\": [{\"id\": \"autoai\", \"runtime_ref\": \"hybrid\", \"nodes\": [{\"id\": \"automl\", \"type\": \"execution_node\", \"parameters\": {\"stage_flag\": true, \"output_logs\": true, \"input_file_separator\": \",\", \"optimization\": {\"learning_type\": \"binary\", \"label\": \"Risk\", \"max_num_daub_ensembles\": 1, \"daub_include_only_estimators\": [\"ExtraTreesClassifierEstimator\", \"GradientBoostingClassifierEstimator\", \"LGBMClassifierEstimator\", \"LogisticRegressionEstimator\", \"RandomForestClassifierEstimator\", \"XGBClassifierEstimator\", \"DecisionTreeClassifierEstimator\"], \"scorer_for_ranking\": \"roc_auc\", \"compute_pipeline_notebooks_flag\": true, \"run_cognito_flag\": true, \"holdout_param\": 0.1}}, \"runtime_ref\": \"autoai\", \"op\": \"kube\"}]}], \"runtimes\": [{\"id\": \"autoai\", \"name\": \"auto_ai.kb\", \"app_data\": {\"wml_data\": {\"hardware_spec\": { \"name\": \"L\"}}}, \"version\": \"3.0.2\"}],\"primary_pipeline\": \"autoai\"}}'\necho $PIPELINE_PAYLOAD | python -m json.tool", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%env PIPELINE_PAYLOAD=$pipeline_payload", "execution_count": 5, "outputs": [{"name": "stdout", "output_type": "stream", "text": "env: PIPELINE_PAYLOAD={\n    \"space_id\": \"74133c06-dce2-4dfc-b913-2e0dc8efc750\",\n    \"name\": \"Credit Risk Prediction - AutoAI\",\n    \"description\": \"\",\n    \"document\": {\n        \"doc_type\": \"pipeline\",\n        \"version\": \"2.0\",\n        \"pipelines\": [\n            {\n                \"id\": \"autoai\",\n                \"runtime_ref\": \"hybrid\",\n                \"nodes\": [\n                    {\n                        \"id\": \"automl\",\n                        \"type\": \"execution_node\",\n                        \"parameters\": {\n                            \"stage_flag\": true,\n                            \"output_logs\": true,\n                            \"input_file_separator\": \",\",\n                            \"optimization\": {\n                                \"learning_type\": \"binary\",\n                                \"label\": \"Risk\",\n                                \"max_num_daub_ensembles\": 1,\n                                \"daub_include_only_estimators\": [\n                                    \"ExtraTreesClassifierEstimator\",\n                                    \"GradientBoostingClassifierEstimator\",\n                                    \"LGBMClassifierEstimator\",\n                                    \"LogisticRegressionEstimator\",\n                                    \"RandomForestClassifierEstimator\",\n                                    \"XGBClassifierEstimator\",\n                                    \"DecisionTreeClassifierEstimator\"\n                                ],\n                                \"scorer_for_ranking\": \"roc_auc\",\n                                \"compute_pipeline_notebooks_flag\": true,\n                                \"run_cognito_flag\": true,\n                                \"holdout_param\": 0.1\n                            }\n                        },\n                        \"runtime_ref\": \"autoai\",\n                        \"op\": \"kube\"\n                    }\n                ]\n            }\n        ],\n        \"runtimes\": [\n            {\n                \"id\": \"autoai\",\n                \"name\": \"auto_ai.kb\",\n                \"app_data\": {\n                    \"wml_data\": {\n                        \"hardware_spec\": {\n                            \"name\": \"L\"\n                        }\n                    }\n                },\n                \"version\": \"3.0.2\"\n            }\n        ],\n        \"primary_pipeline\": \"autoai\"\n    }\n}\n"}]}, {"metadata": {}, "cell_type": "code", "source": "%%bash --out pipeline_id\n\ncurl -sk -X POST \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    --data \"$PIPELINE_PAYLOAD\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/pipelines?version=2020-08-01\" \\\n    | grep '\"id\": ' | awk -F '\"' '{ print $4 }' | sed -n 5p", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%env PIPELINE_ID=$pipeline_id", "execution_count": 7, "outputs": [{"name": "stdout", "output_type": "stream", "text": "env: PIPELINE_ID=0becfea7-83b0-4e98-9d5c-0c9eddec367e\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"experiment_details\"></a>\n### Get experiment details\nTo retrieve AutoAI experiment / optimizer configuration you can follow below cURL GET call."}, {"metadata": {}, "cell_type": "code", "source": "%%bash\n\ncurl -sk -X GET \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/pipelines/$PIPELINE_ID?space_id=$SPACE_ID&version=2020-08-01\" \\\n    | python -m json.tool", "execution_count": 8, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{\n    \"entity\": {\n        \"document\": {\n            \"doc_type\": \"pipeline\",\n            \"pipelines\": [\n                {\n                    \"id\": \"autoai\",\n                    \"nodes\": [\n                        {\n                            \"id\": \"automl\",\n                            \"op\": \"kube\",\n                            \"parameters\": {\n                                \"input_file_separator\": \",\",\n                                \"optimization\": {\n                                    \"compute_pipeline_notebooks_flag\": true,\n                                    \"daub_include_only_estimators\": [\n                                        \"ExtraTreesClassifierEstimator\",\n                                        \"GradientBoostingClassifierEstimator\",\n                                        \"LGBMClassifierEstimator\",\n                                        \"LogisticRegressionEstimator\",\n                                        \"RandomForestClassifierEstimator\",\n                                        \"XGBClassifierEstimator\",\n                                        \"DecisionTreeClassifierEstimator\"\n                                    ],\n                                    \"holdout_param\": 0.1,\n                                    \"label\": \"Risk\",\n                                    \"learning_type\": \"binary\",\n                                    \"max_num_daub_ensembles\": 1.0,\n                                    \"run_cognito_flag\": true,\n                                    \"scorer_for_ranking\": \"roc_auc\"\n                                },\n                                \"output_logs\": true,\n                                \"stage_flag\": true\n                            },\n                            \"runtime_ref\": \"autoai\",\n                            \"type\": \"execution_node\"\n                        }\n                    ],\n                    \"runtime_ref\": \"hybrid\"\n                }\n            ],\n            \"primary_pipeline\": \"autoai\",\n            \"runtimes\": [\n                {\n                    \"app_data\": {\n                        \"wml_data\": {\n                            \"hardware_spec\": {\n                                \"id\": \"a6c4923b-b8e4-444c-9f43-8a7ec3020110\",\n                                \"name\": \"L\"\n                            }\n                        }\n                    },\n                    \"id\": \"autoai\",\n                    \"name\": \"auto_ai.kb\",\n                    \"version\": \"3.0.2\"\n                }\n            ],\n            \"version\": \"2.0\"\n        }\n    },\n    \"metadata\": {\n        \"created_at\": \"2020-08-26T07:47:31.900Z\",\n        \"id\": \"0becfea7-83b0-4e98-9d5c-0c9eddec367e\",\n        \"modified_at\": \"2020-08-26T07:47:31.900Z\",\n        \"name\": \"Credit Risk Prediction - AutoAI\",\n        \"owner\": \"IBMid-5500067NJD\",\n        \"space_id\": \"74133c06-dce2-4dfc-b913-2e0dc8efc750\"\n    }\n}\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"training_connection\"></a>\n### Training data connection\n\nDefine connection information to COS bucket and training data CSV file. This example uses the German Credit Risk dataset. \n\nThe dataset can be downloaded from [here](https://github.com/IBM/watson-machine-learning-samples/raw/master/data/credit_risk/credit_risk_training_light.csv ). You can also download it to local filesystem by running the cell below.\n\n**Action**: Upload training data to COS bucket and enter location information in the next cURL examples."}, {"metadata": {}, "cell_type": "code", "source": "%%bash\n\nwget https://github.com/IBM/watson-machine-learning-samples/raw/master/data/credit_risk/credit_risk_training_light.csv \\\n     -O credit_risk_training_light.csv", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"cos_token\"></a>\n### Get COS token\nRetrieve COS token for further authentication calls."}, {"metadata": {}, "cell_type": "code", "source": "%%bash --out cos_token\n\ncurl -s -X \"POST\" \"$AUTH_ENDPOINT\" \\\n     -H 'Accept: application/json' \\\n     -H 'Content-Type: application/x-www-form-urlencoded' \\\n     --data-urlencode \"apikey=$COS_API_KEY\" \\\n     --data-urlencode \"response_type=cloud_iam\" \\\n     --data-urlencode \"grant_type=urn:ibm:params:oauth:grant-type:apikey\" \\\n     | cut -d '\"' -f 4", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%env COS_TOKEN=$cos_token", "execution_count": 10, "outputs": [{"name": "stdout", "output_type": "stream", "text": "env: COS_TOKEN=eyJraWQiOiIyMDIwMDgyMjE2NTYiLCJhbGciOiJSUzI1NiJ9.eyJpYW1faWQiOiJpYW0tU2VydmljZUlkLWExNDFmNWNlLWVlZmYtNDU5Ny1iZTgyLTg3MTA1NTBhMjdjMyIsImlkIjoiaWFtLVNlcnZpY2VJZC1hMTQxZjVjZS1lZWZmLTQ1OTctYmU4Mi04NzEwNTUwYTI3YzMiLCJyZWFsbWlkIjoiaWFtIiwianRpIjoiYzE0ZTE4NGUtYjM3Zi00ZDJmLWFkZWMtOWQ0NzRjZTJlZWQ0IiwiaWRlbnRpZmllciI6IlNlcnZpY2VJZC1hMTQxZjVjZS1lZWZmLTQ1OTctYmU4Mi04NzEwNTUwYTI3YzMiLCJuYW1lIjoiV0RQLVByb2plY3QtTWFuYWdlbWVudC1jODcxMGM1YS00YjM4LTRlMGYtYWQ3NC03MDM4Yzk4MTJjYzYiLCJzdWIiOiJTZXJ2aWNlSWQtYTE0MWY1Y2UtZWVmZi00NTk3LWJlODItODcxMDU1MGEyN2MzIiwic3ViX3R5cGUiOiJTZXJ2aWNlSWQiLCJhY2NvdW50Ijp7InZhbGlkIjp0cnVlLCJic3MiOiIxY2Y5ZjBlYjZhZjQ0NTlmOTQ3ODcxYmQzM2I0NzMxOCIsImZyb3plbiI6dHJ1ZX0sImlhdCI6MTU5ODQyODA2MCwiZXhwIjoxNTk4NDMxNjYwLCJpc3MiOiJodHRwczovL2lhbS50ZXN0LmNsb3VkLmlibS5jb20vb2lkYy90b2tlbiIsImdyYW50X3R5cGUiOiJ1cm46aWJtOnBhcmFtczpvYXV0aDpncmFudC10eXBlOmFwaWtleSIsInNjb3BlIjoiaWJtIG9wZW5pZCIsImNsaWVudF9pZCI6ImRlZmF1bHQiLCJhY3IiOjEsImFtciI6WyJwd2QiXX0.Ov0BxnBGmXYJM9-oAHsHd2iYrfmnS8j-NJZPSeb5S3EwpgxRS__Ah50GW5JnfhYxQaf1zuAaTD04Yd-Ena9yV2UPRzqK6tp6PpE7vu8Vs2XZ_0ZbwopjWVcc5FR2AxeGHG-g2QSHAZcKwLQ1WjaPwrnnxDOGGGv1ZOal_0nNifl-4kzROAHQ0lF6qAaqCLXluv8O-xvqOXnKfe7hSQyb_Yr6n9sAr6r7gGNKHi3q5ylfj-CdftSC5De9YfrI7FygX26fq-l_umLhzin8MiBP2pt_SgK-68eOtc4ylH2rGxYlWADIaWAcCvBGWrt1H9GxmmWX9O8gGV26GM7IfzNpuQ\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"cos_upload\"></a>\n### Upload file to COS\nUpload your local dataset into your COS bucket"}, {"metadata": {}, "cell_type": "code", "source": "%%bash\n\ncurl -sk -X PUT \\\n    --header \"Authorization: Bearer $COS_TOKEN\" \\\n    --header \"Content-Type: application/octet-stream\" \\\n    --data-binary \"@credit_risk_training_light.csv\" \\\n    \"$COS_ENDPOINT/$COS_BUCKET/credit_risk_training_light.csv\"", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "There should be an empty response when upload finished succesfully."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"run\"></a>\n## 3. Experiment run\n\nThis section provides samples about how to trigger AutoAI experiment via cURL calls."}, {"metadata": {}, "cell_type": "code", "source": "%%bash --out training_payload\n\nTRAINING_PAYLOAD='{\"space_id\": \"'\"$SPACE_ID\"'\", \"training_data_references\": [{\"type\": \"s3\", \"id\": \"credit_risk_training_light.csv\", \"connection\": {\"endpoint_url\": \"'\"$COS_ENDPOINT\"'\", \"access_key_id\": \"'\"$COS_ACCESS_KEY_ID\"'\", \"secret_access_key\": \"'\"$COS_SECRET_ACCESS_KEY\"'\"}, \"location\": {\"bucket\": \"'\"$COS_BUCKET\"'\", \"path\": \"credit_risk_training_light.csv\"}}], \"results_reference\": {\"type\": \"s3\", \"id\": \"autoai_results\", \"connection\": {\"endpoint_url\": \"'\"$COS_ENDPOINT\"'\", \"access_key_id\": \"'\"$COS_ACCESS_KEY_ID\"'\", \"secret_access_key\": \"'\"$COS_SECRET_ACCESS_KEY\"'\"}, \"location\": {\"bucket\": \"'\"$COS_BUCKET\"'\", \"path\": \".\"}}, \"tags\": [{\"value\": \"autoai\"}], \"pipeline\": {\"href\": \"/v4/pipelines/'\"$PIPELINE_ID\"'\"}}'\necho $TRAINING_PAYLOAD | python -m json.tool", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%env TRAINING_PAYLOAD=$training_payload", "execution_count": 13, "outputs": [{"name": "stdout", "output_type": "stream", "text": "env: TRAINING_PAYLOAD={\n    \"space_id\": \"74133c06-dce2-4dfc-b913-2e0dc8efc750\",\n    \"training_data_references\": [\n        {\n            \"type\": \"s3\",\n            \"id\": \"credit_risk_training_light.csv\",\n            \"connection\": {\n                \"endpoint_url\": \"https://s3.us-west.cloud-object-storage.test.appdomain.cloud\",\n                \"access_key_id\": \"***\",\n                \"secret_access_key\": \"***\"\n            },\n            \"location\": {\n                \"bucket\": \"js-bucket\",\n                \"path\": \"credit_risk_training_light.csv\"\n            }\n        }\n    ],\n    \"results_reference\": {\n        \"type\": \"s3\",\n        \"id\": \"autoai_results\",\n        \"connection\": {\n            \"endpoint_url\": \"https://s3.us-west.cloud-object-storage.test.appdomain.cloud\",\n            \"access_key_id\": \"***\",\n            \"secret_access_key\": \"***\"\n        },\n        \"location\": {\n            \"bucket\": \"js-bucket\",\n            \"path\": \".\"\n        }\n    },\n    \"tags\": [\n        {\n            \"value\": \"autoai\"\n        }\n    ],\n    \"pipeline\": {\n        \"href\": \"/v4/pipelines/0becfea7-83b0-4e98-9d5c-0c9eddec367e\"\n    }\n}\n"}]}, {"metadata": {}, "cell_type": "code", "source": "%%bash --out training_id\n\ncurl -sk -X POST \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    --data \"$TRAINING_PAYLOAD\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/trainings?version=2020-08-01\" \\\n    | awk -F'\"id\":' '{print $2}' | cut -c2-37", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%env TRAINING_ID=$training_id", "execution_count": 15, "outputs": [{"name": "stdout", "output_type": "stream", "text": "env: TRAINING_ID=98ef6520-0924-42dd-9998-fc787f7ac6d1\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"training_details\"></a>\n### Get training details\nTraining is an asynchronous endpoint. In case you want to monitor training status and details,\nyou need to use a GET method and specify which training you want to monitor by usage of training ID."}, {"metadata": {}, "cell_type": "code", "source": "%%bash\n\ncurl -sk -X GET \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/trainings/$TRAINING_ID?space_id=$SPACE_ID&version=2020-08-01\" \\\n    | python -m json.tool", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Get training status"}, {"metadata": {}, "cell_type": "code", "source": "%%bash\n\nSTATUS=$(curl -sk -X GET\\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/trainings/$TRAINING_ID?space_id=$SPACE_ID&version=2020-08-01\")\n    \nSTATUS=${STATUS#*state\\\":\\\"}\nSTATUS=${STATUS%%\\\"*}\necho $STATUS", "execution_count": 18, "outputs": [{"name": "stdout", "output_type": "stream", "text": "completed\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Please make sure that training is completed before you go to the next sections.\nMonitor `state` of your training by running above cell couple of times."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"download_model\"></a>\n### Get selected pipeline model\n\nDownload a scikit-learn pipeline model object from the\nAutoAI training job.\nAs all of the trained pipeline models are stored in specified user COS bucket, you can download selected model\nvia COS UI or via following cURL call.\nPlease have in mind, that you need to specify COS bucket and model location in that bucket.\nThis information can be retrieved from the previous call output (GET treining) under:\n- entity -- status -- metrics  -- specific list entry -- intermediate_model -- location -- model"}, {"metadata": {}, "cell_type": "code", "source": "%%bash --out model_path\n\nPATH=$(curl -sk -X GET \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/trainings/$TRAINING_ID?space_id=$SPACE_ID&version=2020-08-01\")\n\n\nPATH=${PATH#*model\\\":\\\"}\nMODEL_PATH=${PATH%%\\\"*}\necho $MODEL_PATH", "execution_count": 19, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%env MODEL_PATH=$model_path", "execution_count": 20, "outputs": [{"name": "stdout", "output_type": "stream", "text": "env: MODEL_PATH=./98ef6520-0924-42dd-9998-fc787f7ac6d1/data/automl/pre_hpo_d_output/Pipeline1/model.pickle\n"}]}, {"metadata": {}, "cell_type": "code", "source": "%%bash\n\ncurl -sk -X GET \\\n    --header \"Authorization: Bearer $COS_TOKEN\" \\\n    --output \"model.pickle\" \\\n    \"$COS_ENDPOINT/$COS_BUCKET/$MODEL_PATH\"", "execution_count": 21, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "If everything went right, you should be able to see your model under specified local path."}, {"metadata": {}, "cell_type": "code", "source": "!ls -l model.pickle", "execution_count": 22, "outputs": [{"name": "stdout", "output_type": "stream", "text": "-rw-r--r--  1 jansoltysik  staff  106522 Aug 26 09:54 model.pickle\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"runs\"></a>\n## 4. Historical runs\n\nIn this section you will see cURL examples describing how to get historical training runs information."}, {"metadata": {}, "cell_type": "markdown", "source": "Output should be similar to the output from training creation but you should see more trainings entries.  \nListing trainings:"}, {"metadata": {}, "cell_type": "code", "source": "%%bash\n\nHISTORICAL_TRAINING_LIMIT_TO_GET=2\n\ncurl -sk -X GET \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/trainings?space_id=$SPACE_ID&version=2020-08-01&limit=$HISTORICAL_TRAINING_LIMIT_TO_GET\" \\\n    | python -m json.tool", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"training_cancel\"></a>\n### Cancel training run\n\n**Tip:** If you want to cancel your training, please convert below cell to `code`, specify training ID and run."}, {"metadata": {}, "cell_type": "raw", "source": "%%bash\n\nTRAINING_ID_TO_CANCEL=...\n\ncurl -sk -X DELETE \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/trainings/$TRAINING_ID_TO_CANCEL?space_id=$SPACE_ID&version=2020-08-01\""}, {"metadata": {}, "cell_type": "markdown", "source": "---"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"deploy_and_score\"></a>\n## 5. Deploy and Score\n\nIn this section you will learn how to deploy and score pipeline model as webservice using WML instance."}, {"metadata": {}, "cell_type": "markdown", "source": "Before deployment creation, you need store your model in WML repository.\nPlease see below cURL call example how to do it. Remember that you need to\nspecify where your chosen model is stored in COS."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"files_preparation\"></a>\n### Files preparation\n\nDownload all needed files (model.pickle, pipeline-model.json and schema.json) from COS.  \n<a href=\"https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-curl#curl-get-object\" \ntarget=\"_blank\" rel=\"noopener no referrer\">Download file from COS</a>"}, {"metadata": {}, "cell_type": "code", "source": "%%bash\n\ncurl -sk -X GET \\\n    --header \"Authorization: Bearer $COS_TOKEN\" \\\n    --output \"model.pickle\" \\\n    \"$COS_ENDPOINT/$COS_BUCKET/$MODEL_PATH\"", "execution_count": 24, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Along with pipeline model, there is also a json file stored with experiment information.  \nIt will be needed during model repository store action."}, {"metadata": {}, "cell_type": "code", "source": "%%bash --out pipeline_model_json_path\n\nPATH=$(curl -sk -X GET \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/trainings/$TRAINING_ID?space_id=$SPACE_ID&version=2020-08-01\")\n    \nPATH=${PATH#*pipeline_model\\\":\\\"}\nPIPELINE_MODEL_PATH=${PATH%%\\\"*}\necho $PIPELINE_MODEL_PATH", "execution_count": 25, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%env PIPELINE_MODEL_JSON_PATH=$pipeline_model_json_path", "execution_count": 26, "outputs": [{"name": "stdout", "output_type": "stream", "text": "env: PIPELINE_MODEL_JSON_PATH=./98ef6520-0924-42dd-9998-fc787f7ac6d1/data/automl/pre_hpo_d_output/Pipeline1/pipeline-model.json\n"}]}, {"metadata": {}, "cell_type": "code", "source": "%%bash\n\ncurl -sk -X GET \\\n    --header \"Authorization: Bearer $COS_TOKEN\" \\\n    --output \"pipeline-model.json\" \\\n    \"$COS_ENDPOINT/$COS_BUCKET/$PIPELINE_MODEL_JSON_PATH\"", "execution_count": 27, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%%bash\n\ntar -czvf model.pickle.tar.gz model.pickle", "execution_count": 28, "outputs": [{"name": "stderr", "output_type": "stream", "text": "a model.pickle\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Prepare compressed file with model and experiment information."}, {"metadata": {}, "cell_type": "code", "source": "!ls -l model*", "execution_count": 29, "outputs": [{"name": "stdout", "output_type": "stream", "text": "-rw-r--r--  1 jansoltysik  staff  106522 Aug 26 09:54 model.pickle\n-rw-r--r--  1 jansoltysik  staff   27482 Aug 26 09:54 model.pickle.tar.gz\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"model_store\"></a>\n### Store AutoAI model\n\nStore information about your model to WML repository.\nYou can take model schema from downloaded `schema.json` from COS."}, {"metadata": {}, "cell_type": "code", "source": "%%bash --out model_payload\n\nMODEL_PAYLOAD='{\"space_id\": \"'\"$SPACE_ID\"'\",\"name\": \"autoai_credit_risk_model\",\"description\": \"This is description\",\"type\": \"wml-hybrid_0.1\", \"software_spec\": {\"name\": \"hybrid_0.1\"}}'\necho $MODEL_PAYLOAD | python -m json.tool", "execution_count": 30, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%env MODEL_PAYLOAD=$model_payload", "execution_count": 31, "outputs": [{"name": "stdout", "output_type": "stream", "text": "env: MODEL_PAYLOAD={\n    \"space_id\": \"74133c06-dce2-4dfc-b913-2e0dc8efc750\",\n    \"name\": \"autoai_credit_risk_model\",\n    \"description\": \"This is description\",\n    \"type\": \"wml-hybrid_0.1\",\n    \"software_spec\": {\n        \"name\": \"hybrid_0.1\"\n    }\n}\n"}]}, {"metadata": {}, "cell_type": "code", "source": "%%bash --out model_id\n\ncurl -sk -X POST \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    --data \"$MODEL_PAYLOAD\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/models?version=2020-08-01\" \\\n    | grep '\"id\": ' | awk -F '\"' '{ print $4 }' | sed -n 2p", "execution_count": 32, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%env MODEL_ID=$model_id", "execution_count": 33, "outputs": [{"name": "stdout", "output_type": "stream", "text": "env: MODEL_ID=2d55a846-4a38-422f-8878-5b2334812b60\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"model_content_upload\"></a>\n### Upload model content\n\nNow you need to upload your model content into the WML repository."}, {"metadata": {}, "cell_type": "code", "source": "%%bash\n\ncurl -sk -X PUT \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    --data-binary \"@pipeline-model.json\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/models/$MODEL_ID/content?space_id=$SPACE_ID&version=2020-08-01&content_format=native\" \\\n    | python -m json.tool", "execution_count": 34, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{\n    \"attachment_id\": \"e3c706e6-7aa3-42db-b76f-48d1ebd97cf8\",\n    \"content_format\": \"native\",\n    \"persisted\": true\n}\n"}]}, {"metadata": {}, "cell_type": "code", "source": "%%bash\n\ncurl -sk -X PUT \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/gzip\" \\\n    --header \"Accept: application/json\" \\\n    --data-binary \"@model.pickle.tar.gz\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/models/$MODEL_ID/content?version=2020-08-01&space_id=$SPACE_ID&content_format=pipeline-node&pipeline_node_id=automl\" \\\n    | python -m json.tool", "execution_count": 35, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{\n    \"attachment_id\": \"3f5a7040-5cd2-449a-99e2-ffa90b85786c\",\n    \"content_format\": \"pipeline-node\",\n    \"persisted\": true,\n    \"pipeline_node_id\": \"automl\"\n}\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"model_content_download\"></a>\n### Download model content\n\nIf you want to download your saved model, please make the following call."}, {"metadata": {}, "cell_type": "code", "source": "%%bash\n\ncurl -sk -X GET \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --output \"model.tar.gz\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/models/$MODEL_ID/download?space_id=$SPACE_ID&version=2020-08-01\"", "execution_count": 36, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "!ls -l model.tar.gz", "execution_count": 37, "outputs": [{"name": "stdout", "output_type": "stream", "text": "-rw-r--r--  1 jansoltysik  staff  297 Aug 26 09:55 model.tar.gz\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## <a id=\"deployment_creation\"></a>\n### Deployment creation\n\nAn AutoAI Batch deployment creation is presented below."}, {"metadata": {}, "cell_type": "code", "source": "%%bash --out deployment_payload\n\nDFEPLOYMENT_PAYLOAD='{\"space_id\": \"'\"$SPACE_ID\"'\",\"name\": \"AutoAI deployment\",\"description\": \"This is description\",\"batch\": {}, \"hybrid_pipeline_hardware_specs\": [{\"node_runtime_id\": \"auto_ai.kb\", \"hardware_spec\": {\"name\": \"M\"}}],\"asset\": {\"id\": \"'\"$MODEL_ID\"'\"}}'\necho $DFEPLOYMENT_PAYLOAD | python -m json.tool", "execution_count": 38, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%env DFEPLOYMENT_PAYLOAD=$deployment_payload", "execution_count": 39, "outputs": [{"name": "stdout", "output_type": "stream", "text": "env: DFEPLOYMENT_PAYLOAD={\n    \"space_id\": \"74133c06-dce2-4dfc-b913-2e0dc8efc750\",\n    \"name\": \"AutoAI deployment\",\n    \"description\": \"This is description\",\n    \"batch\": {},\n    \"hybrid_pipeline_hardware_specs\": [\n        {\n            \"node_runtime_id\": \"auto_ai.kb\",\n            \"hardware_spec\": {\n                \"name\": \"M\"\n            }\n        }\n    ],\n    \"asset\": {\n        \"id\": \"2d55a846-4a38-422f-8878-5b2334812b60\"\n    }\n}\n"}]}, {"metadata": {}, "cell_type": "code", "source": "%%bash --out deployment_id\n\ncurl -sk -X POST \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    --data \"$DFEPLOYMENT_PAYLOAD\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/deployments?version=2020-08-01\" | grep '\"id\": ' | awk -F '\"' '{ print $4 }' | sed -n 2p", "execution_count": 40, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%env DEPLOYMENT_ID=$deployment_id", "execution_count": 41, "outputs": [{"name": "stdout", "output_type": "stream", "text": "env: DEPLOYMENT_ID=72061cab-7eac-4afb-98f8-72aeed130f06\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"deployment_details\"></a>\n### Get deployment details\nAs deployment API is asynchronous, please make sure your deployment is in `ready` state before going to the next points."}, {"metadata": {}, "cell_type": "code", "source": "%%bash\n\ncurl -sk -X GET \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/deployments/$DEPLOYMENT_ID?space_id=$SPACE_ID&version=2020-08-01\" \\\n    | python -m json.tool", "execution_count": 42, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{\n    \"entity\": {\n        \"asset\": {\n            \"id\": \"2d55a846-4a38-422f-8878-5b2334812b60\"\n        },\n        \"batch\": {},\n        \"custom\": {},\n        \"description\": \"This is description\",\n        \"hybrid_pipeline_hardware_specs\": [\n            {\n                \"hardware_spec\": {\n                    \"name\": \"M\"\n                },\n                \"node_runtime_id\": \"auto_ai.kb\"\n            }\n        ],\n        \"name\": \"AutoAI deployment\",\n        \"space_id\": \"74133c06-dce2-4dfc-b913-2e0dc8efc750\",\n        \"status\": {\n            \"state\": \"ready\"\n        }\n    },\n    \"metadata\": {\n        \"created_at\": \"2020-08-26T07:55:17.053Z\",\n        \"description\": \"This is description\",\n        \"id\": \"72061cab-7eac-4afb-98f8-72aeed130f06\",\n        \"modified_at\": \"2020-08-26T07:55:17.053Z\",\n        \"name\": \"AutoAI deployment\",\n        \"owner\": \"IBMid-5500067NJD\",\n        \"space_id\": \"74133c06-dce2-4dfc-b913-2e0dc8efc750\"\n    }\n}\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"batch_score\"></a>\n### Score your Batch deployment\nScoring for Batch deployment is done by creating `jobs`. User can specify job payload as a json or as data connection to eg. COS."}, {"metadata": {}, "cell_type": "code", "source": "%%bash --out job_payload\n\nJOB_PAYLOAD='{\"name\": \"AutoAI job\", \"space_id\": \"'\"$SPACE_ID\"'\",\"deployment\": {\"id\": \"'\"$DEPLOYMENT_ID\"'\"}, \"hybrid_pipeline_hardware_specs\": [{\"node_runtime_id\": \"auto_ai.kb\", \"hardware_spec\": {\"name\": \"M\"}}], \"scoring\": {\"input_data\": [{\"fields\": [\"CheckingStatus\", \"LoanDuration\", \"CreditHistory\", \"LoanPurpose\", \"LoanAmount\", \"ExistingSavings\", \"EmploymentDuration\", \"InstallmentPercent\", \"Sex\", \"OthersOnLoan\", \"CurrentResidenceDuration\", \"OwnsProperty\", \"Age\", \"InstallmentPlans\", \"Housing\", \"ExistingCreditsCount\", \"Job\", \"Dependents\", \"Telephone\", \"ForeignWorker\"], \"values\": [[\"less_0\", 6, \"all_credits_paid_back\", \"car_used\", 250, \"less_100\", \"1_to_4\", 2, \"male\", \"none\", 2, \"savings_insurance\", 28, \"stores\", \"rent\", 1, \"skilled\", 1, \"none\", \"yes\"]]}]}}'\necho $JOB_PAYLOAD | python -m json.tool", "execution_count": 43, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%env JOB_PAYLOAD=$job_payload", "execution_count": 44, "outputs": [{"name": "stdout", "output_type": "stream", "text": "env: JOB_DEPLOYMENT={\n    \"name\": \"AutoAI job\",\n    \"space_id\": \"74133c06-dce2-4dfc-b913-2e0dc8efc750\",\n    \"deployment\": {\n        \"id\": \"72061cab-7eac-4afb-98f8-72aeed130f06\"\n    },\n    \"hybrid_pipeline_hardware_specs\": [\n        {\n            \"node_runtime_id\": \"auto_ai.kb\",\n            \"hardware_spec\": {\n                \"name\": \"M\"\n            }\n        }\n    ],\n    \"scoring\": {\n        \"input_data\": [\n            {\n                \"fields\": [\n                    \"CheckingStatus\",\n                    \"LoanDuration\",\n                    \"CreditHistory\",\n                    \"LoanPurpose\",\n                    \"LoanAmount\",\n                    \"ExistingSavings\",\n                    \"EmploymentDuration\",\n                    \"InstallmentPercent\",\n                    \"Sex\",\n                    \"OthersOnLoan\",\n                    \"CurrentResidenceDuration\",\n                    \"OwnsProperty\",\n                    \"Age\",\n                    \"InstallmentPlans\",\n                    \"Housing\",\n                    \"ExistingCreditsCount\",\n                    \"Job\",\n                    \"Dependents\",\n                    \"Telephone\",\n                    \"ForeignWorker\"\n                ],\n                \"values\": [\n                    [\n                        \"less_0\",\n                        6,\n                        \"all_credits_paid_back\",\n                        \"car_used\",\n                        250,\n                        \"less_100\",\n                        \"1_to_4\",\n                        2,\n                        \"male\",\n                        \"none\",\n                        2,\n                        \"savings_insurance\",\n                        28,\n                        \"stores\",\n                        \"rent\",\n                        1,\n                        \"skilled\",\n                        1,\n                        \"none\",\n                        \"yes\"\n                    ]\n                ]\n            }\n        ]\n    }\n}\n"}]}, {"metadata": {}, "cell_type": "code", "source": "%%bash --out job_id\n\ncurl -sk -X POST \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    --data \"$JOB_PAYLOAD\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/deployment_jobs?version=2020-08-01\" \\\n    | grep '\"id\": ' | awk -F '\"' '{ print $4 }' | sed -n 2p", "execution_count": 45, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%env JOB_ID=$job_id", "execution_count": 46, "outputs": [{"name": "stdout", "output_type": "stream", "text": "env: JOB_ID=12e0c105-9cc4-4195-ba4a-74acc89dfaa5\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"job_list\"></a>\n### Listing all Batch jobs"}, {"metadata": {}, "cell_type": "code", "source": "%%bash\n\ncurl -sk -X GET \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/deployment_jobs?space_id=$SPACE_ID&version=2020-08-01\" \\\n    | python -m json.tool", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"job_get\"></a>\n### Get particular job details"}, {"metadata": {}, "cell_type": "code", "source": "%%bash\n\ncurl -sk -X GET \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/deployment_jobs/$JOB_ID?space_id=$SPACE_ID&version=2020-08-01\" \\\n    | python -m json.tool", "execution_count": 50, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{\n    \"entity\": {\n        \"deployment\": {\n            \"id\": \"72061cab-7eac-4afb-98f8-72aeed130f06\"\n        },\n        \"scoring\": {\n            \"input_data\": [\n                {\n                    \"fields\": [\n                        \"CheckingStatus\",\n                        \"LoanDuration\",\n                        \"CreditHistory\",\n                        \"LoanPurpose\",\n                        \"LoanAmount\",\n                        \"ExistingSavings\",\n                        \"EmploymentDuration\",\n                        \"InstallmentPercent\",\n                        \"Sex\",\n                        \"OthersOnLoan\",\n                        \"CurrentResidenceDuration\",\n                        \"OwnsProperty\",\n                        \"Age\",\n                        \"InstallmentPlans\",\n                        \"Housing\",\n                        \"ExistingCreditsCount\",\n                        \"Job\",\n                        \"Dependents\",\n                        \"Telephone\",\n                        \"ForeignWorker\"\n                    ],\n                    \"values\": [\n                        [\n                            \"less_0\",\n                            6,\n                            \"all_credits_paid_back\",\n                            \"car_used\",\n                            250,\n                            \"less_100\",\n                            \"1_to_4\",\n                            2,\n                            \"male\",\n                            \"none\",\n                            2,\n                            \"savings_insurance\",\n                            28,\n                            \"stores\",\n                            \"rent\",\n                            1,\n                            \"skilled\",\n                            1,\n                            \"none\",\n                            \"yes\"\n                        ]\n                    ]\n                }\n            ],\n            \"predictions\": [\n                {\n                    \"fields\": [\n                        \"prediction\",\n                        \"probability\"\n                    ],\n                    \"values\": [\n                        [\n                            \"Risk\",\n                            [\n                                0.3,\n                                0.7\n                            ]\n                        ]\n                    ]\n                }\n            ],\n            \"status\": {\n                \"completed_at\": \"2020-08-26T07:57:19.000Z\",\n                \"running_at\": \"2020-08-26T07:57:06.000Z\",\n                \"state\": \"completed\"\n            }\n        }\n    },\n    \"metadata\": {\n        \"created_at\": \"2020-08-26T07:55:32.675Z\",\n        \"id\": \"12e0c105-9cc4-4195-ba4a-74acc89dfaa5\",\n        \"modified_at\": \"2020-08-26T07:57:20.537Z\",\n        \"name\": \"AutoAI job\",\n        \"space_id\": \"74133c06-dce2-4dfc-b913-2e0dc8efc750\"\n    }\n}\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"job_cancel\"></a>\n### Cancel job\n\n**Tip:** You can cancel running job by calling delete method.\nJust convert below cell to `code` and run it."}, {"metadata": {}, "cell_type": "raw", "source": "%%bash\n\ncurl -sk -X DELETE \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/deployment_jobs/$JOB_ID?space_id=$SPACE_ID&version=2020-08-01\""}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"deployments_list\"></a>\n### Listing all deployments"}, {"metadata": {}, "cell_type": "code", "source": "%%bash\n\ncurl -sk -X GET \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/deployments?space_id=$SPACE_ID&version=2020-08-01\" \\\n    | python -m json.tool", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"cleaning\"></a>\n## 6. Cleaning section\n\nBelow section is useful when you want to clean all of your previous work within this notebook.\nJust convert below cells into the `code` and run them."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"training_delete\"></a>\n### Delete training run\n**Tip:** You can completely delete a training run with its metadata."}, {"metadata": {}, "cell_type": "raw", "source": "%%bash\n\n%env TRAINING_ID_TO_DELETE=...\n\ncurl -sk -X DELETE \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/trainings/$TRAINING_ID_TO_DELETE?space_id=$SPACE_ID&version=2020-08-01&hard_delete=true\""}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"job_delete\"></a>\n### Delete job\n\n**Tip:** If you want remove job completely (with metadata), just specify `hard_delete` to True."}, {"metadata": {}, "cell_type": "raw", "source": "%%bash\n\ncurl -sk -X DELETE \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/deployment_jobs/$JOB_ID?space_id=$SPACE_ID&version=2020-08-01&hard_delete=true\""}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"deployment_delete\"></a>\n### Deleting deployment\n**Tip:** You can delete existing deployment by calling DELETE method."}, {"metadata": {}, "cell_type": "raw", "source": "%%bash\n\ncurl -sk -X DELETE \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Accept: application/json\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/deployments/$DEPLOYMENT_ID?space_id=$SPACE_ID&version=2020-08-01\""}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"model_delete\"></a>\n### Delete model from repository\n**Tip:** If you want to completely remove your stored model and model metadata, just use a DELETE method."}, {"metadata": {}, "cell_type": "raw", "source": "%%bash\n\ncurl -sk -X DELETE \\\n    --header \"Authorization: Bearer $TOKEN\" \\\n    --header \"Content-Type: application/json\" \\\n    \"$WML_ENDPOINT_URL/ml/v4/models/$MODEL_ID?space_id=$SPACE_ID&version=2020-08-01\""}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"summary\"></a>\n## 7. Summary and next steps\n\n You successfully completed this notebook!.\n \n You learned how to use `cURL` calls to store, deploy and score a AutoAI model in WML. \n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Authors\n\n**Amadeusz Masny**, Python Software Developer in Watson Machine Learning at IBM  \n**Jan So\u0142tysik**, Intern in Watson Machine Learning at IBM"}, {"metadata": {}, "cell_type": "markdown", "source": "Copyright \u00a9 2020 IBM. This notebook and its source code are released under the terms of the MIT License."}, {"metadata": {}, "cell_type": "markdown", "source": "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.biz/cpd-signup\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n</div>"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}