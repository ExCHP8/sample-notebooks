{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Use SPSS and batch deployment with DB2 to predict customer churn with `ibm-watson-machine-learning`"}, {"metadata": {"tags": []}, "cell_type": "markdown", "source": "This notebook contains steps to deploy a sample SPSS stream and start batch scoring new data. \n\nSome familiarity with bash is helpful. This notebook uses Python 3.8.\n\nYou will use a data set, **Telco Customer Churn**, which details anonymous customer data from a telecommunication company. Use the details of this data set to predict customer churn. This is critical to business, as it's easier to retain existing customers than acquire new ones.\n\n## Learning goals\n\nThe learning goals of this notebook are:\n\n-  Loading a CSV file into Db2 on Cloud \n-  Working with the Watson Machine Learning instance\n-  Batch deployment of an SPSS model\n-  Scoring data using deployed model and a Db2 connection\n\n\n## Contents\n\nThis notebook contains the following parts:\n\n1.\t[Setup](#setup)\n2.\t[Model upload](#upload) \n3.  [Create db2 connection](#connection)\n4.\t[Web service creation](#deploy)\n5.\t[Scoring](#score)\n6.  [Clean up](#cleanup)\n7.\t[Summary and next steps](#summary)"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"setup\"></a>\n## 1. Set up the environment\n\nBefore you use the sample code in this notebook, create a <a href=\"https://cloud.ibm.com/catalog/services/watson-machine-learning\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/admin/create-services.html?context=cpdaas&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)."}, {"metadata": {}, "cell_type": "markdown", "source": "### Connection to WML\n\nAuthenticate the Watson Machine Learning service on IBM Cloud. You need to provide platform `api_key` and instance `location`.\n\nYou can use [IBM Cloud CLI](https://cloud.ibm.com/docs/cli/index.html) to retrieve platform API Key and instance location.\n\nAPI Key can be generated in the following way:\n```\nibmcloud login\nibmcloud iam api-key-create API_KEY_NAME\n```\n\nIn result, get the value of `api_key` from the output.\n\n\nLocation of your WML instance can be retrieved in the following way:\n```\nibmcloud login --apikey API_KEY -a https://cloud.ibm.com\nibmcloud resource service-instance WML_INSTANCE_NAME\n```\n\nIn result, get the value of `location` from the output."}, {"metadata": {}, "cell_type": "markdown", "source": "**Tip**: You can generate your `Cloud API key` by going to the [**Users** section of the Cloud console](https://cloud.ibm.com/iam#/users). From that page, click your name, scroll down to the **API Keys** section, and click **Create an IBM Cloud API key**. Give your key a name and click **Create**, then copy the created key and paste it below.\n\nYou can also get the service-specific url by going to the [**Endpoint URLs** section of the Watson Machine Learning docs](https://cloud.ibm.com/apidocs/machine-learning).\nYou can check your instance location in your  <a href=\"https://cloud.ibm.com/catalog/services/watson-machine-learning\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance details.\n\nYou can also get service specific apikey by going to the [**Service IDs** section of the Cloud Console](https://cloud.ibm.com/iam/serviceids).  From that page, click **Create**, then copy the created key and paste it below.\n\n**Action**: Enter your `api_key` and `location` in the following cell."}, {"metadata": {}, "cell_type": "code", "source": "api_key = 'PASTE YOUR PLATFORM API KEY HERE'\nlocation = 'PASTE YOUR INSTANCE LOCATION HERE'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "wml_credentials = {\n    \"apikey\": api_key,\n    \"url\": 'https://' + location + '.ml.cloud.ibm.com'\n}", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Install and import the `ibm-watson-machine-learning` package\n**Note:** `ibm-watson-machine-learning` documentation can be found <a href=\"http://ibm-wml-api-pyclient.mybluemix.net/\" target=\"_blank\" rel=\"noopener no referrer\">here</a>."}, {"metadata": {}, "cell_type": "code", "source": "!pip install -U ibm-watson-machine-learning", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning import APIClient\n\nclient = APIClient(wml_credentials)", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Working with spaces\n\nFirst, create a space that will be used for your work. If you do not have a space, you can use [Deployment Spaces Dashboard](https://dataplatform.cloud.ibm.com/ml-runtime/spaces?context=cpdaas) to create one.\n\n- Click New Deployment Space\n- Create an empty space\n- Select Cloud Object Storage\n- Select Watson Machine Learning instance and press Create\n- Copy `space_id` and paste it below\n\n**Tip**: You can also use SDK to prepare the space for your work. More information can be found [here](https://github.com/IBM/watson-machine-learning-samples/blob/master/cloud/notebooks/python_sdk/instance-management/Space%20management.ipynb).\n\n**Action**: Assign space ID below"}, {"metadata": {}, "cell_type": "code", "source": "space_id = 'PASTE YOUR SPACE ID HERE'", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "You can use `list` method to print all existing spaces."}, {"metadata": {}, "cell_type": "code", "source": "client.spaces.list(limit=10)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "To be able to interact with all resources available in Watson Machine Learning, you need to set **space** which you will be using."}, {"metadata": {}, "cell_type": "code", "source": "client.set.default_space(space_id)", "execution_count": 4, "outputs": [{"data": {"text/plain": "'SUCCESS'"}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"upload\"></a>\n## 2. Upload model\n\nIn this section you will learn how to upload the model to the Cloud.\n\n\n**Action**: Download sample SPSS model from git project using wget."}, {"metadata": {}, "cell_type": "code", "source": "import os\nfrom wget import download\n\nsample_dir = 'spss_sample_model'\nif not os.path.isdir(sample_dir):\n    os.mkdir(sample_dir)\n\nfilename=os.path.join(sample_dir, 'db2-customer-satisfaction-prediction.str')\nif not os.path.isfile(filename):\n    filename = download('https://github.com/IBM/watson-machine-learning-samples/raw/master/cloud/models/spss/db2_customer_satisfaction/model/db2-customer-satisfaction-prediction.str',\\\n                             out=sample_dir)\nprint(filename)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Store SPSS sample model in your Watson Machine Learning instance."}, {"metadata": {}, "cell_type": "code", "source": "client.software_specifications.list()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "sw_spec_uid = client.software_specifications.get_uid_by_name(\"spss-modeler_18.2\")\n\nmodel_meta_props = {\n    client.repository.ModelMetaNames.NAME: \"SPSS customer satisfaction model\",\n    client.repository.ModelMetaNames.TYPE: \"spss-modeler_18.2\",\n    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: sw_spec_uid\n}\n\nmodel_details = client.repository.store_model(filename, model_meta_props)", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "**Note:** You can see that model is successfully stored in Watson Machine Learning Service."}, {"metadata": {}, "cell_type": "code", "source": "client.repository.list_models()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"connection\"></a>\n## 3. Create a Db2 connection\nYou can use commands below to create a db2 connection and required data assets to perform batch scoring."}, {"metadata": {}, "cell_type": "markdown", "source": "### Create tables in Db2 on Cloud\n\n - Download the [inputScore.csv](https://github.com/IBM/watson-machine-learning-samples/raw/master/cloud/data/customer_churn/scoreInput.csv) and [inputScore2.csv](https://github.com/IBM/watson-machine-learning-samples/raw/master/cloud/data/customer_churn/scoreInput2.csv) file from the GitHub repository\n - Click the **Open the console to get started with Db2 on Cloud** icon.\n - Select the **Load Data** and **Desktop** load type.\n - Drag and drop the previously downloaded file and click Next.\n - Set table name to **CUSTOMER** and proceed with creating."}, {"metadata": {}, "cell_type": "markdown", "source": "#### Create a connection"}, {"metadata": {}, "cell_type": "code", "source": "schema_name = 'PUT YOUR SCHEMA NAME HERE'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "db_name = 'db2'\ninput_table_1 = 'CUSTOMER'\ninput_table_2 = 'CUSTOMER_2'\noutput_table = 'OUTPUT'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "db_credentials = {\n      \"db\": \"***\",\n      \"host\": \"***\",\n      \"https_url\": \"***\",\n      \"password\": \"***\",\n      \"port\": \"***\",\n      \"username\": \"***\"\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "db2_data_source_type_id = client.connections.get_datasource_type_uid_by_name(db_name)\n\ndb2_conn_meta_props= {\n    client.connections.ConfigurationMetaNames.NAME: \"conn_db2\",\n    client.connections.ConfigurationMetaNames.DATASOURCE_TYPE: db2_data_source_type_id,\n    client.connections.ConfigurationMetaNames.DESCRIPTION: \"Connection using DB2\",\n    client.connections.ConfigurationMetaNames.PROPERTIES: {\n        \"database\": db_credentials[\"db\"],\n        \"port\": db_credentials[\"port\"],          \n        \"host\": db_credentials[\"host\"],\n        \"password\": db_credentials[\"password\"],\n        \"username\": db_credentials[\"username\"]\n    }\n}\n\ndb2_conn_details = client.connections.create(meta_props=db2_conn_meta_props)", "execution_count": 8, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Creating connections...\nSUCCESS\n"}]}, {"metadata": {}, "cell_type": "code", "source": "db2_conn_id = client.connections.get_uid(db2_conn_details)", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Create input connection data asset"}, {"metadata": {}, "cell_type": "code", "source": "db2_asset_meta_props={\n            client.data_assets.ConfigurationMetaNames.NAME: \"INPUT_TABLE_1\",\n            client.data_assets.ConfigurationMetaNames.CONNECTION_ID: db2_conn_id,\n            client.data_assets.ConfigurationMetaNames.DESCRIPTION: \"db2 table\",\n            client.data_assets.ConfigurationMetaNames.DATA_CONTENT_NAME: input_table_1 }\n\ndb2_conn_input_asset_details = client.data_assets.store(db2_asset_meta_props)  \ninput_data_1_href = client.data_assets.get_href(db2_conn_input_asset_details)", "execution_count": 10, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Creating data asset...\nSUCCESS\n"}]}, {"metadata": {}, "cell_type": "code", "source": "db2_asset_meta_props={\n            client.data_assets.ConfigurationMetaNames.NAME: \"INPUT_TABLE_2\",\n            client.data_assets.ConfigurationMetaNames.CONNECTION_ID: db2_conn_id,\n            client.data_assets.ConfigurationMetaNames.DESCRIPTION: \"db2 table\",\n            client.data_assets.ConfigurationMetaNames.DATA_CONTENT_NAME: input_table_2 }\n\ndb2_conn_input_asset_details = client.data_assets.store(db2_asset_meta_props)  \ninput_data_2_href = client.data_assets.get_href(db2_conn_input_asset_details)", "execution_count": 11, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Creating data asset...\nSUCCESS\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Create output connection data assets"}, {"metadata": {}, "cell_type": "code", "source": "db2_asset_meta_props={\n            client.data_assets.ConfigurationMetaNames.NAME: \"OUTPUT_TABLE\",\n            client.data_assets.ConfigurationMetaNames.CONNECTION_ID: db2_conn_id,\n            client.data_assets.ConfigurationMetaNames.DESCRIPTION: \"db2 table\",\n            client.data_assets.ConfigurationMetaNames.DATA_CONTENT_NAME: output_table }\n\ndb2_conn_output_asset_details = client.data_assets.store(db2_asset_meta_props)  \noutput_data_href = client.data_assets.get_href(db2_conn_output_asset_details)", "execution_count": 12, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Creating data asset...\nSUCCESS\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"deploy\"></a>\n## 4. Create batch deployment\nUse bellow  to create batch deployment for stored model."}, {"metadata": {}, "cell_type": "code", "source": "model_uid = client.repository.get_model_uid(model_details)\n\ndeployment = client.deployments.create(\n    artifact_uid=model_uid,\n    meta_props={\n        client.deployments.ConfigurationMetaNames.NAME: \"SPSS BATCH customer satisfaction\",\n        client.deployments.ConfigurationMetaNames.BATCH: {},\n        client.deployments.ConfigurationMetaNames.HARDWARE_SPEC: {\n            \"name\": \"S\",\n            \"num_nodes\": 1\n        }\n    }\n)", "execution_count": 13, "outputs": [{"name": "stdout", "output_type": "stream", "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: 'b5f984cb-9b46-4884-aa9b-1541efab1faf' started\n\n#######################################################################################\n\n\nready.\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='7ca37c54-19ab-4632-a191-625b3da3c898'\n------------------------------------------------------------------------------------------------\n\n\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"score\"></a>\n## 5. Scoring\n\nYou can create batch job using below methods."}, {"metadata": {}, "cell_type": "markdown", "source": "### 5.1 Scoring using `data_asset` pointing to the DB2."}, {"metadata": {}, "cell_type": "code", "source": "job_payload_ref = {\n    client.deployments.ScoringMetaNames.INPUT_DATA_REFERENCES: [\n        {\n            \"id\": \"conn_db2\",\n            \"name\": \"input_data_1_href\",\n            \"type\": \"data_asset\",\n            \"connection\": {},\n            \"location\": {\n                \"href\": input_data_1_href\n            }\n        },\n        {\n            \"id\": \"conn_db2\",\n            \"name\": \"input_data_2_href\",\n            \"type\": \"data_asset\",\n            \"connection\": {},\n            \"location\": {\n                \"href\": input_data_2_href\n            }\n        }\n    ],\n    client.deployments.ScoringMetaNames.OUTPUT_DATA_REFERENCE: {\n            \"type\": \"data_asset\",\n            \"connection\": {},\n            \"location\": {\n                \"href\": output_data_href\n            }\n    }\n}\n\ndeployment_uid = client.deployments.get_uid(deployment)\njob = client.deployments.create_job(deployment_uid, meta_props=job_payload_ref)", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "You can retrive job ID."}, {"metadata": {}, "cell_type": "code", "source": "job_id = client.deployments.get_job_uid(job)", "execution_count": 15, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "##### Monitor job execution\n\nHere you can check the status of your batch scoring. When batch job is completed the results will be written to a Db2 table."}, {"metadata": {"execution": {"iopub.execute_input": "2021-05-13T08:25:47.637114Z", "iopub.status.busy": "2021-05-13T08:25:47.636298Z", "iopub.status.idle": "2021-05-13T08:26:19.041818Z", "shell.execute_reply": "2021-05-13T08:26:19.042556Z"}}, "cell_type": "code", "source": "import time\n\nelapsed_time = 0\nwhile client.deployments.get_job_status(job_id).get('state') != 'completed' and elapsed_time < 300:\n    print(f\" Current state: {client.deployments.get_job_status(job_id).get('state')}\")\n    elapsed_time += 10\n    time.sleep(10)\nif client.deployments.get_job_status(job_id).get('state') == 'completed':\n    print(f\" Current state: {client.deployments.get_job_status(job_id).get('state')}\")\n    job_details_do = client.deployments.get_job_details(job_id)\n    print(job_details_do)\nelse:\n    print(\"Job hasn't completed successfully in 5 minutes.\")", "execution_count": 21, "outputs": [{"name": "stdout", "output_type": "stream", "text": " Current state: queued\n Current state: running\n Current state: completed\n{'entity': {'deployment': {'id': 'ac0dfe9a-6c98-4eeb-967b-120f9234b0e5'}, 'platform_job': {'job_id': 'bfcf37c5-d190-49bd-abca-fb22116323f5', 'run_id': '361b151b-c5f6-48dc-ae1d-776642c9a692'}, 'scoring': {'input_data_references': [{'connection': {}, 'id': 'conn_db2', 'location': {'href': '/v2/assets/04f74392-0b89-4ca6-baa1-157e4295bd8b?space_id=680a7515-620c-461f-9c6f-1f4c535bfc47'}, 'type': 'data_asset'}, {'connection': {}, 'id': 'conn_db2', 'location': {'href': '/v2/assets/d1e1c2eb-d0eb-430f-8707-f948c0b37ba2?space_id=680a7515-620c-461f-9c6f-1f4c535bfc47'}, 'type': 'data_asset'}], 'output_data_reference': {'connection': {}, 'location': {'href': '/v2/assets/8009a976-1218-42b7-81fc-39b77ec225cd?space_id=680a7515-620c-461f-9c6f-1f4c535bfc47'}, 'type': 'data_asset'}, 'status': {'completed_at': '2021-05-13T08:26:06.058Z', 'running_at': '2021-05-13T08:25:58.434Z', 'state': 'completed'}}}, 'metadata': {'created_at': '2021-05-13T08:25:47.071Z', 'id': 'a5d0e0b3-62c5-41f4-879b-41702e16b185', 'modified_at': '2021-05-13T08:26:06.191Z', 'name': 'name_d68b05fd-7866-4a48-af56-235eb3f03809', 'space_id': '680a7515-620c-461f-9c6f-1f4c535bfc47'}}\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### 5.2 Scoring using `connection_asset` poiniting to the DB2"}, {"metadata": {}, "cell_type": "code", "source": "job_payload_ref = {\n    client.deployments.ScoringMetaNames.INPUT_DATA_REFERENCES: [\n        {\n            \"id\": \"conn_db2\",\n            \"name\": \"input_table_1\",\n            \"type\": \"connection_asset\",\n            \"connection\": {\n                \"id\": db2_conn_id\n            },\n            \"location\": {\n                \"schema_name\": schema_name,\n                \"file_name\": input_table_1\n            }\n        },\n        {\n            \"id\": \"conn_db2\",\n            \"name\": \"input_table_2\",\n            \"type\": \"connection_asset\",\n            \"connection\": {\n                \"id\": db2_conn_id\n            },\n            \"location\": {\n                \"schema_name\": schema_name,\n                \"file_name\": input_table_2\n            }\n        }\n    ],\n    client.deployments.ScoringMetaNames.OUTPUT_DATA_REFERENCE: {\n            \"id\": \"conn_db2\",\n            \"name\": \"output_table\",\n            \"type\": \"connection_asset\",\n            \"connection\": {\n                \"id\": db2_conn_id\n            },\n            \"location\": {\n                \"schema_name\": schema_name,\n                \"file_name\": output_table\n            }\n    }\n}\n\ndeployment_uid = client.deployments.get_uid(deployment)\njob = client.deployments.create_job(deployment_uid, meta_props=job_payload_ref)", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Retrive job ID."}, {"metadata": {}, "cell_type": "code", "source": "job_id = client.deployments.get_job_uid(job)", "execution_count": 15, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "##### Monitor job execution"}, {"metadata": {"execution": {"iopub.execute_input": "2021-05-13T08:26:24.268310Z", "iopub.status.busy": "2021-05-13T08:26:24.267448Z", "iopub.status.idle": "2021-05-13T08:26:55.683936Z", "shell.execute_reply": "2021-05-13T08:26:55.684562Z"}}, "cell_type": "code", "source": "import time\n\nelapsed_time = 0\nwhile client.deployments.get_job_status(job_id).get('state') != 'completed' and elapsed_time < 300:\n    print(f\" Current state: {client.deployments.get_job_status(job_id).get('state')}\")\n    elapsed_time += 10\n    time.sleep(10)\nif client.deployments.get_job_status(job_id).get('state') == 'completed':\n    print(f\" Current state: {client.deployments.get_job_status(job_id).get('state')}\")\n    job_details_do = client.deployments.get_job_details(job_id)\n    print(job_details_do)\nelse:\n    print(\"Job hasn't completed successfully in 5 minutes.\")", "execution_count": 24, "outputs": [{"name": "stdout", "output_type": "stream", "text": " Current state: queued\n Current state: running\n Current state: completed\n{'entity': {'deployment': {'id': 'ac0dfe9a-6c98-4eeb-967b-120f9234b0e5'}, 'platform_job': {'job_id': 'bfcf37c5-d190-49bd-abca-fb22116323f5', 'run_id': '4d83ddcb-88ca-45ca-8209-446698936b8d'}, 'scoring': {'input_data_references': [{'connection': {'id': 'ae2a374b-85fd-4823-b6f5-95f11662324f'}, 'id': 'conn_db2', 'location': {'file_name': 'CUSTOMER', 'schema_name': 'PUT YOUR SCHEMA NAME HERE'}, 'type': 'connection_asset'}, {'connection': {'id': 'ae2a374b-85fd-4823-b6f5-95f11662324f'}, 'id': 'conn_db2', 'location': {'file_name': 'CUSTOMER_2', 'schema_name': 'PUT YOUR SCHEMA NAME HERE'}, 'type': 'connection_asset'}], 'output_data_reference': {'connection': {'id': 'ae2a374b-85fd-4823-b6f5-95f11662324f'}, 'id': 'conn_db2', 'location': {'file_name': 'OUTPUT', 'schema_name': 'PUT YOUR SCHEMA NAME HERE'}, 'type': 'connection_asset'}, 'status': {'completed_at': '2021-05-13T08:26:43.422Z', 'running_at': '2021-05-13T08:26:35.279Z', 'state': 'completed'}}}, 'metadata': {'created_at': '2021-05-13T08:26:23.663Z', 'id': '77973aa5-fbd0-41b8-9012-a4e2016a57dc', 'modified_at': '2021-05-13T08:26:43.622Z', 'name': 'name_3dc38b68-0227-4422-b7eb-b9bdd3f72d95', 'space_id': '680a7515-620c-461f-9c6f-1f4c535bfc47'}}\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Preview scored data\n\nIn this subsection you will load scored data."}, {"metadata": {}, "cell_type": "markdown", "source": "**Tip**: To install `requests` execute the following command: `!pip install requests`"}, {"metadata": {}, "cell_type": "code", "source": "import requests", "execution_count": 19, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "host = db_credentials[\"https_url\"] + \"/dbapi/v3\"\n\nurl = host + \"/auth/tokens\"\ntoken = requests.post(url, json={\n                             \"userid\": db_credentials[\"username\"],\n                             \"password\": db_credentials[\"password\"]}).json()['token']", "execution_count": 20, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "##### Get stored output using Db2 REST API"}, {"metadata": {}, "cell_type": "code", "source": "auth_header = {\n    \"Authorization\": f\"Bearer {token}\"\n}\n\nsql_command = {\n    \"commands\": \"SELECT * FROM OUTPUT\",\n    \"limit\": 100,\n    \"separator\": \",\",\n    \"stop_on_error\": \"yes\"\n}", "execution_count": 21, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "url = host + \"/sql_jobs\"\njobid = requests.post(url, headers=auth_header, json=sql_command).json()['id']", "execution_count": 22, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "resp = requests.get(f\"{url}/{jobid}\", headers=auth_header)\n\nresults = resp.json()[\"results\"][0]\ncolumns = results[\"columns\"]\nrows = results[\"rows\"]", "execution_count": 23, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "##### Preview output using pandas DateFrame\n\n**Tip**: To install `pandas` execute following command: `!pip install pandas`"}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd\n\npd.DataFrame(data=rows, columns=columns)", "execution_count": 24, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customerID</th>\n      <th>Churn</th>\n      <th>Predicted Churn</th>\n      <th>Probability of Churn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9237-HQITU</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>0.8829830706957551</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3638-WEABW</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.0526309571556145</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8665-UTDHZ</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>0.17411004057470159</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8773-HHUOZ</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>0.48432324905415836</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4080-IIARD</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.0920141258229612</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6575-SUVOI</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.0920919392791626</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7495-OOKFY</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>0.9721495250458333</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0731-EBJQB</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.09059837844121355</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1891-QRQSA</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.09210273951918213</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>5919-TMRGD</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>0.8942276923073484</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>9364-YKUVW</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.08573913673013789</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>7563-BIUPC</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>0.878469673954569</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>4183-MYFRB</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.41029784048995666</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>5729-KLZAR</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>0.9589057770843653</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>9102-OXKFY</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.0920128511710483</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>6078-VESFR</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.25027748128974314</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>9979-RGMZT</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.08438119760083618</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1965-DDBWU</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>0.24591107604601636</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>7159-NOKYQ</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.008693015730152798</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>6778-YSNIH</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.04730024365943297</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "    customerID Churn Predicted Churn  Probability of Churn\n0   9237-HQITU   Yes             Yes    0.8829830706957551\n1   3638-WEABW    No              No    0.0526309571556145\n2   8665-UTDHZ   Yes              No   0.17411004057470159\n3   8773-HHUOZ   Yes              No   0.48432324905415836\n4   4080-IIARD    No              No    0.0920141258229612\n5   6575-SUVOI    No              No    0.0920919392791626\n6   7495-OOKFY   Yes             Yes    0.9721495250458333\n7   0731-EBJQB    No              No   0.09059837844121355\n8   1891-QRQSA    No              No   0.09210273951918213\n9   5919-TMRGD   Yes             Yes    0.8942276923073484\n10  9364-YKUVW    No              No   0.08573913673013789\n11  7563-BIUPC   Yes             Yes     0.878469673954569\n12  4183-MYFRB    No              No   0.41029784048995666\n13  5729-KLZAR   Yes             Yes    0.9589057770843653\n14  9102-OXKFY    No              No    0.0920128511710483\n15  6078-VESFR    No              No   0.25027748128974314\n16  9979-RGMZT    No              No   0.08438119760083618\n17  1965-DDBWU   Yes              No   0.24591107604601636\n18  7159-NOKYQ    No              No  0.008693015730152798\n19  6778-YSNIH    No              No   0.04730024365943297"}, "execution_count": 24, "metadata": {}, "output_type": "execute_result"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"cleanup\"></a>\n## 6. Clean up   "}, {"metadata": {}, "cell_type": "markdown", "source": "If you want to clean up all created assets:\n- experiments\n- trainings\n- pipelines\n- model definitions\n- models\n- functions\n- deployments\n\nsee the steps in this sample [notebook](https://github.com/IBM/watson-machine-learning-samples/blob/master/cloud/notebooks/python_sdk/instance-management/Machine%20Learning%20artifacts%20management.ipynb)."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"summary\"></a>\n## 7. Summary and next steps     "}, {"metadata": {}, "cell_type": "markdown", "source": " You successfully completed this notebook! You learned how to use Watson Machine Learning for SPSS model deployment and scoring. Check out our [Online Documentation](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-service-instance.html?context=analytics) for more samples, tutorials, documentation, how-tos, and blog posts. "}, {"metadata": {}, "cell_type": "markdown", "source": "### Author\n\n**Jan So\u0142tysik** Intern in Watson Machine Learning."}, {"metadata": {}, "cell_type": "markdown", "source": "Copyright \u00a9 2020, 2021, 2022 IBM. This notebook and its source code are released under the terms of the MIT License."}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.14", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}
