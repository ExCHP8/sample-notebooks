{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/pmservice/customer-satisfaction-prediction/blob/master/app/static/images/ml_icon_gray.png?raw=true\" align=\"center\" alt=\"\" height=\"45\" width=\"45\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using custom operators with tf.py_func with Watson Machine Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building models with standard components is straightforward, but to use any custom component with your models in Watson Machine Learning, you need to package your custom component code in a source distribution package and store that package in your Watson Machine Learning repository with your model.\n",
    "\n",
    "Learn how to define a custom operation using the tf.py_func operation in TensorFlow. The custom operation is then used in a LeNet network for handwritten character recognition which is trained on the MNIST data set. The trained model is persisted, deployed and scored using the Watson Machine Learning Service (WML) and the Watson Machine Learning Client.\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python-3.6, numpy-1.14 and tensorflow-1.5. Learn more about custom components in the <a href=\"https://dataplatform.cloud.ibm.com/docs/content/analyze-data/ml-custom_libs_overview.html\" target=\"_blank\" rel=\"noopener noreferrer\">Watson Studio documentation</a>.\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "This notebooks focuses particularly on demonstrating how to use custom components in your model. You will learn how to:\n",
    "\n",
    "-  define a custom operation and corresponding gradient using `tf.py_func`\n",
    "-  create a LeNet model using the defined custom operation\n",
    "-  train the model on the MNIST data set\n",
    "-  create a library containing the custom tensor operation\n",
    "-  persist the library and the model in Watson Machine Learning repository\n",
    "-  deploy the model using Watson Machine Learning Service\n",
    "-  perform some classifications using the deployed model\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "1.  [Set up](#setup)\n",
    "2.  [Create the operation for tf.py_func and download the library](#func)\n",
    "3.\t[Load data and initialize parameters](#load)\n",
    "4.\t[Create and train the LeNet model](#model)\n",
    "5.  [Save the LeNet model locally](#save)\n",
    "6.  [Save the custom library and model in the Watson Machine Learning repository](#lib_persistence)\n",
    "7.\t[Save the LeNet model to the Watson Machine Learning repository](#persistence)\n",
    "8.  [Deploy and perform prediction on the LeNet model](#Scoring)\n",
    "9.  [Summary](#summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Set up\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "-  Create a <a href=\"https://cloud.ibm.com/catalog/services/machine-learning\" target=\"_blank\" rel=\"noopener noreferrer\">Watson Machine Learning (WML) Service</a> instance on IBM Cloud (a free plan is offered). Information on how to create the instance is available in the <a href=\"https://dataplatform.ibm.com/docs/content/analyze-data/wml-setup.html\" target=\"_blank\" rel=\"noopener noreferrer\">Watson Studio documentation</a>.\n",
    "- Configure your local python environment:\n",
    "  + Python 3.6\n",
    "  + TensorFlow 1.5\n",
    "  + watson-machine-learning-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rm -rf watson-machine-learning-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install watson-machine-learning-client --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"func\"></a>\n",
    "## 2. Configure the tf.py_func function\n",
    "\n",
    "In this section, you will:\n",
    "- [Create a custom operation for the tf.py_func](createfunc)\n",
    "- [Download the Python libraries](downloadlib) that the tf.py_func needs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create a custom operation for tf.py_func<a id=\"createfunc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you create a custom operation for tf.py_func, you also need to create the corresponding gradient function. TensorFlow maps any function passed to the tf.py_func under the `PyFunc` operation type. TensorFlow models perform gradient calculation during training. Hence, a user defined `tf.py_func` operation requires a corresponding gradient function to be defined and mapped to the `PyFunc` operation type. In this example, `reshape_grad` is the gradient function for the `tf.py_func` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow==1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.framework import ops \n",
    "\n",
    "def reshape_func(x):\n",
    "    return x.reshape((-1, 28, 28, 1)) \n",
    "\n",
    "def reshape_grad(op, grad):\n",
    "    x = op.inputs[0]\n",
    "\n",
    "    return grad\n",
    "\n",
    "def create_py_func_with_grads(op, inp, tout, stateful=True, name=None, grad=None):\n",
    "    grad_name = 'PyFuncGrad' + str(np.random.randint(0, 1e+8))\n",
    "\n",
    "    tf.RegisterGradient(grad_name)(grad)\n",
    "    g = tf.get_default_graph()\n",
    "\n",
    "    with g.gradient_override_map({\"PyFunc\": grad_name}):\n",
    "        return tf.py_func(op, inp, tout, stateful=stateful, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Download a sample custom package for a TensorFlow model<a id=\"downloadlib\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Python-distributable library needs to be created to store and deploy models that use operations defined through `tf.py_func`. The library must contain an `initialize_py_func()` function, which defines the `tf.py_func` operation. The operation defined within this function must have the same name as the operation created during model definition and training. Also, the `initialize_py_func()` function must be referenceable using the top-level module name. For example, if the top-level module in the python distribution package is `my_top_module`, then `initialize_py_func()` must be referenceable as `my_top_module.initialize_py_func()`.\n",
    "\n",
    "Currently, only source-distributed libraries archived in `.zip` format are supported. Library distributions of type `wheels` and `eggs` are not supported.\n",
    "\n",
    "Any 3rd party libraries that are required for the custom transformer must be defined as the dependency for the corresponding library that contains the transformer implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the sample library `custom_reshape_pyfunc.zip`, which defines the reshape operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-09 17:51:19--  https://github.com/pmservice/wml-sample-models/raw/master/tensorflow/custom-op-hand-written-digit-recognition/libraries/custom_reshape_pyfunc-0.1.zip\n",
      "Resolving github.com (github.com)... 140.82.114.4\n",
      "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/pmservice/wml-sample-models/master/tensorflow/custom-op-hand-written-digit-recognition/libraries/custom_reshape_pyfunc-0.1.zip [following]\n",
      "--2019-07-09 17:51:20--  https://raw.githubusercontent.com/pmservice/wml-sample-models/master/tensorflow/custom-op-hand-written-digit-recognition/libraries/custom_reshape_pyfunc-0.1.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.8.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.8.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3138 (3.1K) [application/zip]\n",
      "Saving to: ‘custom_reshape_pyfunc.zip’\n",
      "\n",
      "100%[======================================>] 3,138       --.-K/s   in 0s      \n",
      "\n",
      "2019-07-09 17:51:20 (48.9 MB/s) - ‘custom_reshape_pyfunc.zip’ saved [3138/3138]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/pmservice/wml-sample-models/raw/master/tensorflow/custom-op-hand-written-digit-recognition/libraries/custom_reshape_pyfunc-0.1.zip --output-document=custom_reshape_pyfunc.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "## 3. Load the data and initialize parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the <a href=\"http://yann.lecun.com/exdb/mnist/index.html\" target=\"_blank\" rel=\"noopener noreferrer\">MNIST data set</a> from Yann LeCun's homepage using the built-in TensorFlow library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the training and network parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 10000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784 \n",
    "n_classes = 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "## 4. Create and train the LeNet model\n",
    "\n",
    "In this section, you will create the LeNet model and then train it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the placeholders and the default layer configurations for the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input], name=\"x_input\")\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `create_py_func_with_grads` function defines a `tf.py_func` operation together with the corresponding gradient and returns the resulting tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trans1 = create_py_func_with_grads(reshape_func, [x], tf.float32, False, name='ReshapeFunc', grad=reshape_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-4365cb5f254c>:32: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convolution Layer -1\n",
    "x_conv2d_l1 = tf.nn.conv2d(x_trans1, weights['wc1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "x_w_bias_l1 = tf.nn.bias_add(x_conv2d_l1, biases['bc1'])\n",
    "x_relu_l1 = tf.nn.relu(x_w_bias_l1)\n",
    "conv1_out = tf.nn.max_pool(x_relu_l1,\n",
    "                           ksize=[1, 2, 2, 1],\n",
    "                           strides=[1, 2, 2, 1],\n",
    "                           padding='SAME')\n",
    "\n",
    "\n",
    "# Convolution Layer -2\n",
    "x_conv2d_l2 = tf.nn.conv2d(conv1_out, weights['wc2'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "x_w_bias_l2 = tf.nn.bias_add(x_conv2d_l2, biases['bc2'])\n",
    "x_relu_l2 = tf.nn.relu(x_w_bias_l2)\n",
    "conv2_out = tf.nn.max_pool(x_relu_l2,\n",
    "                           ksize=[1, 2, 2, 1],\n",
    "                           strides=[1, 2, 2, 1],\n",
    "                           padding='SAME')\n",
    "\n",
    "# Fully connected layer\n",
    "# Reshape conv2 output to fit fully connected layer input\n",
    "fc1 = tf.reshape(conv2_out, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "fc1 = tf.nn.relu(fc1)\n",
    "\n",
    "# Output, class prediction\n",
    "conv_out = tf.add(tf.matmul(fc1, weights['out']), biases['out'], name=\"output_tensor\")\n",
    "\n",
    "predictor = tf.argmax(conv_out, 1, name=\"predictor\")\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=conv_out, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# To Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(conv_out, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch iteration: 128\n",
      "Completed batch iteration: 256\n",
      "Completed batch iteration: 384\n",
      "Completed batch iteration: 512\n",
      "Completed batch iteration: 640\n",
      "Completed batch iteration: 768\n",
      "Completed batch iteration: 896\n",
      "Completed batch iteration: 1024\n",
      "Completed batch iteration: 1152\n",
      "Completed batch iteration: 1280\n",
      "Iter 1280, Minibatch Loss= 16422.097656, Training Accuracy= 0.27344\n",
      "Completed batch iteration: 1408\n",
      "Completed batch iteration: 1536\n",
      "Completed batch iteration: 1664\n",
      "Completed batch iteration: 1792\n",
      "Completed batch iteration: 1920\n",
      "Completed batch iteration: 2048\n",
      "Completed batch iteration: 2176\n",
      "Completed batch iteration: 2304\n",
      "Completed batch iteration: 2432\n",
      "Completed batch iteration: 2560\n",
      "Iter 2560, Minibatch Loss= 11632.546875, Training Accuracy= 0.47656\n",
      "Completed batch iteration: 2688\n",
      "Completed batch iteration: 2816\n",
      "Completed batch iteration: 2944\n",
      "Completed batch iteration: 3072\n",
      "Completed batch iteration: 3200\n",
      "Completed batch iteration: 3328\n",
      "Completed batch iteration: 3456\n",
      "Completed batch iteration: 3584\n",
      "Completed batch iteration: 3712\n",
      "Completed batch iteration: 3840\n",
      "Iter 3840, Minibatch Loss= 5073.618652, Training Accuracy= 0.60938\n",
      "Completed batch iteration: 3968\n",
      "Completed batch iteration: 4096\n",
      "Completed batch iteration: 4224\n",
      "Completed batch iteration: 4352\n",
      "Completed batch iteration: 4480\n",
      "Completed batch iteration: 4608\n",
      "Completed batch iteration: 4736\n",
      "Completed batch iteration: 4864\n",
      "Completed batch iteration: 4992\n",
      "Completed batch iteration: 5120\n",
      "Iter 5120, Minibatch Loss= 4080.135254, Training Accuracy= 0.71094\n",
      "Completed batch iteration: 5248\n",
      "Completed batch iteration: 5376\n",
      "Completed batch iteration: 5504\n",
      "Completed batch iteration: 5632\n",
      "Completed batch iteration: 5760\n",
      "Completed batch iteration: 5888\n",
      "Completed batch iteration: 6016\n",
      "Completed batch iteration: 6144\n",
      "Completed batch iteration: 6272\n",
      "Completed batch iteration: 6400\n",
      "Iter 6400, Minibatch Loss= 2746.335205, Training Accuracy= 0.81250\n",
      "Completed batch iteration: 6528\n",
      "Completed batch iteration: 6656\n",
      "Completed batch iteration: 6784\n",
      "Completed batch iteration: 6912\n",
      "Completed batch iteration: 7040\n",
      "Completed batch iteration: 7168\n",
      "Completed batch iteration: 7296\n",
      "Completed batch iteration: 7424\n",
      "Completed batch iteration: 7552\n",
      "Completed batch iteration: 7680\n",
      "Iter 7680, Minibatch Loss= 2653.687500, Training Accuracy= 0.79688\n",
      "Completed batch iteration: 7808\n",
      "Completed batch iteration: 7936\n",
      "Completed batch iteration: 8064\n",
      "Completed batch iteration: 8192\n",
      "Completed batch iteration: 8320\n",
      "Completed batch iteration: 8448\n",
      "Completed batch iteration: 8576\n",
      "Completed batch iteration: 8704\n",
      "Completed batch iteration: 8832\n",
      "Completed batch iteration: 8960\n",
      "Iter 8960, Minibatch Loss= 1442.446411, Training Accuracy= 0.85938\n",
      "Completed batch iteration: 9088\n",
      "Completed batch iteration: 9216\n",
      "Completed batch iteration: 9344\n",
      "Completed batch iteration: 9472\n",
      "Completed batch iteration: 9600\n",
      "Completed batch iteration: 9728\n",
      "Completed batch iteration: 9856\n",
      "Completed batch iteration: 9984\n",
      "Model training finished!\n"
     ]
    }
   ],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "step = 1\n",
    "# Keep training until reach max iterations\n",
    "while step * batch_size < training_iters:\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    # Run optimization op (backprop)\n",
    "    sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "    print(\"Completed batch iteration: \" + str(step*batch_size) )\n",
    "    if step % display_step == 0:\n",
    "        # Calculate batch loss and accuracy\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y})\n",
    "    \n",
    "        print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "              \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "              \"{:.5f}\".format(acc))\n",
    "    step += 1\n",
    "print(\"Model training finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"save\"></a>\n",
    "## 5. Save the LeNet model locally\n",
    "\n",
    "In this section, you will use `SavedModelBuilderSave` to save the model locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the previously created directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "save_path = './tf_model_mnist_test'\n",
    "# delete dir if directory exists\n",
    "if os.path.exists(save_path):\n",
    "    shutil.rmtree(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `SignatureDef` metadata for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_signature content:\n",
      "inputs {\n",
      "  key: \"inputs\"\n",
      "  value {\n",
      "    name: \"x_input:0\"\n",
      "    dtype: DT_FLOAT\n",
      "    tensor_shape {\n",
      "      dim {\n",
      "        size: -1\n",
      "      }\n",
      "      dim {\n",
      "        size: 784\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  key: \"classes\"\n",
      "  value {\n",
      "    name: \"predictor:0\"\n",
      "    dtype: DT_INT64\n",
      "    tensor_shape {\n",
      "      dim {\n",
      "        size: -1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "method_name: \"tensorflow/serving/classify\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_inputs = tf.saved_model.utils.build_tensor_info(x)\n",
    "classification_outputs_classes = tf.saved_model.utils.build_tensor_info(predictor)\n",
    "\n",
    "classification_signature = (\n",
    "      tf.saved_model.signature_def_utils.build_signature_def(\n",
    "          inputs={\n",
    "              tf.saved_model.signature_constants.CLASSIFY_INPUTS:\n",
    "                  classification_inputs\n",
    "          },\n",
    "          outputs={\n",
    "              tf.saved_model.signature_constants.CLASSIFY_OUTPUT_CLASSES:\n",
    "                  classification_outputs_classes\n",
    "          },\n",
    "          method_name=tf.saved_model.signature_constants.CLASSIFY_METHOD_NAME))\n",
    "\n",
    "print(\"classification_signature content:\")\n",
    "print(classification_signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use TensorFlow's `SavedModelBuilder` API to save the LeNet model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'./tf_model_mnist_test/saved_model.pb'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'./tf_model_mnist_test/saved_model.pb'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the signature_def_map.\n",
    "\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(save_path)\n",
    "legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
    "builder.add_meta_graph_and_variables(\n",
    "      sess, [tf.saved_model.tag_constants.SERVING],\n",
    "      signature_def_map={\n",
    "          'predict_images': classification_signature,\n",
    "      },\n",
    "      legacy_init_op=legacy_init_op)\n",
    "\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lib_persistence\"></a>\n",
    "## 6. Save the custom library and model in the Watson Machine Learning repository\n",
    "\n",
    "\n",
    "In this section, use the `watson_machine_learning_client` to:\n",
    "- Save the library `custom_reshape_pyfunc.zip` in the WML Repository by creating a library resource.\n",
    "- Create a runtime resource and bind the library resource to it. This runtime resource will be used to configure the online deployment runtime environment for a model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Save the library as a library artifact\n",
    "\n",
    "Authenticate to the Watson Machine Learning (WML) service on IBM Cloud.\n",
    "\n",
    "Authentication information (your credentials) can be found in the <a href=\"https://console.bluemix.net/docs/services/service_credentials.html#service_credentials\" target=\"_blank\" rel=\"noopener noreferrer\">Service Credentials</a> tab of the service instance that you created on IBM Cloud. \n",
    "If there are no credentials listed for your instance in **Service credentials**, click **New credential (+)** and enter the information required to generate new authentication information. \n",
    "\n",
    "**Action**: Enter your WML service instance credentials here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials = {\n",
    "    \"apikey\": \"...\",\n",
    "    \"username\": \"...\",\n",
    "    \"password\": \"...\",\n",
    "    \"instance_id\": \"...\",\n",
    "    \"url\": \"https://ibm-watson-ml.mybluemix.net\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you create the library metadata for storing the library in WML Repository, make sure that the value passed to `client.runtimes.LibraryMetaNames.NAME` key is the same as the value passed to the `name` parameter of `setup()` function in `setup.py` file which is used to build the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_lib_zip_path = \"custom_reshape_pyfunc.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_meta = {\n",
    "    client.runtimes.LibraryMetaNames.NAME: \"custom_reshape_pyfunc\",\n",
    "    client.runtimes.LibraryMetaNames.DESCRIPTION: \"A custom pyfunc lib which reshapes input\",\n",
    "    client.runtimes.LibraryMetaNames.FILEPATH: cust_lib_zip_path,\n",
    "    client.runtimes.LibraryMetaNames.VERSION: \"1.2\",\n",
    "    client.runtimes.LibraryMetaNames.PLATFORM: {\"name\": \"python\", \"versions\": [\"3.5\"]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_library_details = client.runtimes.store_library(lib_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  ---------------------  -------  ------------------------  -------------  -----------------\n",
      "GUID                                  NAME                   VERSION  CREATED                   PLATFORM NAME  PLATFORM VERSIONS\n",
      "7090989e-a4fd-443d-a58b-7853270afcf7  custom_reshape_pyfunc  1.2      2019-07-09T17:52:57.672Z  python         ['3.5']\n",
      "b98fd429-1c59-43bf-9274-ac6c9d499c08  sklearn_arima          0.1      2019-07-03T00:55:07.237Z  python         ['3.5']\n",
      "------------------------------------  ---------------------  -------  ------------------------  -------------  -----------------\n"
     ]
    }
   ],
   "source": [
    "client.runtimes.list_libraries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_library_uid = client.runtimes.get_library_uid(custom_library_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7090989e-a4fd-443d-a58b-7853270afcf7'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_library_uid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Save the runtime resource artifact\n",
    "The runtime resource artifact contains references to a collection of all the custom libraries that need to be used together to deploy the model.\n",
    "When you create the metadata to store the runtime artifact, pass a list of library uids that need to be used to the `client.runtimes.ConfigurationMetaNames.LIBRARIES_UIDS` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_meta = {\n",
    "    client.runtimes.ConfigurationMetaNames.NAME: 'runtime_mnist',\n",
    "    client.runtimes.ConfigurationMetaNames.DESCRIPTION: 'runtime spec - mnist',\n",
    "    client.runtimes.ConfigurationMetaNames.PLATFORM: {\n",
    "        \"name\": \"python\",\n",
    "        \"version\": \"3.5\"\n",
    "    },\n",
    "    client.runtimes.ConfigurationMetaNames.LIBRARIES_UIDS: [custom_library_uid]\n",
    "}\n",
    "runtime_details = client.runtimes.store(runtime_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'guid': '55a5c250-b93d-4cad-b58c-d83175bfd9da',\n",
       "  'url': 'https://us-south.ml.cloud.ibm.com/v4/runtimes/55a5c250-b93d-4cad-b58c-d83175bfd9da',\n",
       "  'created_at': '2019-07-09T17:52:59.448Z'},\n",
       " 'entity': {'name': 'runtime_mnist',\n",
       "  'description': 'runtime spec - mnist',\n",
       "  'custom_libraries': [{'name': 'custom_reshape_pyfunc',\n",
       "    'version': '1.2',\n",
       "    'url': 'https://us-south.ml.cloud.ibm.com/v4/libraries/7090989e-a4fd-443d-a58b-7853270afcf7'}],\n",
       "  'content_url': 'https://us-south.ml.cloud.ibm.com/v4/runtimes/55a5c250-b93d-4cad-b58c-d83175bfd9da/content',\n",
       "  'platform': {'name': 'python', 'version': '3.5'}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55a5c250-b93d-4cad-b58c-d83175bfd9da\n"
     ]
    }
   ],
   "source": [
    "custom_runtime_uid = client.runtimes.get_uid(runtime_details)\n",
    "print(custom_runtime_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"persistence\"></a>\n",
    "## 7. Save the LeNet model to the Watson Machine Learning repository\n",
    "\n",
    "The model that needs to be saved in the repo needs to be of tar.gz format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Create a model archive\n",
    "\n",
    "First, remove any existing model archive with the same name, then create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('tf_mnist_pyfunc.tar.gz'):\n",
    "    os.remove('tf_mnist_pyfunc.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dsxuser/work/tf_model_mnist_test\n"
     ]
    }
   ],
   "source": [
    "cd tf_model_mnist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_model.pb  \u001b[0m\u001b[01;34mvariables\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_model.pb\r\n",
      "variables/\r\n",
      "variables/variables.index\r\n",
      "variables/variables.data-00000-of-00001\r\n"
     ]
    }
   ],
   "source": [
    "!tar -cvf ../tf_mnist_pyfunc.tar *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dsxuser/work\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip tf_mnist_pyfunc.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'tf_mnist_pyfunc.tar.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Save the model to the Watson Machine Learning repository\n",
    "Bind Runtime resource to the model and save the model to Watson Machine Learning repository. <br>\n",
    "`client.repository.ModelMetaNames.RUNTIME_UID` key value pair is added to the model metadata as a reference to the runtime artifact which stores the list of library artifact urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meta = {\n",
    "    client.repository.ModelMetaNames.AUTHOR_NAME: \"IBM\",\n",
    "    client.repository.ModelMetaNames.AUTHOR_EMAIL: \"ibm@ibm.com\",\n",
    "    client.repository.ModelMetaNames.NAME: \"cust_pyfunc_mnist\",\n",
    "    client.repository.ModelMetaNames.DESCRIPTION: \"cust MNIST with pyfunc\",\n",
    "    client.repository.ModelMetaNames.RUNTIME_UID: custom_runtime_uid,\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_NAME: \"tensorflow\",\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_VERSION: \"1.5\",\n",
    "    client.repository.ModelMetaNames.RUNTIME_NAME: \"python\",\n",
    "    client.repository.ModelMetaNames.RUNTIME_VERSION: \"3.5\"\n",
    "}\n",
    "model_details = client.repository.store_model(model=model_path, meta_props=model_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9fa55b5e-45f5-46ae-829e-42d8c038017a\n"
     ]
    }
   ],
   "source": [
    "model_uid = client.repository.get_model_uid(model_details)\n",
    "print(model_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'guid': '9fa55b5e-45f5-46ae-829e-42d8c038017a',\n",
       "  'url': 'https://us-south.ml.cloud.ibm.com/v3/wml_instances/b4b6c696-172c-4164-8049-c0b621dbf3c9/published_models/9fa55b5e-45f5-46ae-829e-42d8c038017a',\n",
       "  'created_at': '2019-07-09T17:53:04.949Z',\n",
       "  'modified_at': '2019-07-09T17:53:05.026Z'},\n",
       " 'entity': {'runtime_environment': 'python-3.5',\n",
       "  'learning_configuration_url': 'https://us-south.ml.cloud.ibm.com/v3/wml_instances/b4b6c696-172c-4164-8049-c0b621dbf3c9/published_models/9fa55b5e-45f5-46ae-829e-42d8c038017a/learning_configuration',\n",
       "  'author': {'name': 'IBM'},\n",
       "  'name': 'cust_pyfunc_mnist',\n",
       "  'description': 'cust MNIST with pyfunc',\n",
       "  'learning_iterations_url': 'https://us-south.ml.cloud.ibm.com/v3/wml_instances/b4b6c696-172c-4164-8049-c0b621dbf3c9/published_models/9fa55b5e-45f5-46ae-829e-42d8c038017a/learning_iterations',\n",
       "  'feedback_url': 'https://us-south.ml.cloud.ibm.com/v3/wml_instances/b4b6c696-172c-4164-8049-c0b621dbf3c9/published_models/9fa55b5e-45f5-46ae-829e-42d8c038017a/feedback',\n",
       "  'latest_version': {'url': 'https://us-south.ml.cloud.ibm.com/v3/ml_assets/models/9fa55b5e-45f5-46ae-829e-42d8c038017a/versions/e4c953a4-7dba-44f7-8605-74301b2fe75e',\n",
       "   'guid': 'e4c953a4-7dba-44f7-8605-74301b2fe75e',\n",
       "   'created_at': '2019-07-09T17:53:05.026Z'},\n",
       "  'model_type': 'tensorflow-1.5',\n",
       "  'deployments': {'count': 0,\n",
       "   'url': 'https://us-south.ml.cloud.ibm.com/v3/wml_instances/b4b6c696-172c-4164-8049-c0b621dbf3c9/published_models/9fa55b5e-45f5-46ae-829e-42d8c038017a/deployments'},\n",
       "  'evaluation_metrics_url': 'https://us-south.ml.cloud.ibm.com/v3/wml_instances/b4b6c696-172c-4164-8049-c0b621dbf3c9/published_models/9fa55b5e-45f5-46ae-829e-42d8c038017a/evaluation_metrics',\n",
       "  'runtime': {'url': 'https://us-south.ml.cloud.ibm.com/v4/runtimes/55a5c250-b93d-4cad-b58c-d83175bfd9da'}}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Scoring'></a>\n",
    "## 8. Deploy and perform prediction on the LeNet model\n",
    "\n",
    "In this section, you will:\n",
    "- Deploy the saved model that uses the custom transformer\n",
    "- Perform predictions\n",
    "You will use the WML client to perform these tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "Synchronous deployment creation for uid: '9fa55b5e-45f5-46ae-829e-42d8c038017a' started\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "\n",
      "INITIALIZING\n",
      "DEPLOY_IN_PROGRESS.................\n",
      "DEPLOY_SUCCESS\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_uid='7e4cc05a-9868-4ea7-b502-b2a56324d686'\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deployment_details = client.deployments.create(model_uid, \"Mnist model deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Score the deployed model\n",
    "\n",
    "Get the scoring url for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_url = client.deployments.get_scoring_url(deployment_details)\n",
    "print(scoring_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare sample scoring data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mnist.test.next_batch(1)[0].tolist()\n",
    "payload = {'values': image}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f91fad12438>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 1, 1)\n",
    "plt.axis('off')\n",
    "plt.imshow((np.reshape(np.array(image), (28, 28)) * 255).astype(np.uint8), cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring result: [4]\n"
     ]
    }
   ],
   "source": [
    "predictions = client.deployments.score(scoring_url, payload)\n",
    "print('Scoring result: ' + str(predictions['values']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Delete the deployments, libaries, models and runtimes\n",
    "\n",
    "Use the following method to delete the deployment if it is no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_id = client.deployments.get_uid(deployment_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.deployments.delete(deployment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that all your deployments are deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  -------------------------------------------------------  -------  ------------------  ------------------------  -----------------  -------------\n",
      "GUID                                  NAME                                                     TYPE     STATE               CREATED                   FRAMEWORK          ARTIFACT TYPE\n",
      "af073cc6-dca4-42d3-a27e-9892e8bfc3c0  Keras MNIST model deployment through compressed file.    online   DEPLOY_SUCCESS      2019-07-09T17:50:11.230Z  tensorflow-1.5     model\n",
      "7985e484-4192-400e-82e5-3756d4600668  ARIMA model python function deployment                   online   DEPLOY_SUCCESS      2019-07-03T20:33:40.817Z  n/a                function\n",
      "6aedb5b7-638a-4388-ab0d-45fecb3b7081  Customer Churn Prediction                                online   DEPLOY_SUCCESS      2019-07-03T15:51:34.166Z  mllib-2.3          model\n",
      "cfcd5f9e-5b07-4bea-b57d-304c12254add  sklearn_pipeline_arima                                   online   DEPLOY_SUCCESS      2019-07-03T01:06:29.302Z  scikit-learn-0.19  model\n",
      "7b045679-07c9-4225-9116-c153c6359588  Virtual deployment of Boston model                       virtual  DEPLOY_IN_PROGRESS  2019-05-20T18:20:14.124Z  scikit-learn-0.19  model\n",
      "2b9a344c-2dbf-4568-920d-bb5b598d8273  Online scoring                                           online   DEPLOY_SUCCESS      2019-05-17T17:34:23.382Z  mllib-2.3          model\n",
      "69aa4267-dc8c-4243-bc33-3ee7571c0ca4  Online scoring                                           online   DEPLOY_SUCCESS      2019-05-17T17:29:35.859Z  mllib-2.3          model\n",
      "81911f93-50bb-4fec-a146-eb6f8519b79e  Virtual deployment of Boston model                       virtual  DEPLOY_IN_PROGRESS  2019-05-13T21:11:07.340Z  scikit-learn-0.19  model\n",
      "4431988f-678b-4f40-92b4-2dbe63ea54e2  Virtual deployment of Boston model                       virtual  DEPLOY_IN_PROGRESS  2019-05-13T19:16:19.731Z  scikit-learn-0.19  model\n",
      "31fdffd5-6a0a-459f-a160-7c4be26ddf15  ML Contest - Label Prediction Model deployment           online   DEPLOY_SUCCESS      2019-05-07T16:48:56.694Z  scikit-learn-0.19  model\n",
      "18fe2647-55e0-451a-8f51-0c3195223981  ML Contest - Issue ETA Prediction Model deployment       online   DEPLOY_SUCCESS      2019-05-07T16:48:51.102Z  scikit-learn-0.19  model\n",
      "5649340d-248b-4d34-a2d8-ed3e0316ea9b  ML Contest - Assignee Prediction Model deployment        online   DEPLOY_SUCCESS      2019-05-07T16:48:45.286Z  scikit-learn-0.19  model\n",
      "49055fc5-88f4-46ea-b17a-517d75f120ba  Online scoring                                           online   DEPLOY_SUCCESS      2019-04-26T17:19:40.703Z  mllib-2.3          model\n",
      "7eb9b874-53b8-463c-bd19-058ee52e3e3d  Online scoring                                           online   DEPLOY_SUCCESS      2019-04-26T17:07:07.833Z  mllib-2.3          model\n",
      "8b95a4dd-4b3f-4b36-bd3e-b58b59f100e2  Mnist model deployment                                   online   DEPLOY_SUCCESS      2019-04-02T16:09:27.875Z  tensorflow-1.5     model\n",
      "451f5f1a-d1f5-4a90-a441-b2953053ae6f  Time Series model (SPSS) deployment                      online   DEPLOY_SUCCESS      2019-03-28T19:00:49.524Z  spss-modeler-18.1  model\n",
      "486a79af-ea0b-4e8e-8166-dc2bb43b6c98  TensorFlow MNIST model deployment                        online   DEPLOY_SUCCESS      2019-03-15T18:27:34.468Z  tensorflow-1.5     model\n",
      "92991643-a229-4f9e-a70a-3e9de612942e  Sample SPSS model deployment                             online   DEPLOY_SUCCESS      2019-03-12T12:59:15.857Z  spss-modeler-18.1  model\n",
      "dce80b25-3d32-4005-b96b-9d9c80a7239a  MNIST keras deployment                                   online   DEPLOY_FAILURE      2019-03-07T13:37:41.529Z  tensorflow-1.5     model\n",
      "00edc46c-5df5-482e-936a-4d9f2e5fbc06  Product line model deployment                            online   DEPLOY_SUCCESS      2019-03-06T14:30:35.086Z  mllib-2.3          model\n",
      "86da6500-18ff-4970-b3e4-7e335d4a08f9  Mnist model deployment                                   online   DEPLOY_SUCCESS      2019-03-06T12:52:13.175Z  tensorflow-1.5     model\n",
      "d250df1b-6e43-4c69-98d2-10ff25b5d63d  Virtual deployment of Boston model                       virtual  DEPLOY_SUCCESS      2019-03-06T11:45:33.176Z  scikit-learn-0.19  model\n",
      "6d3cf6bb-db92-427c-8b52-9d050d7bfec8  Virtual deployment of Boston model                       virtual  DEPLOY_SUCCESS      2019-03-06T11:32:59.110Z  scikit-learn-0.19  model\n",
      "ded4770f-c2fe-4653-9ce2-0c79ecfa10be  Iris species prediction                                  online   DEPLOY_SUCCESS      2019-03-04T12:59:23.413Z  pmml-4.2           model\n",
      "450f555b-1952-4ef1-90be-96a16f600345  Predict breast cancer                                    online   DEPLOY_SUCCESS      2019-02-28T19:11:28.862Z  scikit-learn-0.19  model\n",
      "dd987565-3e04-4179-9cf9-546710fbadcd  Web scraping python function deployment                  online   DEPLOY_SUCCESS      2019-02-28T11:50:04.209Z  n/a                function\n",
      "984ffa92-1c82-4b54-bb56-f6f85e915227  Web scraping python function deployment                  online   DEPLOY_SUCCESS      2019-02-27T17:50:16.907Z  n/a                function\n",
      "e5472c3f-c7d7-4a3e-9b20-44f03030373e  Web scraping python function deployment                  online   DEPLOY_SUCCESS      2019-02-27T16:51:24.029Z  n/a                function\n",
      "304c671c-6a48-496d-b27b-3ad9888a0156  Online scoring                                           online   DEPLOY_SUCCESS      2019-02-27T13:50:39.730Z  mllib-2.3          model\n",
      "18298746-41ec-4bac-928c-fc34e3708ca9  Sample SPSS model deployment                             online   DEPLOY_SUCCESS      2019-02-27T11:53:13.523Z  spss-modeler-18.1  model\n",
      "375d050d-1e3b-49e5-9f1d-655f28734ec7  Sample SPSS model deployment                             online   DEPLOY_SUCCESS      2019-02-27T09:29:07.286Z  spss-modeler-18.1  model\n",
      "2924aaaf-bddf-4567-8206-6972c163dfa4  Sample SPSS model deployment                             online   DEPLOY_SUCCESS      2019-02-26T13:13:44.977Z  spss-modeler-18.1  model\n",
      "feb87375-fca8-4b0c-8f2f-5c83a6e26115  Iris species prediction                                  online   DEPLOY_SUCCESS      2019-02-25T13:09:17.454Z  pmml-4.2           model\n",
      "a0e16777-75ad-489a-a6db-5213619381a4  Keras MNIST model deployment through compressed file.    online   DEPLOY_SUCCESS      2019-02-25T12:29:47.265Z  tensorflow-1.5     model\n",
      "5c5ebf10-c47a-4224-b35d-3646b0348af1  Web scraping python function deployment                  online   DEPLOY_SUCCESS      2019-02-21T14:58:00.141Z  n/a                function\n",
      "b9efb426-845a-45e7-b591-85c4bdb1417c  SMS Spam prediction model deployment.                    online   DEPLOY_SUCCESS      2019-02-13T15:52:48.108Z  scikit-learn-0.19  model\n",
      "569fb590-41aa-433e-aeb4-89a9688a4a7b  Keras earthquake magnitude prediction model deployment.  online   DEPLOY_SUCCESS      2019-02-11T16:41:49.568Z  tensorflow-1.12    model\n",
      "7b2ff02b-b6a7-4ef4-b0e6-6765b1c45766  Keras earthquake magnitude prediction model deployment.  online   DEPLOY_SUCCESS      2019-02-07T00:21:58.175Z  tensorflow-1.12    model\n",
      "a738de63-d74e-454a-9dd7-f377c65420bc  Online scoring                                           online   DEPLOY_SUCCESS      2019-01-19T19:49:21.391Z  mllib-2.3          model\n",
      "d8f43799-cf5c-499f-a9d3-42d2e398f337  Sample SPSS model deployment                             online   DEPLOY_SUCCESS      2019-01-18T10:28:38.134Z  spss-modeler-18.1  model\n",
      "12056c7c-6ff1-454d-b324-d1cf4b42c4fd  Iris species prediction                                  online   DEPLOY_SUCCESS      2019-01-18T09:36:17.097Z  pmml-4.2           model\n",
      "a375c7bc-963d-4a9b-9896-7dbcdcaed78d  Web scraping python function deployment                  online   DEPLOY_SUCCESS      2019-01-17T10:11:40.324Z  n/a                function\n",
      "a8b47a68-060c-4474-a5c0-15da3304063a  Product line model deployment                            online   DEPLOY_SUCCESS      2019-01-17T10:02:44.991Z  mllib-2.3          model\n",
      "ada89546-d27c-4c32-953f-84f2238eb12a  Product line model deployment                            online   DEPLOY_SUCCESS      2019-01-17T07:14:05.178Z  mllib-2.3          model\n",
      "902853d1-9ff6-40a7-8918-d6b7b39c3a4e  Web scraping python function deployment                  online   DEPLOY_SUCCESS      2019-01-17T02:37:29.921Z  n/a                function\n",
      "3da0fb97-24b9-44d6-ac16-e97a0cf8dfcb  Keras MNIST model deployment through compressed file.    online   DEPLOY_SUCCESS      2019-01-15T14:49:46.285Z  tensorflow-1.5     model\n",
      "------------------------------------  -------------------------------------------------------  -------  ------------------  ------------------------  -----------------  -------------\n"
     ]
    }
   ],
   "source": [
    "client.deployments.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the library, model or runtime by passing in the appropriate GUID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.repository.delete(model_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.repository.delete(custom_library_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.repository.delete(custom_runtime_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "## 9. Summary\n",
    "\n",
    "In this notebook we learnt how to create a custom Python operation using TensorFlow's `tf.py_func` and used it on the LeNet model for MNIST.\n",
    "\n",
    "We also learned how to use the `watson-machine-learning-client` to store a library created to use the same operation into theWML Repository.\n",
    "\n",
    "Finally, we stored our custom LeNet model with references to the created library into WML Repository, and this model could be deployed and scored later using the WML Service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore the functionalities of Watson Studio further, check out our <a href=\"https://dataplatform.ibm.com/docs/content/analyze-data/wml-setup.html\" target=\"_blank\" rel=\"noopener noreferrer\">Online Documentation</a> for more samples, tutorials, documentation, how-tos, and blog posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998.\n",
    "\n",
    "Creative Commons Zero v1.0 Universal License: The code in section [2.1 Create a custom operation for tf.py_func](#2.1-Create-a-custom-operation-for-tf.py_func) is based on the following:\n",
    "- https://github.com/tensorflow/tensorflow/issues/1095\n",
    "- https://gist.github.com/harpone/3453185b41d8d985356cbe5e57d67342"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author\n",
    "**Srikrishna S Bhat**, M. Tech, is a Software Engineer at IBM Watson Machine Learning Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright © 2018, 2019 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n",
    "<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n",
    "<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n",
    "<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n",
    "<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
