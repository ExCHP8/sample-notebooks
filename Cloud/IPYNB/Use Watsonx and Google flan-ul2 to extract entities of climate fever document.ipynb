{"cells": [{"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n# Use watsonx, and `google/flan-ul2` to extract the named entities of  climate fever document"}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "This notebook contains the steps and code to demonstrate support of named entity extraction in watsonx. It introduces commands for data retrieval and model testing.\n\nSome familiarity with Python is helpful. This notebook uses Python 3.10.\n\n## Introduction\n\nThe objective is to explore and utilize the Google Flan-UL2 model for entity extraction.Google Flan-UL2 is a pre-trained language model which can be used for token-level entity extraction tasks. Entity extraction, also known as Named Entity Recognition (NER), involves identifying and classifying named entities (such as persons, organizations, locations, dates, etc.) from unstructured text.\n\nHere are the steps we took in this notebook for Named Entity Extractions:\n- Data Collection and Preprocessing:\nCollect or obtain a dataset containing text documents \n- Instructions:\nDefine the task and the prompt: Determine the specific entity extraction task we want the model to perform. Design an appropriate prompt that includes relevant instructions for the model, such as input format and expected output format.\n- Training Examples:\nprovide training examples in the form of input-output pairs. Each input example consists of a prompt and corresponding tokenized text, while the output is the target entity labels associated with the tokens in the text.\n- Evaluation:\nCompare the predicted entity labels with the  pseudo ground truth labels in the test set. Calculate evaluation metrics, such as precision, recall, and F1-score, to assess the performance of the model for entity extraction.(**we do not have ground truth entity extraction data for this dataset, we use an open source package to create a pseudo-ground truth that can be used for demonstration purposes.**)\n\n\n## Learning goal\n\nThe goal of this notebook is to demonstrate how to use `google/flan-ul2` model to extract named entities for climate change claims.\n\n## Use case & dataset\nA dataset adopting the FEVER methodology that consists of 1535 real-world claims regarding climate-change collected on the internet. Each claim is accompanied by five manually annotated evidence sentences retrieved from the English Wikipedia that support, refute or do not give enough information to validate the claim totalling in 7675 claim-evidence pairs. The dataset features challenging claims that relate multiple facets and disputed cases of claims where both supporting and refuting evidence are present.Named entities are  extracted form the claims using the google/flan-ul2 model. \n\n\n\n\n## Contents\n\nThis notebook contains the following parts:\n\n- [Setup](#setup)\n- [Data loading](#data)\n- [Foundation Models on watsonx](#models)\n- [Model testing](#predict)\n- [Score](#score)\n- [Summary](#summary)"}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"setup\"></a>\n##  Set up the environment\n\nBefore you use the sample code in this notebook, you must perform the following setup tasks:\n\n-  Create a <a href=\"https://cloud.ibm.com/catalog/services/watson-machine-learning\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/admin/create-services.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>).\n"}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "### Install and import the `datasets` and dependecies\nyou need to install below required dependencies to be able to continue"}, {"metadata": {}, "cell_type": "code", "source": "!pip install datasets | tail -n 1\n!pip install requests | tail -n 1\n!pip install  wget | tail -n 1\n!pip install ibm-cloud-sdk-core | tail -n 1\n!pip install scikit-learn | tail -n 1\n!pip install spacy | tail -n 1\n!python -m spacy download en_core_web_sm | tail -1", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import os, getpass, wget\nimport json\nimport re\nimport random\nimport requests\nimport spacy\nimport copy\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom pandas import read_csv\nfrom sklearn.metrics import classification_report\nfrom ibm_cloud_sdk_core import IAMTokenManager\nfrom sklearn.model_selection import train_test_split\nnlp = spacy.load('en_core_web_sm')", "execution_count": 1, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Inferencing class\nThis cell defines a class that makes a REST API call to the watsonx Foundation Model\ninferencing API that we will use to generate output from the provided input.\nThe class takes the access token created in the previous step, and uses it to\nmake a REST API call with input, model id and model parameters. The response\nfrom the API call is returned as the cell output."}, {"metadata": {}, "cell_type": "markdown", "source": "**Action:** Provide Watson Machine Learning url to work with wastonx.ai."}, {"metadata": {}, "cell_type": "code", "source": "endpoint_url = getpass.getpass(\"Please enter your WML endpoint url (hit enter): \")", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Define a `Prompt` class for prompts generation."}, {"metadata": {}, "cell_type": "code", "source": "class Prompt:\n    def __init__(self, access_token, project_id):\n        self.access_token = access_token\n        self.project_id = project_id\n\n    def generate(self, input, model_id, parameters):\n        wml_url = f\"{endpoint_url}/ml/v1/text/generation?version=2024-03-19\"\n        Headers = {\n            \"Authorization\": \"Bearer \" + self.access_token,\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\"\n        }\n        data = {\n            \"model_id\": model_id,\n            \"input\": input,\n            \"parameters\": parameters,\n            \"project_id\": self.project_id\n        }\n        response = requests.post(wml_url, json=data, headers=Headers)\n        if response.status_code == 200:\n            return response.json()[\"results\"][0]\n        else:\n            return response.text\n        ", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### watsonx API connection\nThis cell defines the credentials required to work with watsonx API for Foundation\nModel inferencing.\n\n**Action:** Provide the IBM Cloud personal API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"IBM Cloud user API key\">documentation</a>."}, {"metadata": {}, "cell_type": "code", "source": "access_token = IAMTokenManager(\n    apikey = getpass.getpass(\"Please enter your WML api key (hit enter): \"),\n    url = \"https://iam.cloud.ibm.com/identity/token\"\n).get_token()", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Defining the project id\nThe API requires project id that provides the context for the call. We will obtain\nthe id from the project in which this notebook runs:"}, {"metadata": {}, "cell_type": "code", "source": "try:\n    project_id = os.environ[\"PROJECT_ID\"]\nexcept KeyError:\n    project_id = getpass.getpass(\"Please enter your project_id (hit enter): \")", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"data\"></a>\n## Data loading"}, {"metadata": {}, "cell_type": "markdown", "source": "Download the `climate` dataset."}, {"metadata": {}, "cell_type": "code", "source": "filename = 'data_clm_fever.csv'\nurl = 'https://raw.githubusercontent.com/kmokht1/Datasets/main/data_clm_fever.csv'\nif not os.path.isfile(filename): wget.download(url, out=filename)", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Read the data."}, {"metadata": {}, "cell_type": "code", "source": "data= read_csv(\"data_clm_fever.csv\", index_col=[0])\n#data=data[['narrative','product']]\ndata.head()", "execution_count": 7, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>claim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Global warming is driving polar bears toward e...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The sun has gone into \u2018lockdown\u2019 which could c...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The polar bear population has been growing.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ironic' study finds more CO2 has slightly cool...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Human additions of CO2 are in the margin of er...</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                               claim\n0  Global warming is driving polar bears toward e...\n1  The sun has gone into \u2018lockdown\u2019 which could c...\n2        The polar bear population has been growing.\n3  Ironic' study finds more CO2 has slightly cool...\n4  Human additions of CO2 are in the margin of er..."}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Split data to train and test"}, {"metadata": {}, "cell_type": "code", "source": "data_train, data_test, _,_ = train_test_split(data['claim'], \n                                                    data['claim'],\n                                                    test_size=0.3,\n                                                    random_state=33,\n                                             )", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Inspect data sample "}, {"metadata": {}, "cell_type": "code", "source": "data_sample=data_train.reset_index(inplace=False, drop=True)[random.sample(range(0, len(data_train)), 10)]\nprint(data_sample)", "execution_count": 9, "outputs": [{"name": "stdout", "output_type": "stream", "text": "662                   Polar bear numbers are increasing.\n207    \"In 1999\u00a0New Scientist\u00a0reported a comment by t...\n675    \"We found [U.S. weather] stations located next...\n175    Skeptics who oppose scientific findings that t...\n728    Pollard and DeConto are the first to admit tha...\n99     Global average temperatures over land have plu...\n747    the world is barely half a degree Celsius (0.9...\n670    Theory, models and direct measurement confirm ...\n849    Never mind that the emissions of carbon dioxid...\n948    Sea-level rise does not seem to depend on ocea...\nName: claim, dtype: object\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"models\"></a>\n## Foundation Models on watsonx"}, {"metadata": {}, "cell_type": "markdown", "source": "#### List available models"}, {"metadata": {}, "cell_type": "code", "source": "models_json = requests.get(endpoint_url + '/ml/v1/foundation_model_specs?version=2024-03-19&limit=50',\n                           headers={\n                                    'Authorization': f'Bearer {access_token}',\n                                    'Content-Type': 'application/json',\n                                    'Accept': 'application/json'\n                            }).json()\nmodels_ids = [m['model_id'] for m in models_json['resources']]\nmodels_ids", "execution_count": 10, "outputs": [{"data": {"text/plain": "['bigcode/starcoder',\n 'bigscience/mt0-xxl',\n 'codellama/codellama-34b-instruct-hf',\n 'eleutherai/gpt-neox-20b',\n 'google/flan-t5-xl',\n 'google/flan-t5-xxl',\n 'google/flan-ul2',\n 'ibm-mistralai/mixtral-8x7b-instruct-v01-q',\n 'ibm/granite-13b-chat-v1',\n 'ibm/granite-13b-chat-v2',\n 'ibm/granite-13b-instruct-v1',\n 'ibm/granite-13b-instruct-v2',\n 'ibm/granite-20b-multilingual',\n 'ibm/mpt-7b-instruct2',\n 'meta-llama/llama-2-13b-chat',\n 'meta-llama/llama-2-70b-chat']"}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}]}, {"metadata": {}, "cell_type": "markdown", "source": "You need to specify `model_id` that will be used for inferencing:"}, {"metadata": {}, "cell_type": "code", "source": "model_id = \"google/flan-ul2\"", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"predict\"></a>\n##  Analyze named entities"}, {"metadata": {}, "cell_type": "markdown", "source": "Define instructions for the model. "}, {"metadata": {}, "cell_type": "markdown", "source": "Prepare model inputs\n\nfor zero-shot example, use below zero_shot_inputs"}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "zero_shot_inputs = [{\"input\": text} for text in data_test]\nfor i in range(10):\n    print(f\"The sentence example {i+1} is:\\n {zero_shot_inputs[i]['input']}\\n\")", "execution_count": 12, "outputs": [{"name": "stdout", "output_type": "stream", "text": "The sentence example 1 is:\n Most likely the primary control knob [on climate change] is the ocean waters and this environment that we live in.\n\nThe sentence example 2 is:\n The Rio Grande is a classic \u201cfeast or famine\u201d river, with a dry year or two typically followed by a couple of wet years that allow for recovery.\n\nThe sentence example 3 is:\n Days of near-100-degree-Fahrenheit temperatures cooked the Mountain West in early July, and a scorching heat wave lingered over the Pacific Northwest in early August.\u201d\n\nThe sentence example 4 is:\n In our lifetime, there has been no correlation between carbon dioxide emissions and temperature\n\nThe sentence example 5 is:\n There is no way for us to prevent the world\u2019s CO2 emissions    from doubling by 2100\"\n\nThe sentence example 6 is:\n Wu et al (2010) use a new method to calculate ice sheet mass balance.\n\nThe sentence example 7 is:\n In the last 35 years of global warming, sun and climate have been going in opposite directions.\n\nThe sentence example 8 is:\n Australia has more solar coverage than any other continent.\n\nThe sentence example 9 is:\n Polar bears are in danger of extinction as well as many other species.\n\nThe sentence example 10 is:\n The United States has been restricting soot emissions  in Draconian fashion since the Clean Air Act of 1963.\n\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Prepare model inputs\n\nfor few-shot examples, use below few_shot_inputs"}, {"metadata": {}, "cell_type": "code", "source": "few_shot_inputs_ = [{\"input\": text} for text in data_test.values]\nfor i in range(5):\n    print(f\"The sentence example {i+1} is:\\n {few_shot_inputs_[i]['input']}\\n\")", "execution_count": 13, "outputs": [{"name": "stdout", "output_type": "stream", "text": "The sentence example 1 is:\n Most likely the primary control knob [on climate change] is the ocean waters and this environment that we live in.\n\nThe sentence example 2 is:\n The Rio Grande is a classic \u201cfeast or famine\u201d river, with a dry year or two typically followed by a couple of wet years that allow for recovery.\n\nThe sentence example 3 is:\n Days of near-100-degree-Fahrenheit temperatures cooked the Mountain West in early July, and a scorching heat wave lingered over the Pacific Northwest in early August.\u201d\n\nThe sentence example 4 is:\n In our lifetime, there has been no correlation between carbon dioxide emissions and temperature\n\nThe sentence example 5 is:\n There is no way for us to prevent the world\u2019s CO2 emissions    from doubling by 2100\"\n\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Preparing the dictionaries of the inputs: for demonstration purposes, we provide the examples using an open source entity extraction model."}, {"metadata": {}, "cell_type": "code", "source": "# Process each document in the dataset\nexample_dic ={}\nexample_dic_list=[]\n\nfor document in data_sample:\n    \n    doc = nlp(document.strip())  # Process the document with spacy NLP pipeline\n    if (len(doc.ents) != 0):\n        example_dic ={}\n        example_dic['document']=document\n        for i, ent in enumerate(doc.ents):\n            example_dic[f'phrase_{i}']=ent.text\n            example_dic[f'label_{i}']=ent.label_\n            \n        example_dic_list.append(example_dic)", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "json_formatted_str = json.dumps(example_dic_list[:4], indent=4)\nprint(json_formatted_str)", "execution_count": 15, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[\n    {\n        \"document\": \"\\\"In 1999\\u00a0New Scientist\\u00a0reported a comment by the leading Indian glaciologist Syed Hasnain, who said in an email interview with this author that all the glaciers in the central and eastern Himalayas\\u00a0could disappear by 2035.\",\n        \"phrase_0\": \"1999\",\n        \"label_0\": \"DATE\",\n        \"phrase_1\": \"Indian\",\n        \"label_1\": \"NORP\",\n        \"phrase_2\": \"Syed Hasnain\",\n        \"label_2\": \"PERSON\",\n        \"phrase_3\": \"Himalayas\",\n        \"label_3\": \"GPE\",\n        \"phrase_4\": \"2035\",\n        \"label_4\": \"DATE\"\n    },\n    {\n        \"document\": \"\\\"We found [U.S. weather] stations located next to  the exhaust fans of air conditioning units, surrounded by asphalt  parking lots and roads,\\u00a0on blistering-hot rooftops, and near sidewalks  and buildings that absorb and radiate heat.\",\n        \"phrase_0\": \"U.S.\",\n        \"label_0\": \"GPE\"\n    },\n    {\n        \"document\": \"Skeptics who oppose scientific findings that threaten their world view are far closer to Galileo's belief-based critics in the Catholic Church.\",\n        \"phrase_0\": \"Galileo\",\n        \"label_0\": \"PRODUCT\",\n        \"phrase_1\": \"the Catholic Church\",\n        \"label_1\": \"ORG\"\n    },\n    {\n        \"document\": \"Pollard and DeConto are the first to admit that their model is still crude, but its results have pushed the entire scientific community into emergency mode.\",\n        \"phrase_0\": \"DeConto\",\n        \"label_0\": \"GPE\",\n        \"phrase_1\": \"first\",\n        \"label_1\": \"ORDINAL\"\n    }\n]\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Creating text format from the above dictionary"}, {"metadata": {}, "cell_type": "code", "source": "examples=[]\nfor i in range(len(example_dic_list)):\n    examples.append('document: \\n'+example_dic_list[i]['document']+'\\n')\n    di=copy.deepcopy(example_dic_list[i])\n    del di['document']\n    examples.append('\\n')\n    examples.append(str(di))\n    examples.append('\\n\\n\\n')\nexamples_input=''.join(examples)", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(examples_input)", "execution_count": 17, "outputs": [{"name": "stdout", "output_type": "stream", "text": "document: \n\"In 1999\u00a0New Scientist\u00a0reported a comment by the leading Indian glaciologist Syed Hasnain, who said in an email interview with this author that all the glaciers in the central and eastern Himalayas\u00a0could disappear by 2035.\n\n{'phrase_0': '1999', 'label_0': 'DATE', 'phrase_1': 'Indian', 'label_1': 'NORP', 'phrase_2': 'Syed Hasnain', 'label_2': 'PERSON', 'phrase_3': 'Himalayas', 'label_3': 'GPE', 'phrase_4': '2035', 'label_4': 'DATE'}\n\n\ndocument: \n\"We found [U.S. weather] stations located next to  the exhaust fans of air conditioning units, surrounded by asphalt  parking lots and roads,\u00a0on blistering-hot rooftops, and near sidewalks  and buildings that absorb and radiate heat.\n\n{'phrase_0': 'U.S.', 'label_0': 'GPE'}\n\n\ndocument: \nSkeptics who oppose scientific findings that threaten their world view are far closer to Galileo's belief-based critics in the Catholic Church.\n\n{'phrase_0': 'Galileo', 'label_0': 'PRODUCT', 'phrase_1': 'the Catholic Church', 'label_1': 'ORG'}\n\n\ndocument: \nPollard and DeConto are the first to admit that their model is still crude, but its results have pushed the entire scientific community into emergency mode.\n\n{'phrase_0': 'DeConto', 'label_0': 'GPE', 'phrase_1': 'first', 'label_1': 'ORDINAL'}\n\n\ndocument: \nGlobal average temperatures over land have plummeted by more than 1C since the middle of this year \u2013 their biggest and steepest fall on record.\n\n{'phrase_0': 'the middle of this year', 'label_0': 'DATE'}\n\n\ndocument: \nthe world is barely half a degree Celsius (0.9 degrees Fahrenheit) warmer than it was about 35 years ago\n\n{'phrase_0': 'barely half', 'label_0': 'CARDINAL', 'phrase_1': '0.9 degrees', 'label_1': 'QUANTITY', 'phrase_2': 'Fahrenheit', 'label_2': 'GPE', 'phrase_3': 'about 35 years ago', 'label_3': 'DATE'}\n\n\n\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Defining the model parameters\nWe need to provide a set of model parameters that will influence the\nresult:Based on decoding strategy that we have for the models, the parameters can change.\n\nThere are two decoding strategies: 1-Greedy 2-Sampling.\n\nWe usually use Greedy for complaint classification, Summarization,Extraction and Q&A\n\nWe usually use Sampling for content generation"}, {"metadata": {}, "cell_type": "code", "source": "# GREEDY PAREMETER CONFIGURATION\n\nparameters = {\n         \"decoding_method\": \"greedy\",\n         \"random_seed\": 33,\n         \"repetition_penalty\":1,\n         \"min_new_tokens\": 1,\n         \"max_new_tokens\": 150\n}", "execution_count": 18, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Extract the named entities of climate claim document using `google/flan-ul2` model.\n\n\n**Note:** You might need to adjust model `parameters` for different models or tasks, to do so please refer to <a href=\"https://ibm.github.io/watsonx-ai-python-sdk/fm_model.html#metanames.GenTextParamsMetaNames\" target=\"_blank\" rel=\"GenTextParamsMetaNames params\">documentation</a>."}, {"metadata": {}, "cell_type": "markdown", "source": "Initialize the `Promtp` class.\n\n**Hint:** Your authentication token might expire, if so please regenerate the `access_token` reinitialize the `Promtp` class."}, {"metadata": {}, "cell_type": "code", "source": "prompt = Prompt(access_token, project_id)", "execution_count": 19, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "List of all possible NERs: As we do not have ground truth entity extraction data for this dataset, we use an open source package to get the list of named entities"}, {"metadata": {}, "cell_type": "code", "source": "list_of_NERS=nlp.get_pipe('ner').labels\nprint(list_of_NERS)", "execution_count": 20, "outputs": [{"name": "stdout", "output_type": "stream", "text": "('CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Define the instruction"}, {"metadata": {}, "cell_type": "code", "source": "instruction=\"\"\"\nAccurately identify and classify named entities in text. The list of possible labels are:['CARDINAL','DATE','EVENT','FAC','GPE','LANGUAGE','LAW',\n'LOC','MONEY','NORP','ORDINAL','ORG','PERCENT','PERSON','PRODUCT','QUANTITY','TIME','WORK_OF_ART'].\n\nReturn your responses in dictionary format. for the each found item, provide the \"phrase\" and\nthe corresponding \"label\" along with their number as dictionary keys separated by numbers. \nEncapsulate the phrases and labels in single quotation mark. \nFor instance, 'phrase_0':'London', 'label_0':'LOC', 'phrase_1':'Mount Everest', 'label_1':'LOC', and so on.\nUse the following training examples as follows:\n\"\"\"", "execution_count": 21, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(instruction)", "execution_count": 22, "outputs": [{"name": "stdout", "output_type": "stream", "text": "\nAccurately identify and classify named entities in text. The list of possible labels are:['CARDINAL','DATE','EVENT','FAC','GPE','LANGUAGE','LAW',\n'LOC','MONEY','NORP','ORDINAL','ORG','PERCENT','PERSON','PRODUCT','QUANTITY','TIME','WORK_OF_ART'].\n\nReturn your responses in dictionary format. for the each found item, provide the \"phrase\" and\nthe corresponding \"label\" along with their number as dictionary keys separated by numbers. \nEncapsulate the phrases and labels in single quotation mark. \nFor instance, 'phrase_0':'London', 'label_0':'LOC', 'phrase_1':'Mount Everest', 'label_1':'LOC', and so on.\nUse the following training examples as follows:\n\n"}]}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "results = []\nfor inp in few_shot_inputs_[:40]:\n    results.append(prompt.generate(\" \".join([instruction+examples_input+ \"document:\" +inp['input']]), model_id, parameters))", "execution_count": 23, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "json_formatted_str = json.dumps(results[:4], indent=4)\nprint(json_formatted_str)", "execution_count": 25, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[\n    {\n        \"generated_text\": \"['control knob', 'ORG', 'LOC', 'PERSON', 'EVENT', 'LANGUAGE', 'PERCENT', 'ORG', 'PERSON', 'PERCENT', 'PERSON', 'PERCENT', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON'\",\n        \"generated_token_count\": 150,\n        \"input_token_count\": 935,\n        \"stop_reason\": \"max_tokens\"\n    },\n    {\n        \"generated_text\": \"phrase_0: \\\"The Rio Grande\\\", 'label_0': 'LOC', 'phrase_1': 'feast or famine', 'label_1': 'LOC', 'phrase_2': 'a dry year or two typically followed by a couple of wet years that allow for recovery', 'label_2': 'LOC', 'phrase_3': 'a couple of wet years', 'label_3': 'LOC', 'phrase_4': 'recovery', 'label_4'\",\n        \"generated_token_count\": 150,\n        \"input_token_count\": 950,\n        \"stop_reason\": \"max_tokens\"\n    },\n    {\n        \"generated_text\": \"phrase_0': Mountain West', 'label_0': 'LOC', 'phrase_1': Pacific Northwest', 'label_1': 'LOC', 'phrase_2': 'Days of near-100-degree-Fahrenheit temperatures cooked the Mountain West in early July, and a scorching heat wave lingered over the Pacific Northwest in early August.', 'label_2': 'LOC', 'label_3': 'DATE', 'label_4': 'EVENT', 'label_5': '\",\n        \"generated_token_count\": 150,\n        \"input_token_count\": 950,\n        \"stop_reason\": \"max_tokens\"\n    },\n    {\n        \"generated_text\": \"'phrase_0': 'carbon dioxide emissions', 'label_0': 'QUANTITY', 'phrase_1': 'temperature', 'label_1': 'TIME', 'phrase_2': 'our lifetime', 'label_2': 'PERSON'\",\n        \"generated_token_count\": 85,\n        \"input_token_count\": 926,\n        \"stop_reason\": \"eos_token\"\n    }\n]\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Explore model output."}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "for i in range(len(results)):\n    print('--------------------------------------------------')\n    print(f\"Document #{i}:\\n{few_shot_inputs_[i]['input']}\")\n    print(f'Raw results from LLM model:\\n ',results[i]['generated_text'])\n    print('--------------------------------------------------')", "execution_count": 26, "outputs": [{"name": "stdout", "output_type": "stream", "text": "--------------------------------------------------\nDocument #0:\nMost likely the primary control knob [on climate change] is the ocean waters and this environment that we live in.\nRaw results from LLM model:\n  ['control knob', 'ORG', 'LOC', 'PERSON', 'EVENT', 'LANGUAGE', 'PERCENT', 'ORG', 'PERSON', 'PERCENT', 'PERSON', 'PERCENT', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON'\n--------------------------------------------------\n--------------------------------------------------\nDocument #1:\nThe Rio Grande is a classic \u201cfeast or famine\u201d river, with a dry year or two typically followed by a couple of wet years that allow for recovery.\nRaw results from LLM model:\n  phrase_0: \"The Rio Grande\", 'label_0': 'LOC', 'phrase_1': 'feast or famine', 'label_1': 'LOC', 'phrase_2': 'a dry year or two typically followed by a couple of wet years that allow for recovery', 'label_2': 'LOC', 'phrase_3': 'a couple of wet years', 'label_3': 'LOC', 'phrase_4': 'recovery', 'label_4'\n--------------------------------------------------\n--------------------------------------------------\nDocument #2:\nDays of near-100-degree-Fahrenheit temperatures cooked the Mountain West in early July, and a scorching heat wave lingered over the Pacific Northwest in early August.\u201d\nRaw results from LLM model:\n  phrase_0': Mountain West', 'label_0': 'LOC', 'phrase_1': Pacific Northwest', 'label_1': 'LOC', 'phrase_2': 'Days of near-100-degree-Fahrenheit temperatures cooked the Mountain West in early July, and a scorching heat wave lingered over the Pacific Northwest in early August.', 'label_2': 'LOC', 'label_3': 'DATE', 'label_4': 'EVENT', 'label_5': '\n--------------------------------------------------\n--------------------------------------------------\nDocument #3:\nIn our lifetime, there has been no correlation between carbon dioxide emissions and temperature\nRaw results from LLM model:\n  'phrase_0': 'carbon dioxide emissions', 'label_0': 'QUANTITY', 'phrase_1': 'temperature', 'label_1': 'TIME', 'phrase_2': 'our lifetime', 'label_2': 'PERSON'\n--------------------------------------------------\n--------------------------------------------------\nDocument #4:\nThere is no way for us to prevent the world\u2019s CO2 emissions    from doubling by 2100\"\nRaw results from LLM model:\n  phrase_0': 'CO2 emissions', 'label_0': 'QUANTITY', 'phrase_1': 'from doubling by 2100', 'label_1': 'DATE', 'phrase_2': 'world\u2019s', 'label_2': 'CO2', 'phrase_3': 'from doubling by 2100', 'label_3': 'DATE', 'phrase_4': 'There is no way for us to prevent the world\u2019s CO2 emissions from doubling by 2100', \n--------------------------------------------------\n--------------------------------------------------\nDocument #5:\nWu et al (2010) use a new method to calculate ice sheet mass balance.\nRaw results from LLM model:\n  'phrase_0': 'Wu et al', 'label_0': 'PERSON', 'phrase_1': '(2010)', 'label_1': 'DATE'\n--------------------------------------------------\n--------------------------------------------------\nDocument #6:\nIn the last 35 years of global warming, sun and climate have been going in opposite directions.\nRaw results from LLM model:\n  ['35 years', 'ORDER', 'CARDINAL', 'LAW', 'PERSON', 'PERCENT', 'QUANTITY', 'PERCENT', 'PERSON', 'PERCENT', 'PERSON', 'PERCENT', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'PER\n--------------------------------------------------\n--------------------------------------------------\nDocument #7:\nAustralia has more solar coverage than any other continent.\nRaw results from LLM model:\n  'phrase_0': 'Australia', 'label_0': 'LOC'\n--------------------------------------------------\n--------------------------------------------------\nDocument #8:\nPolar bears are in danger of extinction as well as many other species.\nRaw results from LLM model:\n  'phrase_0': 'Polar bears', 'label_0': 'FAC', 'phrase_1': 'many other species', 'label_1': 'FAC'\n--------------------------------------------------\n--------------------------------------------------\nDocument #9:\nThe United States has been restricting soot emissions  in Draconian fashion since the Clean Air Act of 1963.\nRaw results from LLM model:\n  phrase_0': \"The United States\" , 'label_0': 'LOC', 'phrase_1': \"Draconian fashion\" , 'label_1': 'LAW', 'phrase_2': \"Clean Air Act\" , 'label_2': 'LAW', 'phrase_3': '1963', 'label_3': 'DATE'\n--------------------------------------------------\n--------------------------------------------------\nDocument #10:\nThe costs of inaction far outweigh the costs of mitigation.\nRaw results from LLM model:\n  'phrase_0': 'costs of inaction', 'label_0': 'QUANTITY', 'phrase_1': 'costs of mitigation', 'label_1': 'QUANTITY'\n--------------------------------------------------\n--------------------------------------------------\nDocument #11:\n\u201cIn their award winning book, \u2018Taken By Storm\u2019 (2007), Canadian researchers Christopher Essex and Ross McKitrick explain: \u2018Temperature is not an amount of something [like height or weight].\nRaw results from LLM model:\n  'phrase_0': 'Taken By Storm\u2019 ', 'label_0': 'BOOK', 'phrase_1': 'Canadian', 'label_1': 'LOC', 'phrase_2': 'Christopher Essex', 'label_2': 'PERSON', 'phrase_3': 'Ross McKitrick', 'label_3': 'PERSON', 'phrase_4': 'Temperature', 'label_4': 'PRODUCT'\n--------------------------------------------------\n--------------------------------------------------\nDocument #12:\nGreg Hunt CSIRO research shows carbon emissions can be reduced by 20 per cent over 40 years using nature, soils and trees.\nRaw results from LLM model:\n  'phrase_0': 'Greg Hunt CSIRO', 'label_0': 'ORG', 'phrase_1': 'research shows carbon emissions can be reduced by 20 per cent over 40 years using nature, soils and trees', 'label_1': 'PERCENT'\n--------------------------------------------------\n--------------------------------------------------\nDocument #13:\nWith that in mind, they propose a plausible and terrifying \u201c2050 scenario\u201d whereby humanity could face irreversible collapse in just three decades.\nRaw results from LLM model:\n  ['2050 scenario', 'label_0': 'PERSON', 'label_1': '2050', 'label_2': 'scenario', 'label_3': 'irreversible collapse', 'label_4': 'three decades']\n--------------------------------------------------\n--------------------------------------------------\nDocument #14:\nNo known natural forcing fits the fingerprints of observed warming except anthropogenic greenhouse gases.\nRaw results from LLM model:\n  'phrase_0': 'known natural forcing', 'label_0': 'FAC', 'phrase_1': 'anthropogenic greenhouse gases', 'label_1': 'FAC'\n--------------------------------------------------\n--------------------------------------------------\nDocument #15:\nWe know the Northwest Passage had been open before.\"\nRaw results from LLM model:\n  phrase_0': \"the Northwest Passage had been open before.\", 'label_0': 'NORP', 'phrase_1': 'We know', 'label_1': 'PERSON'\n--------------------------------------------------\n--------------------------------------------------\nDocument #16:\nMass coral bleaching is a new phenomenon and was never observed before the 1980s as global warming ramped up.\nRaw results from LLM model:\n  'phrase_0': 'Mass coral bleaching', 'label_0': 'FAC', 'phrase_1': 'new phenomenon', 'label_1': 'GPE', 'phrase_2': 'was never observed before the 1980s', 'label_2': 'EVENT', 'phrase_3': 'global warming ramped up', 'label_3': 'GPE', 'phrase_4': 'before the 1980s', 'label_4': 'DATE'\n--------------------------------------------------\n--------------------------------------------------\nDocument #17:\n[S]unspot activity on the surface of our star has dropped to a new low.\nRaw results from LLM model:\n  ['phrase_0': 's]unspot activity', 'label_0': 'FAC']\n--------------------------------------------------\n--------------------------------------------------\nDocument #18:\nCarbon dioxide is a trace gas.\u201d\nRaw results from LLM model:\n  phrase_0: \"Carbon dioxide is a trace gas.\", 'label_0': 'QUANTITY', 'phrase_1': 'Carbon dioxide', 'label_1': 'TRACE_GAS'\n--------------------------------------------------\n--------------------------------------------------\nDocument #19:\nArctic sea ice has been steadily thinning, even in the last few years while the surface ice (eg - sea ice extent) increased slightly.\nRaw results from LLM model:\n  ['Arctic sea ice', 'label_0': 'LOC', 'label_1': 'FAC', 'label_2': 'ORG', 'label_3': 'PERSON', 'label_4': 'PERCENT', 'label_5': 'QUANTITY', 'label_6': 'PERCENT', 'label_7': 'PERSON', 'label_8': 'PERCENT', 'label_9': 'PERSON\n--------------------------------------------------\n--------------------------------------------------\nDocument #20:\nThe consensus among scientists and policy-makers is that we\u2019ll pass this point of no return if the global mean temperature rises by more than two degrees Celsius.\nRaw results from LLM model:\n  ['point of no return', 'label_0': 'QUANTITY', 'point', 'label_1': 'QUANTITY', 'two degrees Celsius', 'label_2': 'QUANTITY', 'global mean temperature', 'label_3': 'QUANTITY', 'scientists', 'label_4': 'PERSON', 'policy-makers', 'label_5': 'PERSON']\n--------------------------------------------------\n--------------------------------------------------\nDocument #21:\nOver the last 30-40 years 80% of coral in the Caribbean have been destroyed and 50% in Indonesia and the Pacific.\nRaw results from LLM model:\n  ['Carribean', 'LOC'], ['Indonesia', 'LOC'], ['Pacific', 'LOC']]\n--------------------------------------------------\n--------------------------------------------------\nDocument #22:\nThere are about 120,000 solar energy jobs in the United States, but only 1,700 of them are in Georgia.\nRaw results from LLM model:\n  ['United States', 'LOC', 'Georgia', 'LOC']\n--------------------------------------------------\n--------------------------------------------------\nDocument #23:\nAll the indicators show that global warming is still happening.\nRaw results from LLM model:\n  'phrase_0': 'global warming', 'label_0': 'GPE'\n--------------------------------------------------\n--------------------------------------------------\nDocument #24:\nWhile there are isolated cases of growing glaciers, the overwhelming trend in glaciers worldwide is retreat.\nRaw results from LLM model:\n  ['grow glaciers', 'label_0': 'LOC', 'grow glaciers', 'label_1': 'LOC', 'grow glaciers', 'label_2': 'LOC', 'grow glaciers', 'label_3': 'LOC', 'grow glaciers', 'label_4': 'LOC', 'grow glaciers', 'label_5': 'LOC', 'grow glaciers', 'label_6': '\n--------------------------------------------------\n--------------------------------------------------\nDocument #25:\n\"The 30 major droughts of the 20th century were likely\u00a0natural\u00a0in all respects; and, hence, they are \"indicative of what could also happen in the future,\" as Narisma\nRaw results from LLM model:\n  'phrase_0': \"The 30 major droughts of the 20th century were likely natural in all respects; and, hence, they are \"indicative of what could also happen in the future,\" as narisma', 'label_0': 'PERSON', 'label_1': 'ORG', 'label_2': 'PERCENT', 'label_3': 'ORG', 'label_4': 'PERCENT', 'label_5': 'PERSON', 'label_6': 'PERSON\n--------------------------------------------------\n--------------------------------------------------\nDocument #26:\nPrevious IPCC reports tended to assume that clouds would have a neutral impact because the warming and cooling feedbacks would cancel each other out.\nRaw results from LLM model:\n  'phrase_0': 'IPCC', 'label_0': 'ORG', 'phrase_1': 'reports', 'label_1': 'EVENT', 'phrase_2': 'would cancel each other out', 'label_2': 'warming and cooling feedbacks'\n--------------------------------------------------\n--------------------------------------------------\nDocument #27:\nMeasurements indicating that 2017 had relatively more sea ice in the Arctic and less melting of glacial ice in Greenland casts scientific doubt on the reality of global warming.\nRaw results from LLM model:\n  ['Arctic', 'label_0': 'LOC', 'Greenland', 'label_1': 'LOC', 'label_2': 'LOC', 'label_3': 'LOC', 'label_4': 'LOC', 'label_5': 'LOC', 'label_6': 'LOC', 'label_7': 'LOC', 'label_8': 'LOC', 'label_9': \n--------------------------------------------------\n--------------------------------------------------\nDocument #28:\nIt has never been shown that human emissions of carbon dioxide drive global warming.\nRaw results from LLM model:\n  ['human emissions', 'label_0': 'PERCENT', 'human emissions', 'label_1': 'CO2', 'label_2': 'global warming']\n--------------------------------------------------\n--------------------------------------------------\nDocument #29:\ncutting speed limits could slow climate change\nRaw results from LLM model:\n  'phrase_0': 'cutting speed limits', 'label_0': 'QUANTITY', 'phrase_1': 'could slow climate change', 'label_1': 'QUANTITY'\n--------------------------------------------------\n--------------------------------------------------\nDocument #30:\nResearch has found a human influence on the climate of the past several decades ...\nRaw results from LLM model:\n  'phrase_0': 'human influence', 'label_0': 'ORG', 'phrase_1': 'on the climate of the past several decades', 'label_1': 'ORG', 'phrase_2': 'Research has found', 'label_2': 'ORG', 'phrase_3': 'on the climate of the past several decades', 'label_3': 'ORG', 'phrase_4': 'Research has found', 'label_4': 'ORG\n--------------------------------------------------\n--------------------------------------------------\nDocument #31:\nBy 2100 the seas will rise another 6 inches or so\u2014a far cry from Al Gore\u2019s alarming numbers\nRaw results from LLM model:\n  'phrase_0': 'Al Gore\u2019s', 'label_0': 'PERSON', 'phrase_1': 'alarming numbers', 'label_1': 'PERSON', 'phrase_2': '6 inches', 'label_2': 'QUANTITY', 'phrase_3': '2100', 'label_3': 'DATE'\n--------------------------------------------------\n--------------------------------------------------\nDocument #32:\nMultiple lines of independent evidence indicate humidity is rising and provides positive feedback.\nRaw results from LLM model:\n  'phrase_0': 'multiple lines of independent evidence', 'label_0': 'PERCENT'\n--------------------------------------------------\n--------------------------------------------------\nDocument #33:\na study that totally debunks the whole concept of man-made Global Warming\nRaw results from LLM model:\n  'phrase_0': 'Global Warming', 'label_0': 'GPE', 'phrase_1': 'man-made', 'label_1': 'GPE', 'phrase_2': 'concept', 'label_2': 'GPE', 'phrase_3': 'whole', 'label_3': 'GPE', 'phrase_4': 'concept', 'label_4': 'GPE', 'phrase_5': 'whole concept\n--------------------------------------------------\n--------------------------------------------------\nDocument #34:\nClaims have recently surfaced in the blogosphere that an increasing number of scientists are warning of an imminent global cooling, some even going so far as to call it a \"growing consensus\".\nRaw results from LLM model:\n  ['phrase_0': 'blogosphere', 'label_0': 'LOC', 'phrase_1': 'increasing number of scientists', 'label_1': 'PERSON', 'phrase_2': 'global cooling', 'label_2': 'EVENT', 'phrase_3': 'growing consensus', 'label_3': 'PERSON']\n--------------------------------------------------\n--------------------------------------------------\nDocument #35:\nThe extent of climate change\u2019s influence on the jet stream is an intense subject of research.\nRaw results from LLM model:\n  'phrase_0': 'climate change\u2019s influence', 'label_0': 'ORG', 'phrase_1': 'jet stream', 'label_1': 'REGION', 'phrase_2': 'research', 'label_2': 'ORG', 'phrase_3': 'intense', 'label_3': 'ORG', 'phrase_4': 'subject', 'label_4': 'ORG', 'phrase_5':\n--------------------------------------------------\n--------------------------------------------------\nDocument #36:\nCO2 limits won't cool the planet.\nRaw results from LLM model:\n  'phrase_0': 'CO2 limits', 'label_0': 'QUANTITY', 'phrase_1': 'cool the planet', 'label_1': 'ORDER', 'phrase_2': 'limits', 'label_2': 'CO2', 'phrase_3': 'CO2', 'label_3': 'ORDER', 'phrase_4': 'CO2', 'label_4': 'ORDER', 'phrase_5': 'CO2\n--------------------------------------------------\n--------------------------------------------------\nDocument #37:\n\u201cGlobal warming alarmists\u2019 preferred electricity source \u2013 wind power \u2013 kills nearly 1 million bats every year (to say nothing of the more than 500,000 birds killed every year) in the United States alone.\nRaw results from LLM model:\n  phrase_0': \"Global warming alarmists\u2019 preferred electricity source \u2013 wind power \u2013 kills nearly 1 million bats every year (to say nothing of the more than 500,000 birds killed every year) in the United States alone.\", 'label_0': 'LOC', 'phrase_1': 'United States', 'label_1': 'LOC'\n--------------------------------------------------\n--------------------------------------------------\nDocument #38:\nThey concluded that trends toward rising climate damages were mainly due to increased population and economic activity in the path of storms, that it was not currently possible to determine the portion of damages attributable to greenhouse gases, and that they didn\u2019t expect that situation to change in the near future.\nRaw results from LLM model:\n  ['They', 'label_0': 'PERSON', 'label_1': 'ORG', 'label_2': 'PERCENT', 'label_3': 'LAW', 'label_4': 'PERCENT', 'label_5': 'PERSON', 'label_6': 'PERCENT', 'label_7': 'PERSON', 'label_8': 'PERCENT', 'label_9': 'PERSON', 'label_\n--------------------------------------------------\n--------------------------------------------------\nDocument #39:\nHumans are too insignificant to affect global climate.\nRaw results from LLM model:\n  'phrase_0': 'Humans', 'label_0': 'PERSON', 'phrase_1': 'global climate', 'label_1': 'PERCENT'\n--------------------------------------------------\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Score the Model"}, {"metadata": {}, "cell_type": "markdown", "source": "First, we need to extract `y_true` by performing NER using **Spacy** package as the ground truth."}, {"metadata": {}, "cell_type": "code", "source": "# Process each document in the few_shot_inputs_\nfsi ={}\nfsi_list_for_ground_truth=[]\n\nfor document in few_shot_inputs_[:40]:\n    doc = nlp(document['input'].strip())  # Process the document with spacy NLP pipeline\n    if (len(doc.ents) != 0):\n        fsi ={}\n        fsi['document']=document['input']\n        for i, ent in enumerate(doc.ents):\n            fsi[f'phrase_{i}']=ent.text\n            fsi[f'label_{i}']=ent.label_\n        \n            \n        fsi_list_for_ground_truth.append(fsi)\n    else:\n        fsi_list_for_ground_truth.append({})", "execution_count": 27, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "json_formatted_str = json.dumps(fsi_list_for_ground_truth[:4], indent=4)\nprint(json_formatted_str)", "execution_count": 28, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[\n    {},\n    {\n        \"document\": \"The Rio Grande is a classic \\u201cfeast or famine\\u201d river, with a dry year or two typically followed by a couple of wet years that allow for recovery.\",\n        \"phrase_0\": \"The Rio Grande\",\n        \"label_0\": \"ORG\",\n        \"phrase_1\": \"a dry year\",\n        \"label_1\": \"DATE\",\n        \"phrase_2\": \"two\",\n        \"label_2\": \"CARDINAL\",\n        \"phrase_3\": \"a couple of wet years\",\n        \"label_3\": \"DATE\"\n    },\n    {\n        \"document\": \"Days of near-100-degree-Fahrenheit temperatures cooked the Mountain West in early July, and a scorching heat wave lingered over the Pacific Northwest in early August.\\u201d\",\n        \"phrase_0\": \"the Mountain West\",\n        \"label_0\": \"LOC\",\n        \"phrase_1\": \"early July\",\n        \"label_1\": \"DATE\",\n        \"phrase_2\": \"the Pacific Northwest\",\n        \"label_2\": \"LOC\",\n        \"phrase_3\": \"early August\",\n        \"label_3\": \"DATE\"\n    },\n    {}\n]\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Post processing the results so that they can be compared with the ground truth"}, {"metadata": {}, "cell_type": "code", "source": "def extract_dictionary_from_results(s):\n    \n    ss2=s.split(', ')\n    \n    pc=0\n    lc=0\n    for w in ss2:\n        if 'phrase_' in w:\n            pc+=1\n        if 'label_' in w:\n            lc+=1\n    if ((pc==lc) and ((pc%2)==0) and ((lc%2)==0)):\n        return (eval(\"{\"+s+\"}\"))\n    \n    elif((pc%2)!=0 or ((lc%2)!=0)):\n       \n        lim = min(pc,lc)\n        wlim = 2*lim\n        return (eval('{'+','.join(ss2[:wlim])+'}'))\n        ", "execution_count": 29, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "This function finds common words in two given phrases"}, {"metadata": {}, "cell_type": "code", "source": "def find_common_words(string1, string2):\n    words1 = set(string1.lower().split())\n    words2 = set(string2.lower().split())\n    common_words = words1.intersection(words2)\n    return list(common_words)", "execution_count": 30, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "This function removes unnecessary \"the\" and \"a\" from the given phrase"}, {"metadata": {}, "cell_type": "code", "source": "def drop_words(string):\n    words_to_drop = ['the', 'a']\n    pattern = r'\\b(?:{})\\b'.format('|'.join(words_to_drop))\n    cleaned_string = re.sub(pattern, '', string, flags=re.IGNORECASE)\n    return cleaned_string.strip()", "execution_count": 31, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "This function handles imbalanced quotation marks"}, {"metadata": {}, "cell_type": "code", "source": "def polish_results(r):\n    \n    sp=r.split(',')\n    \n    nw=[]\n    for w in sp:\n        b=''\n        b=w.replace('\"', '').replace(\"'\", \"\")\n        nw.append(b)\n    \n    msl=[]\n    for w in nw:\n        ns=w.split(\":\")\n        nss=[]\n        for i in range(len(ns)):\n            ns[i]=ns[i].lstrip()\n        nss.append(\"'\"+ns[0]+\"'\"+':'+\"'\"+ns[1]+\"'\")\n\n        ms=''.join(nss)\n        msl.append(ms)\n\n    res=','.join(msl)\n    \n    return res", "execution_count": 32, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The performance of the model can be compared to ground truth labels. The code below handles this task by comparing the identified phrases, which are common in both ground truth and model results. This task is done by ignoring the order which phrases appear in both ground truth and LLMs results and comparing the lenght of common words in both of them."}, {"metadata": {}, "cell_type": "code", "source": "y_true=[]\ny_pred=[]\n\nfor i in range(len(fsi_list_for_ground_truth)):\n    \n    try:\n        keys=fsi_list_for_ground_truth[i].keys()\n        if (len(keys) !=0):\n            temp_s = copy.deepcopy(fsi_list_for_ground_truth[i])\n            del temp_s['document']\n            \n            \n            ground_truth_keys = list(temp_s.keys())\n            ground_truth_values = list(temp_s.values())\n            \n            model_results=extract_dictionary_from_results(polish_results(results[i]['generated_text']))\n            \n            model_res_keys=list(model_results.keys())\n            model_res_values=list(model_results.values())\n            \n          \n            \n            for k in ground_truth_keys:\n                if ('phrase_' in k):\n                    \n                    phrase=temp_s[k]\n                    \n                    for v in model_res_values:\n                        if (len(find_common_words(drop_words(phrase),drop_words(v)))/len(phrase.split())>0.5):\n                            ground_truth_label = temp_s['label_'+(ground_truth_keys[ground_truth_values.index(phrase)].strip('phrase_'))]\n                            model_res_label=model_results['label_'+(model_res_keys[model_res_values.index(v)].strip('phrase_'))]\n                            \n                            if (model_res_label==ground_truth_label):\n                                y_true.append(1)\n                                y_pred.append(1)\n                            else:\n                                y_true.append(1)\n                                y_pred.append(0)\n                            \n    except:\n        pass\n        \n        \nlen_y_true = len(y_true)\nlen_y_pred = len(y_pred)\n\nfsi_ners=copy.deepcopy(fsi_list_for_ground_truth)\n\ntry:\n    del fsi_ners['document']\n    \nexcept:\n    pass\n        ", "execution_count": 33, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "len_y_true = len(y_true)\nlen_y_pred = len(y_pred)\n\nfor i in range(len(fsi_list_for_ground_truth)):\n    fsi_ners=copy.deepcopy(fsi_list_for_ground_truth[i])\n    try:\n        del fsi_ners['document']\n       \n        \n        model_ners=extract_dictionary_from_results(results[i]['generated_text'])\n       \n        \n        if (len(fsi_ners)>len(model_ners)):\n            diff = len(fsi_ners)-len(model_ners)\n            \n            for j in range(len(diff)):\n                y_true.append(1)\n                y_pred.append(0)\n    except:\n        pass", "execution_count": 34, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(y_true)", "execution_count": 35, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"}]}, {"metadata": {}, "cell_type": "code", "source": "print(y_pred)", "execution_count": 36, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0]\n"}]}, {"metadata": {}, "cell_type": "code", "source": "print(classification_report(y_pred=y_pred,y_true=y_true))", "execution_count": 37, "outputs": [{"name": "stdout", "output_type": "stream", "text": "              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         0\n           1       1.00      0.47      0.64        15\n\n    accuracy                           0.47        15\n   macro avg       0.50      0.23      0.32        15\nweighted avg       1.00      0.47      0.64        15\n\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Let's only apply for single entity of Location"}, {"metadata": {}, "cell_type": "markdown", "source": "# SINGLE ENTITY\nSingle entity case: We tried a single entity extraction as well. It is essential to consider the quality of the extraction process. If the objective is to extract multiple entity types and the accuracy is not good enough,you may want to experiment with a smaller set of entity types at a time to see whether the accuracy can be improved (as there are more examples of that entity type that can fit in the context of the model, compared to the case of many entity types). \n\nHere, we are trying to experiment with a single entity type."}, {"metadata": {}, "cell_type": "code", "source": "specific_label = 'LOC'\ndesc = 'location'", "execution_count": 38, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "label_replacement_dictionary={'GPE':'LOC'}", "execution_count": 39, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "instruction=f\"\"\"\nAccurately identify and classify the \nNERs of type {desc} ({specific_label}).\n\nReturn your responses in dictionary format. for the each item you found, provide the \"phrase\" and\nthe corresponding \"label\" along with their number as dictionary key separated by numbers. \nIncrement the 'phrase_' and 'label_' for the next NER.Each 'phrase_' should be coupled with a 'label_'.\nMake sure to encapsulate the found phrases and labels in single quotation mark.\nFor instance, 'phrase_0':'London', 'label_0':'LOC', 'phrase_1':'Mount Everest', 'label_1':'LOC', and so on.\nUse the following training examples as follows:\n\n\"\"\"", "execution_count": 40, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(instruction)", "execution_count": 41, "outputs": [{"name": "stdout", "output_type": "stream", "text": "\nAccurately identify and classify the \nNERs of type location (LOC).\n\nReturn your responses in dictionary format. for the each item you found, provide the \"phrase\" and\nthe corresponding \"label\" along with their number as dictionary key separated by numbers. \nIncrement the 'phrase_' and 'label_' for the next NER.Each 'phrase_' should be coupled with a 'label_'.\nMake sure to encapsulate the found phrases and labels in single quotation mark.\nFor instance, 'phrase_0':'London', 'label_0':'LOC', 'phrase_1':'Mount Everest', 'label_1':'LOC', and so on.\nUse the following training examples as follows:\n\n\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "This function replaces the ground truth lables with the desired one as mentioned in the replacement dictionary."}, {"metadata": {}, "cell_type": "code", "source": "def replace_label_values(examples,label_replacement_dictionary):\n    examples_cp = copy.deepcopy(examples)\n    for i in range(len(examples_cp)):\n        keys = list(examples_cp[i].keys())\n        for k in keys:\n            if 'label_' in k:\n                for rl in label_replacement_dictionary.keys():\n                    if (examples_cp[i][k] == rl):\n                        examples_cp[i][k]=label_replacement_dictionary[rl]\n    return examples_cp", "execution_count": 42, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "post_processed_examples = replace_label_values(example_dic_list,label_replacement_dictionary)", "execution_count": 43, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "json_formatted_str = json.dumps(post_processed_examples[:4], indent=4)\nprint(json_formatted_str)", "execution_count": 44, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[\n    {\n        \"document\": \"\\\"In 1999\\u00a0New Scientist\\u00a0reported a comment by the leading Indian glaciologist Syed Hasnain, who said in an email interview with this author that all the glaciers in the central and eastern Himalayas\\u00a0could disappear by 2035.\",\n        \"phrase_0\": \"1999\",\n        \"label_0\": \"DATE\",\n        \"phrase_1\": \"Indian\",\n        \"label_1\": \"NORP\",\n        \"phrase_2\": \"Syed Hasnain\",\n        \"label_2\": \"PERSON\",\n        \"phrase_3\": \"Himalayas\",\n        \"label_3\": \"LOC\",\n        \"phrase_4\": \"2035\",\n        \"label_4\": \"DATE\"\n    },\n    {\n        \"document\": \"\\\"We found [U.S. weather] stations located next to  the exhaust fans of air conditioning units, surrounded by asphalt  parking lots and roads,\\u00a0on blistering-hot rooftops, and near sidewalks  and buildings that absorb and radiate heat.\",\n        \"phrase_0\": \"U.S.\",\n        \"label_0\": \"LOC\"\n    },\n    {\n        \"document\": \"Skeptics who oppose scientific findings that threaten their world view are far closer to Galileo's belief-based critics in the Catholic Church.\",\n        \"phrase_0\": \"Galileo\",\n        \"label_0\": \"PRODUCT\",\n        \"phrase_1\": \"the Catholic Church\",\n        \"label_1\": \"ORG\"\n    },\n    {\n        \"document\": \"Pollard and DeConto are the first to admit that their model is still crude, but its results have pushed the entire scientific community into emergency mode.\",\n        \"phrase_0\": \"DeConto\",\n        \"label_0\": \"LOC\",\n        \"phrase_1\": \"first\",\n        \"label_1\": \"ORDINAL\"\n    }\n]\n"}]}, {"metadata": {}, "cell_type": "code", "source": "def keep_only_certain_labels(examples, specific_label):\n    list_of_modified_examples=[]\n    for e in examples:\n        e_cp = copy.deepcopy(e)\n        keys = list(e_cp.keys())\n        \n        for k in keys:\n            if 'label_' in k:\n                numeric_val = k.split('label_')[1]\n                #print('NV=',numeric_val)\n                if (e_cp[k]!=specific_label):\n                    del e_cp[k]\n                    del e_cp['phrase_'+numeric_val]\n        \n        if(len(e_cp)>1):\n            list_of_modified_examples.append(e_cp)\n    \n    return list_of_modified_examples", "execution_count": 45, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "modified_examples_list = keep_only_certain_labels(post_processed_examples, specific_label)", "execution_count": 46, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "json_formatted_str = json.dumps(modified_examples_list, indent=4)\nprint(json_formatted_str)", "execution_count": 47, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[\n    {\n        \"document\": \"\\\"In 1999\\u00a0New Scientist\\u00a0reported a comment by the leading Indian glaciologist Syed Hasnain, who said in an email interview with this author that all the glaciers in the central and eastern Himalayas\\u00a0could disappear by 2035.\",\n        \"phrase_3\": \"Himalayas\",\n        \"label_3\": \"LOC\"\n    },\n    {\n        \"document\": \"\\\"We found [U.S. weather] stations located next to  the exhaust fans of air conditioning units, surrounded by asphalt  parking lots and roads,\\u00a0on blistering-hot rooftops, and near sidewalks  and buildings that absorb and radiate heat.\",\n        \"phrase_0\": \"U.S.\",\n        \"label_0\": \"LOC\"\n    },\n    {\n        \"document\": \"Pollard and DeConto are the first to admit that their model is still crude, but its results have pushed the entire scientific community into emergency mode.\",\n        \"phrase_0\": \"DeConto\",\n        \"label_0\": \"LOC\"\n    },\n    {\n        \"document\": \"the world is barely half a degree Celsius (0.9 degrees Fahrenheit) warmer than it was about 35 years ago\",\n        \"phrase_2\": \"Fahrenheit\",\n        \"label_2\": \"LOC\"\n    }\n]\n"}]}, {"metadata": {}, "cell_type": "code", "source": "examples=[]", "execution_count": 48, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "for i in range(len(modified_examples_list)):\n    examples.append('document: \\n'+modified_examples_list[i]['document']+'\\n')\n    di=copy.deepcopy(modified_examples_list[i])\n    del di['document']\n    examples.append('\\n')\n    examples.append(str(di))\n    examples.append('\\n\\n\\n')", "execution_count": 49, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "examples_input=''.join(examples)", "execution_count": 50, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(examples_input)", "execution_count": 51, "outputs": [{"name": "stdout", "output_type": "stream", "text": "document: \n\"In 1999\u00a0New Scientist\u00a0reported a comment by the leading Indian glaciologist Syed Hasnain, who said in an email interview with this author that all the glaciers in the central and eastern Himalayas\u00a0could disappear by 2035.\n\n{'phrase_3': 'Himalayas', 'label_3': 'LOC'}\n\n\ndocument: \n\"We found [U.S. weather] stations located next to  the exhaust fans of air conditioning units, surrounded by asphalt  parking lots and roads,\u00a0on blistering-hot rooftops, and near sidewalks  and buildings that absorb and radiate heat.\n\n{'phrase_0': 'U.S.', 'label_0': 'LOC'}\n\n\ndocument: \nPollard and DeConto are the first to admit that their model is still crude, but its results have pushed the entire scientific community into emergency mode.\n\n{'phrase_0': 'DeConto', 'label_0': 'LOC'}\n\n\ndocument: \nthe world is barely half a degree Celsius (0.9 degrees Fahrenheit) warmer than it was about 35 years ago\n\n{'phrase_2': 'Fahrenheit', 'label_2': 'LOC'}\n\n\n\n"}]}, {"metadata": {}, "cell_type": "code", "source": "results = []\nfor inp in few_shot_inputs_[:40]:\n    results.append(prompt.generate(\" \".join([instruction+examples_input+ \"document:\" +inp['input']]), model_id, parameters))", "execution_count": 52, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "json_formatted_str = json.dumps(results[:4], indent=4)\nprint(json_formatted_str)", "execution_count": 53, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[\n    {\n        \"generated_text\": \"phrase_0: \\\"the ocean waters and this environment that we live in.\\\", 'label_0': 'LOC'\",\n        \"generated_token_count\": 31,\n        \"input_token_count\": 495,\n        \"stop_reason\": \"eos_token\"\n    },\n    {\n        \"generated_text\": \"phrase_0: \\\"The Rio Grande\\\", 'label_0': 'LOC'\",\n        \"generated_token_count\": 24,\n        \"input_token_count\": 510,\n        \"stop_reason\": \"eos_token\"\n    },\n    {\n        \"generated_text\": \"phrase_0': \\\"the Mountain West\\\", 'label_0': 'LOC', phrase_1': \\\"the Pacific Northwest\\\", 'label_1': 'LOC'\",\n        \"generated_token_count\": 48,\n        \"input_token_count\": 510,\n        \"stop_reason\": \"eos_token\"\n    },\n    {\n        \"generated_text\": \"phrase_0: carbon dioxide emissions label_0: 'LOC'\",\n        \"generated_token_count\": 21,\n        \"input_token_count\": 486,\n        \"stop_reason\": \"eos_token\"\n    }\n]\n"}]}, {"metadata": {}, "cell_type": "code", "source": "def polish_results(r):\n    \n    sp=r.split(',')\n    \n    nw=[]\n    for w in sp:\n        b=''\n        b=w.replace('\"', '').replace(\"'\", \"\")\n        nw.append(b)\n        \n    msl=[]\n    for w in nw:\n        ns=w.split(\":\")\n        nss=[]\n        for i in range(len(ns)):\n            ns[i]=ns[i].lstrip()\n        nss.append(\"'\"+ns[0]+\"'\"+':'+\"'\"+ns[1]+\"'\")\n\n        ms=''.join(nss)\n        msl.append(ms)\n\n    res=','.join(msl)\n    \n    return res", "execution_count": 54, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(polish_results(results[2]['generated_text']))", "execution_count": 55, "outputs": [{"name": "stdout", "output_type": "stream", "text": "'phrase_0':'the Mountain West','label_0':'LOC','phrase_1':'the Pacific Northwest','label_1':'LOC'\n"}]}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "print(extract_dictionary_from_results(polish_results(results[2]['generated_text'])))", "execution_count": 56, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{'phrase_0': 'the Mountain West', 'label_0': 'LOC', 'phrase_1': 'the Pacific Northwest', 'label_1': 'LOC'}\n"}]}, {"metadata": {}, "cell_type": "code", "source": "print(extract_dictionary_from_results(polish_results(results[0]['generated_text'])))", "execution_count": 57, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{'phrase_0': 'the ocean waters and this environment that we live in.', 'label_0': 'LOC'}\n"}]}, {"metadata": {}, "cell_type": "code", "source": "y_true=[]\ny_pred=[]\n\nfor i in range(len(fsi_list_for_ground_truth)):\n    try:\n        keys=fsi_list_for_ground_truth[i].keys()\n        if (len(keys) !=0):\n            temp_s = copy.deepcopy(fsi_list_for_ground_truth[i])\n            del temp_s['document']\n      \n            \n            ground_truth_keys = list(temp_s.keys())\n            ground_truth_values = list(temp_s.values())\n            \n            model_results=extract_dictionary_from_results(polish_results(results[i]['generated_text']))\n            \n            model_res_keys=list(model_results.keys())\n            model_res_values=list(model_results.values())\n            \n            \n            \n            for k in ground_truth_keys:\n                if ('phrase_' in k):\n                  \n                    phrase=temp_s[k]\n                   \n                    for v in model_res_values:\n                        if (len(find_common_words(drop_words(phrase),drop_words(v)))/len(phrase.split())>0.5):\n\n                            ground_truth_label = temp_s['label_'+(ground_truth_keys[ground_truth_values.index(phrase)].strip('phrase_'))]\n                            \n                            if (ground_truth_label==specific_label):\n                                model_res_label=model_results['label_'+(model_res_keys[model_res_values.index(v)].strip('phrase_'))]\n\n                                if (model_res_label==ground_truth_label):\n                                    y_true.append(1)\n                                    y_pred.append(1)\n                                else:\n                                    y_true.append(1)\n                                    y_pred.append(0)\n\n    except:\n        pass\n        \n        \nlen_y_true = len(y_true)\nlen_y_pred = len(y_pred)\n\nfsi_ners=copy.deepcopy(fsi_list_for_ground_truth)\n\ntry:\n    del fsi_ners['document']\n    \nexcept:\n    pass\n        ", "execution_count": 58, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "len_y_true = len(y_true)\nlen_y_pred = len(y_pred)\n\nfor i in range(len(fsi_list_for_ground_truth)):\n    fsi_ners=copy.deepcopy(fsi_list_for_ground_truth[i])\n    try:\n        del fsi_ners['document']\n        \n        \n        model_ners=extract_dictionary_from_results(results[i]['generated_text'])\n       \n        \n        if (len(fsi_ners)>len(model_ners)):\n            diff = len(fsi_ners)-len(model_ners)\n            \n            for j in range(len(diff)):\n                y_true.append(1)\n                y_pred.append(0)\n    except:\n        pass", "execution_count": 59, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "y_pred", "execution_count": 60, "outputs": [{"data": {"text/plain": "[1, 1, 1, 1]"}, "execution_count": 60, "metadata": {}, "output_type": "execute_result"}]}, {"metadata": {}, "cell_type": "code", "source": "y_true", "execution_count": 61, "outputs": [{"data": {"text/plain": "[1, 1, 1, 1]"}, "execution_count": 61, "metadata": {}, "output_type": "execute_result"}]}, {"metadata": {}, "cell_type": "code", "source": "print(classification_report(y_pred=y_pred,y_true=y_true))", "execution_count": 62, "outputs": [{"name": "stdout", "output_type": "stream", "text": "              precision    recall  f1-score   support\n\n           1       1.00      1.00      1.00         4\n\n    accuracy                           1.00         4\n   macro avg       1.00      1.00      1.00         4\nweighted avg       1.00      1.00      1.00         4\n\n"}]}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"summary\"></a>\n## Summary and next steps\n\n You successfully completed this notebook!.\n \n You learned how to extract named entities with Google's `google/flan-ul2` on watsonx. \n \n Check out our <a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"Online Documentation\">Online Documentation</a> for more samples, tutorials, documentation, how-tos, and blog posts. \n"}, {"metadata": {}, "cell_type": "markdown", "source": " **Author: Kahila Mokhtari**"}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "Copyright \u00a9 2023, 2024 IBM. This notebook and its source code are released under the terms of the MIT License."}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.14", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}
