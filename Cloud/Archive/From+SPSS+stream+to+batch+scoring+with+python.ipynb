{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"border: none\" align=\"left\">\n",
    "   <tr style=\"border: none\">\n",
    "      <th style=\"border: none\"><font face=\"verdana\" size=\"5\" color=\"black\"><b>Predict the best drug for heart treatment with IBM Watson Machine Learning (SPSS)</b></th>\n",
    "      <th style=\"border: none\"><img src=\"https://github.com/pmservice/customer-satisfaction-prediction/blob/master/app/static/images/ml_icon_gray.png?raw=true\" alt=\"Watson Machine Learning icon\" height=\"40\" width=\"40\"></th>\n",
    "   </tr>\n",
    "   <tr style=\"border: none\">\n",
    "       <th style=\"border: none\"><img src=\"https://github.com/pmservice/drug-selection/raw/master/images/heart_banner.png\" width=\"600\" alt=\"Icon\"> </th>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains steps and code to load an IBM SPSS predictive model to IBM Bluemix Cloud and start scoring new data. This notebook introduces commands for getting data, model persistance to Watson Machine Learning repository, model deployment, and batch scoring.\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 2.0.\n",
    "\n",
    "You will use the **drug_batch_data** data set, which is published on GitHub and details anonymous patients records. Use the details of this data set to predict the best drug for heart disease treatment.\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "The learning goals of this notebook are:\n",
    "\n",
    "-  Load a CSV file into Db2 on Cloud (formerly DashDB).\n",
    "-  Persist the SPSS model in the Watson Machine Learning repository.\n",
    "-  Deploy a model for batch scoring by using the Watson Machine Learning API.\n",
    "-  Score sample scoring data by using the Watson Machine Learning API.\n",
    "-  Explore and visualize prediction result using the `plotly` package.\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "1.\t[Setup](#setup)\n",
    "2.\t[Persist the model](#persistence)\n",
    "3.\t[Score in the cloud](#scoring)\n",
    "4.\t[Explore predictions](#explore)\n",
    "4.\t[Summary and next steps](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Setup\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "-  Create a [Watson Machine Learning Service](https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/) instance (a free plan is offered). \n",
    "-  Create a [Db2 on Cloud](https://console.ng.bluemix.net/catalog/services/db2-on-cloud/) instance (an entry plan is offered). \n",
    "-  Upload the **drugTrain2** data to Db2 on Cloud.\n",
    "\n",
    "\n",
    "### Create the DRUGTRAIN2 table in Db2 on Cloud  \n",
    "\n",
    "1.  Download the [drug_batch_data.csv](https://github.com/pmservice/drug-selection/blob/master/data/drug_batch_data.csv) file from the GitHub repository.\n",
    "2.  Click the **Open the console to get started with Db2 on Cloud** icon.\n",
    "3.  Select the **Load Data** and **Desktop** load type.\n",
    "4.  Drag and drop the previously downloaded file and click **Next**.\n",
    "5.  The **DRUG_BATCH_DATA** table with uploaded data should be created for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"persistence\"></a>\n",
    "## 2. Persist the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will learn how to store your model in the Watson Machine Learning repository by using the REST API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action**: Put the authentication information (URL and access_key) from your instance of Watson Machine Learning service in the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"https://ibm-watson-ml.mybluemix.net\"\n",
    "access_key =\"***\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Tip**: The URL and access_key can be found on the **Service Credentials** tab of the service instance you created in Bluemix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: Download the sample SPSS stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action**: Download the sample SPSS stream from the GitHub project by using the `wget` command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: First, you need to install required packages. You can do it by running the following code. Run it only one time.<BR><BR>\n",
    "!pip install wget --user <BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/pmservice/drug-selection/raw/master/model/Drug1n_capitalized.str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: If you are using your own stream make sure that the columns names that are used in the stream and the ones that are used in the database have the same capitalization, for example UPPER CASE letters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2: Deploy the Drug1n_capitalized.str to the Watson Machine Learning service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib3, requests, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context_id = \"drug_cap_stream\"\n",
    "upload_endpoint = url + \"/pm/v1/file/\" + context_id + \"?accesskey=\" + access_key\n",
    "files = {'file': ('Drug1n_capitalized.str', open('Drug1n_capitalized.str', 'rb'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "upload_response = requests.put(upload_endpoint, files=files)\n",
    "\n",
    "print upload_response\n",
    "print upload_response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the model is deployed successfuly to the Watson Machine Learning service on cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: The `context_id` variable can be any string that describes your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"scoring\"></a>\n",
    "## 3. Score in the cloud by using a batch job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will learn how to a create batch job and score records present in Db2 on Cloud by using the Watson Machine Learning REST API. \n",
    "For more information about REST APIs, see the [Bluemix Documentation](https://console.ng.bluemix.net/docs/services/PredictiveModeling/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Create a connection map to the Db2 table with data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your Db2 credentials from Bluemix update the **host**, **port**, **db**, **username**, and **password** values in the following `dbDefinitions` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbDefinitions = {\n",
    "    \"db1\":{\n",
    "         \"type\":\"DashDB\",\n",
    "         \"host\":\"awh-yp-small02.services.dal.bluemix.net\",\n",
    "         \"port\":50000,\n",
    "         \"db\":\"BLUDB\",\n",
    "         \"username\":\"***\",\n",
    "         \"password\":\"***\"\n",
    "      }\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: All the required fields can be found on the **Service Credentials** tab of the Db2 on Cloud service instance that you created in Bluemix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use different names, you'll need to update the `table` name, in the example `DRUG_BATCH_DATA` and `node` name to reflect your model's input/output node names in the following dictionary. You can also update the result `table` name from `RESULTS_DRUG` to any custom string in the `exports` section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "      \"inputs\":[\n",
    "         {\n",
    "            \"odbc\":{\n",
    "               \"dbRef\":\"db1\",\n",
    "               \"table\":\"DRUG_BATCH_DATA\"\n",
    "            },\n",
    "            \"node\":\"scoreInput\",\n",
    "            \"attributes\":[\n",
    "\n",
    "            ]\n",
    "         }\n",
    "      ],\n",
    "      \"exports\":[\n",
    "         {\n",
    "            \"odbc\":{\n",
    "               \"dbRef\":\"db1\",\n",
    "               \"table\":\"RESULTS_DRUG\",\n",
    "               \"insertMode\":\"Create\"\n",
    "            },\n",
    "            \"node\":\"Table\",\n",
    "            \"attributes\":[\n",
    "\n",
    "            ]\n",
    "         }\n",
    "      ]\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: The database table name must match the SPSS Modeler stream file. The table with data to score that should be put into the **inputs: table**; **inputs/exports: node** variables must match the input and output node names that are used in the SPSS modeler stream file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2: Submit the batch job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_id = \"drug_job5\"\n",
    "batch_endpoint = url + \"/pm/v1/jobs/\" + job_id + \"?accesskey=\" + access_key\n",
    "\n",
    "batch_payload = {\n",
    "    \"action\":\"BATCH_SCORE\", \n",
    "    \"model\":{\n",
    "      \"id\":\"drug_cap_stream\",\n",
    "      \"name\":\"Drug1n_capitalized.str\"\n",
    "   },\n",
    "   \"dbDefinitions\": dbDefinitions,\n",
    "   \"setting\": settings\n",
    "}\n",
    "\n",
    "batch_header = {\"Content-Type\": \"application/json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_response = requests.post(batch_endpoint, json=batch_payload, headers=batch_header)\n",
    "\n",
    "print batch_response\n",
    "print batch_response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the batch job has been submitted, you can check the status of your batch job by using the following REST API method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_status_response = requests.get(batch_endpoint)\n",
    "\n",
    "print batch_status_response\n",
    "print batch_status_response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see our batch job status is SUCCESS. Prediction results are stored in the `RESULTS_DRUG` table. Let's connect to Db2 on Cloud and explore it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"explore\"></a>\n",
    "## 4. Explore predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will connect to the `RESULTS_DRUG` table by using the Apache Spark `read` method to explore the prediction results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1: Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following code to read the predictions results into a Spark data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "properties = {\n",
    "    'jdbcurl': 'jdbc:db2://awh-yp-small02.services.dal.bluemix.net:50000/BLUDB',\n",
    "    'user': '***',\n",
    "    'password': '***'\n",
    "}\n",
    "\n",
    "data = spark.read.jdbc(properties['jdbcurl'], table='DASH111858.RESULTS_DRUG', properties=properties)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that data has been loaded correctly. Now we can check the schema of the prediction data by using the `printSchema()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to preview the prediction data, call the `show()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the resulting table two columns with predicted drug (`N-DRUG`) and probability (`NC-DRUG`) are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.select(\"$N-DRUG\").groupBy(\"$N-DRUG\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can calculate drug distribution by using a `select` statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2: Create a sample visualization of the data by using the `plotly` package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection you will explore prediction results with Plotly, which is an online analytics and data visualization tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**:  First, you need to install required packages. You can do it by running the following code. Run it only one time.\n",
    "\n",
    "!pip install plotly --user\n",
    "\n",
    "!pip install cufflinks --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install plotly --user \n",
    "!pip install cufflinks --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Plotly and other required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas\n",
    "import plotly.plotly as py\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "sys.path.append(\"\".join([os.environ[\"HOME\"]])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the Apache Spark data frame to a Pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_pdf = data.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a pie chart that shows drugs distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cumulative_stats = data_pdf.groupby(['$N-DRUG']).count()\n",
    "\n",
    "drug_data = [go.Pie(\n",
    "            labels=cumulative_stats.index,\n",
    "            values=cumulative_stats['$NC-DRUG'],\n",
    "    )]\n",
    "\n",
    "drug_layout = go.Layout(\n",
    "    title='Heart treatment drugs distribution',\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=drug_data, layout=drug_layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this data set, you might want to do some analysis of the mean _k_ value per drug type by using a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_data = [go.Bar(\n",
    "            y=data_pdf.groupby(['$N-DRUG']).mean()[\"K\"],\n",
    "            x=cumulative_stats.index\n",
    "            \n",
    "    )]\n",
    "\n",
    "age_layout = go.Layout(\n",
    "    title='Mean K per recommended drug',\n",
    "    xaxis=dict(\n",
    "        title = \"Drug\",\n",
    "        showline=False,),\n",
    "    yaxis=dict(\n",
    "        title = \"Mean K\",\n",
    "        ),\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=age_data, layout=age_layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the bar plot you created, you might make the following conclusion: The drugC and drugX is recommended for patients with high value of _k_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"summary\"></a>\n",
    "## 7. Summary and next steps     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " You successfully completed this notebook! You learned how to use Apache Spark machine learning as well as Watson Machine Learning for model creation and deployment. Check out our [Online Documentation](www.ibm.com) for more samples, tutorials, documentation, how-tos, and blog posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors\n",
    "\n",
    "**Lukasz Cmielowski**, PhD, is an Automation Architect and Data Scientist in IBM with a track record of developing enterprise-level applications that substantially increases clients' ability to turn data into actionable knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2017 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.0",
   "language": "python",
   "name": "python2-spark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
