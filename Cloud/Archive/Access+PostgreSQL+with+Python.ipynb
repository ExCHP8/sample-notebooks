{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access PostgreSQL with Python\n",
    "\n",
    "This notebook shows how to access a PostgreSQL database when using Python.\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "1. [Setup](#Setup)\n",
    "1. [Import the *psycopg2* Python library](#Import-the-psycopg2-Python-library)\n",
    "1. [Identify and enter the database connection credentials](#Identify-and-enter-the-database-connection-credentials)\n",
    "1. [Create the database connection](#Create-the-database-connection)\n",
    "1. [Create a table](#Create-a-table)\n",
    "1. [Insert data into a table](#Insert-data-into-a-table)\n",
    "1. [Query data](#Query-data)\n",
    "1. [Close the database connection](#Close-the-database-connection)\n",
    "1. [Summary](#Summary)\n",
    "\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before beginning you will need access to a *PostgreSQL* database. PostgreSQL is a powerful, open source, object-relational database system. It is a multi-user database management system and has sophisticated features such as Multi-Version Concurrency Control, point in time recovery, and more. To learn more, see the [PostgreSQL website](http://www.postgresql.org/).\n",
    "\n",
    "When dealing with large data sets (for example 50 GB) that potentially exceed the memory of your machine (RAM), it is nice to have another possibility such as an PostgreSQL database, where you can query the data in smaller digestible chunks. In this way, you just query data in smaller chunks (for instance 2 GB), and leave resources for the computation.\n",
    "\n",
    "[Try PostgreSQL free of charge on IBM Bluemix.](https://console.ng.bluemix.net/catalog/services/compose-for-postgresql/)\n",
    "\n",
    "\n",
    "<a class=\"ibm-tooltip\" href=\"https://console.ng.bluemix.net/catalog/services/compose-for-postgresql/\" target=\"_blank\" title=\"\" id=\"ibm-tooltip-0\">\n",
    "<img alt=\"IBM Bluemix.Get started now\" height=\"193\" width=\"153\" src=\"https://ibm.box.com/shared/static/a91ydi71gu58ar10aosoc3sflyo3jif2.png\" >\n",
    "</a> \n",
    "\n",
    "\n",
    "## Import the *psycopg2* Python library\n",
    "\n",
    "__Psycopg2__ is a driver for interacting with PostgreSQL from the Python scripting language. It provides to efficiently perform the full range of SQL operations against Postgres databases. Run the commands below to install and import the psycopg2 library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in /usr/local/src/bluemix_jupyter_bundle.v46/notebook/lib/python2.7/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify and enter the database connection credentials\n",
    "\n",
    "Connecting to PostgreSQL database requires the following information:\n",
    "* Host name or IP address \n",
    "* Host port\n",
    "* default database name\n",
    "* Connection protocol\n",
    "* User ID\n",
    "* User password\n",
    "\n",
    "All of this information must be captured in a connection string in a subsequent step. Provide the PostgreSQL connection information as shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Enter the values for you database connection\n",
    "dsn_database = \"<database name>\"       # for example  \"compose\"\n",
    "dsn_hostname = \"<your host name>\"     # for example  \"aws-us-east-1-portal.4.dblayer.com\"\n",
    "dsn_port = \"<port>\"                 # for example  11101 \n",
    "dsn_uid = \"<your user id>\"        # for example  \"admin\"\n",
    "dsn_pwd = \"<your password>\"      # for example  \"xxx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the database connection\n",
    "\n",
    "Set up a connection as follows. If a connection cannot be made an exception will be raised. \n",
    "*conn.cursor* will return a cursor object and you can use this cursor to perform queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to database\n",
      "\t->host=bluemix-sandbox-dal-9-portal.1.dblayer.com port=28059 dbname=compose user=admin password=KRRGHQDOZSLTKXJU\n",
      "Connected!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn_string = \"host=\"+dsn_hostname+\" port=\"+dsn_port+\" dbname=\"+dsn_database+\" user=\"+dsn_uid+\" password=\"+dsn_pwd\n",
    "    print \"Connecting to database\\n\t->%s\" % (conn_string)\n",
    "    conn=psycopg2.connect(conn_string)\n",
    "    print \"Connected!\\n\"\n",
    "except:\n",
    "    print \"Unable to connect to the database.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to define a cursor to work with. It is important to note that Python/Psycopg cursors are not cursors as defined by PostgreSQL. Given the cursor, we can execute a query, for example, to retrieve the list of databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(\"\"\"SELECT datname from pg_database\"\"\")\n",
    "rows = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can iterate through _rows_ to print the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Show me the databases:\n",
      "\n",
      "    template1\n",
      "    template0\n",
      "    postgres\n",
      "    compose\n"
     ]
    }
   ],
   "source": [
    "print \"\\nShow me the databases:\\n\"\n",
    "for row in rows:\n",
    "    print \"   \", row[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a table\n",
    "\n",
    "Create a test table named Cars. The code below drops the Cars table if it already exists, and then creates the new table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor.execute(\"DROP TABLE IF EXISTS Cars\")\n",
    "cursor.execute(\"CREATE TABLE Cars(Id INTEGER PRIMARY KEY, Name VARCHAR(20), Price INT)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert data into a table\n",
    "\n",
    "Run the following commands to create records in the new Cars table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor.execute(\"INSERT INTO Cars VALUES(1,'Audi',52642)\")\n",
    "cursor.execute(\"INSERT INTO Cars VALUES(2,'Mercedes',57127)\")\n",
    "cursor.execute(\"INSERT INTO Cars VALUES(3,'Skoda',9000)\")\n",
    "cursor.execute(\"INSERT INTO Cars VALUES(4,'Volvo',29000)\")\n",
    "cursor.execute(\"INSERT INTO Cars VALUES(5,'Bentley',350000)\")\n",
    "cursor.execute(\"INSERT INTO Cars VALUES(6,'Citroen',21000)\")\n",
    "cursor.execute(\"INSERT INTO Cars VALUES(7,'Hummer',41400)\")\n",
    "cursor.execute(\"INSERT INTO Cars VALUES(8,'Volkswagen',21600)\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query data\n",
    "\n",
    "The following Python code fetches and displays records from the Cars table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"SELECT * from Cars\"\"\")\n",
    "rows = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can display the records neatly using pretty print:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Show me the databases:\n",
      "\n",
      "[(1, 'Audi', 52642),\n",
      " (2, 'Mercedes', 57127),\n",
      " (3, 'Skoda', 9000),\n",
      " (4, 'Volvo', 29000),\n",
      " (5, 'Bentley', 350000),\n",
      " (6, 'Citroen', 21000),\n",
      " (7, 'Hummer', 41400),\n",
      " (8, 'Volkswagen', 21600)]\n"
     ]
    }
   ],
   "source": [
    "print \"\\nShow me the databases:\\n\"\n",
    "import pprint\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a loop to show each row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number= 1   Name= Audi   Price 52642\n",
      " Number= 2   Name= Mercedes   Price 57127\n",
      " Number= 3   Name= Skoda   Price 9000\n",
      " Number= 4   Name= Volvo   Price 29000\n",
      " Number= 5   Name= Bentley   Price 350000\n",
      " Number= 6   Name= Citroen   Price 21000\n",
      " Number= 7   Name= Hummer   Price 41400\n",
      " Number= 8   Name= Volkswagen   Price 21600\n"
     ]
    }
   ],
   "source": [
    "for row in rows:\n",
    "    print \" Number=\", row[0] ,\"  Name=\", row[1],\"  Price\", row[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Export data using *copy_to()* methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fout = open('cars.csv', 'w')\n",
    "cursor.copy_to(fout, 'cars', sep=\",\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, import data using *copy_from()* methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('cars.csv', 'r')\n",
    "cursor.copy_from(f, 'cars', sep=\",\")                    \n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close the database connection\n",
    "\n",
    "It is good practice to close your database connection after work is done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated how to establish a connection to a PostgreSQL database from Python using the psycopg2 library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to learn more?\n",
    "### Free courses on <a href=\"https://bigdatauniversity.com/courses/?utm_source=tutorial-dashdb-python&utm_medium=github&utm_campaign=bdu/\" rel=\"noopener noreferrer\" target=\"_blank\">Big Data University</a>: <a href=\"https://bigdatauniversity.com/courses/?utm_source=tutorial-dashdb-python&utm_medium=github&utm_campaign=bdu\" rel=\"noopener noreferrer\" target=\"_blank\"><img src = \"https://ibm.box.com/shared/static/xomeu7dacwufkoawbg3owc8wzuezltn6.png\" width=600px> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors\n",
    "\n",
    "**Saeed Aghabozorgi**, PhD, is a Data Scientist in IBM with a track record of developing enterprise-level applications that substantially increases clients' ability to turn data into actionable knowledge. He is a researcher in the data mining field and an expert in developing advanced analytic methods like machine learning and statistical modelling on large data sets.\n",
    "\n",
    "**Polong Lin** is a Data Scientist at IBM in Canada. Under the Emerging Technologies division, Polong is responsible for educating the next generation of data scientists through Big Data University. Polong is a regular speaker in conferences and meetups, and holds an M.Sc. in Cognitive Psychology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2017 Big Data University. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\" rel=\"noopener noreferrer\" target=\"_blank\">MIT License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.0",
   "language": "python",
   "name": "python2-spark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}