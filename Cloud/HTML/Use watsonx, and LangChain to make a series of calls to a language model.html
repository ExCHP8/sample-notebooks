<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>0b1d08864f3943938863e1a0efa28de9</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<p><img
src="https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png"
alt="image" /></p>
<h1
id="use-watsonx-and-langchain-to-make-a-series-of-calls-to-a-language-model">Use
watsonx, and LangChain to make a series of calls to a language
model</h1>
</div>
<div class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<h4 id="disclaimers">Disclaimers</h4>
<ul>
<li>Use only Projects and Spaces that are available in watsonx
context.</li>
</ul>
<h2 id="notebook-content">Notebook content</h2>
<p>This notebook contains the steps and code to demonstrate Simple
Sequential Chain using langchain integration with watsonx models.</p>
<p>Some familiarity with Python is helpful. This notebook uses Python
3.10.</p>
<h2 id="learning-goal">Learning goal</h2>
<p>The goal of this notebook is to demonstrate how to chain
<code>google/flan-ul2</code> and <code>google/flan-t5-xxl</code> models
to generate a sequence of creating a random question on a given topic
and an answer to that question and also to make the user friends with
LangChain framework, using simple chain (LLMChain) and the extended
chain (SimpleSequentialChain) with the WatsonxLLM.</p>
<h2 id="contents">Contents</h2>
<p>This notebook contains the following parts:</p>
<ul>
<li><a href="#setup">Setup</a></li>
<li><a href="#models">Foundation Models on watsonx</a></li>
<li><a href="#watsonxllm">LangChain integration</a></li>
<li><a href="#experiment">Simple Sequential Chain experiment</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
</div>
<div class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<p><a id="setup"></a></p>
<h2 id="set-up-the-environment">Set up the environment</h2>
<p>Before you use the sample code in this notebook, you must perform the
following setup tasks:</p>
<ul>
<li>Create a
<a href="https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/" target="_blank" rel="noopener no referrer">Watson
Machine Learning (WML) Service</a> instance (a free plan is offered and
information about how to create the instance can be found
<a href="https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-service-instance.html?context=analytics" target="_blank" rel="noopener no referrer">here</a>).</li>
</ul>
</div>
<section id="install-and-import-the-datasets-and-dependecies"
class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<h3>Install and import the <code>datasets</code> and dependecies</h3>
</section>
<div class="cell code"
data-pycharm="{&quot;is_executing&quot;:true,&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="st">&quot;ibm-watson-machine-learning&gt;=1.0.327&quot;</span> <span class="op">|</span> tail <span class="op">-</span>n <span class="dv">1</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="st">&quot;pydantic&gt;=1.10.0&quot;</span> <span class="op">|</span> tail <span class="op">-</span>n <span class="dv">1</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="st">&quot;langchain==0.0.340&quot;</span> <span class="op">|</span> tail <span class="op">-</span>n <span class="dv">1</span></span></code></pre></div>
</div>
<section id="defining-the-wml-credentials" class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<h3>Defining the WML credentials</h3>
<p>This cell defines the WML credentials required to work with watsonx
Foundation Model inferencing.</p>
<p><strong>Action:</strong> Provide the IBM Cloud user API key. For
details, see
<a href="https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui" target="_blank" rel="noopener no referrer">documentation</a>.</p>
</section>
<div class="cell code" data-execution_count="1"
data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> getpass</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>credentials <span class="op">=</span> {</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;url&quot;</span>: <span class="st">&quot;https://us-south.ml.cloud.ibm.com&quot;</span>,</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;apikey&quot;</span>: getpass.getpass(<span class="st">&quot;Please enter your WML api key (hit enter): &quot;</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
</div>
<section id="defining-the-project-id" class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<h3>Defining the project id</h3>
<p>The Foundation Model requires project id that provides the context
for the call. We will obtain the id from the project in which this
notebook runs. Otherwise, please provide the project id.</p>
</section>
<div class="cell code" data-execution_count="2"
data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    project_id <span class="op">=</span> os.environ[<span class="st">&quot;PROJECT_ID&quot;</span>]</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">KeyError</span>:</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    project_id <span class="op">=</span> <span class="bu">input</span>(<span class="st">&quot;Please enter your project_id (hit enter): &quot;</span>)</span></code></pre></div>
</div>
<div class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<p><a id="models"></a></p>
<h2 id="foundation-models-on-watsonxai">Foundation Models on
<code>watsonx.ai</code></h2>
</div>
<section id="list-available-models" class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<h4>List available models</h4>
<p>All avaliable models are presented under <code>ModelTypes</code>
class.</p>
</section>
<div class="cell code" data-execution_count="3"
data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ibm_watson_machine_learning.foundation_models.utils.enums <span class="im">import</span> ModelTypes</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>([model.name <span class="cf">for</span> model <span class="kw">in</span> ModelTypes])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>[&#39;FLAN_T5_XXL&#39;, &#39;FLAN_UL2&#39;, &#39;MT0_XXL&#39;, &#39;GPT_NEOX&#39;, &#39;MPT_7B_INSTRUCT2&#39;, &#39;STARCODER&#39;, &#39;LLAMA_2_70B_CHAT&#39;, &#39;GRANITE_13B_INSTRUCT&#39;, &#39;GRANITE_13B_CHAT&#39;]
</code></pre>
</div>
</div>
<div class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<p>You need to specify <code>model_id</code>'s that will be used for
inferencing:</p>
</div>
<div class="cell code" data-execution_count="4"
data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>model_id_1 <span class="op">=</span> ModelTypes.FLAN_UL2</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>model_id_2 <span class="op">=</span> ModelTypes.FLAN_T5_XXL</span></code></pre></div>
</div>
<section id="defining-the-model-parameters" class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<h3>Defining the model parameters</h3>
<p>You might need to adjust model <code>parameters</code> for different
models or tasks, to do so please refer to documentation under
<code>GenTextParamsMetaNames</code> class.</p>
<p><strong>Action:</strong> If any complications please refer to the
<a href="https://ibm.github.io/watson-machine-learning-sdk/" target="_blank" rel="noopener no referrer">documentation</a>.</p>
</section>
<div class="cell code" data-execution_count="5"
data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ibm_watson_machine_learning.metanames <span class="im">import</span> GenTextParamsMetaNames <span class="im">as</span> GenParams</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ibm_watson_machine_learning.foundation_models.utils.enums <span class="im">import</span> DecodingMethods</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>parameters <span class="op">=</span> {</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    GenParams.DECODING_METHOD: DecodingMethods.SAMPLE,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    GenParams.MAX_NEW_TOKENS: <span class="dv">100</span>,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    GenParams.MIN_NEW_TOKENS: <span class="dv">1</span>,</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    GenParams.TEMPERATURE: <span class="fl">0.5</span>,</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    GenParams.TOP_K: <span class="dv">50</span>,</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    GenParams.TOP_P: <span class="dv">1</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
</div>
<section id="initialize-the-model" class="cell markdown">
<h3>Initialize the model</h3>
<p>Initialize the <code>Model</code> class with previous set params.</p>
</section>
<div class="cell code" data-execution_count="6">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ibm_watson_machine_learning.foundation_models <span class="im">import</span> Model</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>flan_ul2_model <span class="op">=</span> Model(</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    model_id<span class="op">=</span>model_id_1, </span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    params<span class="op">=</span>parameters, </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    credentials<span class="op">=</span>credentials,</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    project_id<span class="op">=</span>project_id)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>flan_t5_model <span class="op">=</span> Model(</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    model_id<span class="op">=</span>model_id_2,</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    credentials<span class="op">=</span>credentials,</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    project_id<span class="op">=</span>project_id)</span></code></pre></div>
</div>
<div class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<p><a id="watsonxllm"></a></p>
<h2 id="langchain-integration">LangChain integration</h2>
<p><code>WatsonxLLM</code> is a wrapper around watsonx.ai models that
provide chain integration around the models.</p>
<p><strong>Action:</strong> For more details about
<code>CustomLLM</code> check the
<a href="https://python.langchain.com/docs/modules/model_io/models/llms/custom_llm" target="_blank" rel="noopener no referrer">LangChain
documentation</a></p>
<h3 id="initialize-the-watsonxllm-class">Initialize the
<code>WatsonxLLM</code> class.</h3>
</div>
<div class="cell code" data-execution_count="7"
data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ibm_watson_machine_learning.foundation_models.extensions.langchain <span class="im">import</span> WatsonxLLM</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>flan_ul2_llm <span class="op">=</span> WatsonxLLM(model<span class="op">=</span>flan_ul2_model)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>flan_t5_llm <span class="op">=</span> WatsonxLLM(model<span class="op">=</span>flan_t5_model)</span></code></pre></div>
</div>
<div class="cell markdown">
<p><strong>Hint:</strong> To use Chain interface from LangChain with
watsonx.ai models you must call <code>model.to_langchain()</code>
method.</p>
<p>It returns <code>WatsonxLLM</code> wrapper compatible with LangChain
CustomLLM specification.</p>
</div>
<div class="cell code" data-execution_count="8">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>flan_ul2_model.to_langchain()</span></code></pre></div>
<div class="output execute_result" data-execution_count="8">
<pre><code>WatsonxLLM(model=&lt;ibm_watson_machine_learning.foundation_models.model.Model object at 0x7fb7190d9990&gt;)</code></pre>
</div>
</div>
<div class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<p>You can print all set data about the WatsonxLLM object using the
<code>dict()</code> method.</p>
</div>
<div class="cell code" data-execution_count="9"
data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>flan_ul2_llm.<span class="bu">dict</span>()</span></code></pre></div>
<div class="output execute_result" data-execution_count="9">
<pre><code>{&#39;model_id&#39;: &#39;google/flan-ul2&#39;,
 &#39;params&#39;: {&#39;decoding_method&#39;: &lt;DecodingMethods.SAMPLE: &#39;sample&#39;&gt;,
  &#39;max_new_tokens&#39;: 100,
  &#39;min_new_tokens&#39;: 1,
  &#39;temperature&#39;: 0.5,
  &#39;top_k&#39;: 50,
  &#39;top_p&#39;: 1},
 &#39;project_id&#39;: &#39;00f1747d-e5ba-4ce6-bdb7-409e8486e18a&#39;,
 &#39;space_id&#39;: None,
 &#39;_type&#39;: &#39;IBM watsonx.ai&#39;}</code></pre>
</div>
</div>
<div class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<p><a id="experiment"></a></p>
<h2 id="simple-sequential-chain-experiment">Simple Sequential Chain
experiment</h2>
<p>The simplest type of sequential chain is called a
<code>SimpleSequentialChain</code>, in which each step has a single
input and output and the output of one step serves as the input for the
following step.</p>
<p>The experiment will consist in generating a random question about any
topic and answer the following question.</p>
</div>
<div class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<p>An object called <code>PromptTemplate</code> assists in generating
prompts using a combination of user input, additional non-static data,
and a fixed template string.</p>
<p>In our case we would like to create two <code>PromptTemplate</code>
objects which will be responsible for creating a random question and
answering it.</p>
</div>
<div class="cell code" data-execution_count="10"
data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain <span class="im">import</span> PromptTemplate</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>prompt_1 <span class="op">=</span> PromptTemplate(</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    input_variables<span class="op">=</span>[<span class="st">&quot;topic&quot;</span>], </span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    template<span class="op">=</span><span class="st">&quot;Generate a random question about </span><span class="sc">{topic}</span><span class="st">: Question: &quot;</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>prompt_2 <span class="op">=</span> PromptTemplate(</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    input_variables<span class="op">=</span>[<span class="st">&quot;question&quot;</span>],</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    template<span class="op">=</span><span class="st">&quot;Answer the following question: </span><span class="sc">{question}</span><span class="st">&quot;</span>,</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<p>We would like to add functionality around language models using
<code>LLMChain</code> chain.</p>
<p><code>prompt_to_flan_ul2</code> chain formats the prompt template
whose task is to generate random question, passes the formatted string
to LLM and returns the LLM output.</p>
</div>
<div class="cell markdown">
<p><strong>Hint:</strong> To use Chain interface from LangChain with
watsonx.ai models you must call <code>model.to_langchain()</code>
method.</p>
<p>It returns <code>WatsonxLLM</code> wrapper compatible with LangChain
CustomLLM specification.</p>
</div>
<div class="cell code" data-execution_count="11"
data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.chains <span class="im">import</span> LLMChain</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>prompt_to_flan_ul2 <span class="op">=</span> LLMChain(llm<span class="op">=</span>flan_ul2_model.to_langchain(), prompt<span class="op">=</span>prompt_1)</span></code></pre></div>
</div>
<div class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<p><code>flan_to_t5</code> chain formats the prompt template whose task
is to answer the question we got from <code>prompt_to_flan_ul2</code>
chain, passes the formatted string to LLM and returns the LLM
output.</p>
</div>
<div class="cell code" data-execution_count="12"
data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>flan_to_t5 <span class="op">=</span> LLMChain(llm<span class="op">=</span>flan_t5_model.to_langchain(), prompt<span class="op">=</span>prompt_2)</span></code></pre></div>
</div>
<div class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<p>This is the overall chain where we run
<code>prompt_to_flan_ul2</code> and <code>flan_to_t5</code> chains in
sequence.</p>
</div>
<div class="cell code" data-execution_count="13"
data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.chains <span class="im">import</span> SimpleSequentialChain</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>qa <span class="op">=</span> SimpleSequentialChain(chains<span class="op">=</span>[prompt_to_flan_ul2, flan_to_t5], verbose<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
</div>
<div class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<p>Generate random question and answer to topic.</p>
</div>
<div class="cell code" data-execution_count="14"
data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>qa.run(<span class="st">&#39;life&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>

&gt; Entering new SimpleSequentialChain chain...
What is the smallest unit of a plant?
cell

&gt; Finished chain.
</code></pre>
</div>
<div class="output execute_result" data-execution_count="14">
<pre><code>&#39;cell&#39;</code></pre>
</div>
</div>
<div class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<p><a id="summary"></a></p>
<h2 id="summary-and-next-steps">Summary and next steps</h2>
<p>You successfully completed this notebook!.</p>
<p>You learned how to use Simple Squential Chain using custom llm
WastonxLLM.</p>
<p>Check out our
<em><a href="https://ibm.github.io/watson-machine-learning-sdk/samples.html" target="_blank" rel="noopener no referrer">Online
Documentation</a></em> for more samples, tutorials, documentation,
how-tos, and blog posts.</p>
</div>
<section id="authors" class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<h3>Authors:</h3>
<p><strong>Mateusz Szewczyk</strong>, Software Engineer at Watson
Machine Learning.</p>
</section>
<div class="cell markdown"
data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<p>Copyright © 2023 IBM. This notebook and its source code are released
under the terms of the MIT License.</p>
</div>
</body>
</html>
