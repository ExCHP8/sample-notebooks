{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebba4ba2-1849-4378-a1e4-25187f693665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51ac838-eb85-47b2-8646-1f245012352b",
   "metadata": {},
   "source": [
    "# Inferencing with Granite Text-to-SQL Models \n",
    "\n",
    "This notebook demonstrates how to use the two Text2SQL pipeline components, the Schema Linking model (SL) and SQL Generation model (SQL Gen). The inputs of Text2SQL pipeline include a natural language question (NLQ), a database schema in the JSON format, and optionally an evidence (or hint) for models to generate a better SQL query. Inference calls to two models are done via WX.AI REST API Endpoints as shown in the sample code in the steps below. This notebook also shows the input prompt and output of each component in the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00273b3",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Setup](#setup)\n",
    "1. [Create a prompt for the Schema Linking Model](#schemaprompt)\n",
    "1. [Perform an inference on the Schema Linking model using the WX.AI endpoint](#schemainference)\n",
    "1. [Post the process of the Schema Linking model output](#schemapost)\n",
    "1. [Create a prompt for the SQL Geneneration model](#sqlprompt)\n",
    "1. [Perform an inference on the SQL Generation model using the WX.AI endpoint](#sqlinference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4259cad",
   "metadata": {},
   "source": [
    "## Setup\n",
    "<a id=\"setup\"></a>\n",
    "\n",
    "You need to provide an API key and a project ID. You can either enter them in the code samples below or set them as these environment variables: `WATSONX_APIKEY` and `WATSONX_PROJECTID`.\n",
    "\n",
    "First, provide your watsonx API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a454ba-5e15-4bbb-8a97-23a23f66a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "try:\n",
    "    ibm_cloud_api_key = input('Enter WatsonX API Key: ')\n",
    "except:\n",
    "    ibm_cloud_api_key = os.getenv(\"WATSONX_APIKEY\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bca719e",
   "metadata": {},
   "source": [
    "Next, provide the project ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade712a1-3bbb-480b-9ff5-481404b6d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    project_id = input('Enter WatsonX Project ID: ')\n",
    "except:\n",
    "    project_id = os.getenv(\"WATSONX_PROJECTID\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab14bb8-df7e-40f2-a92f-68cdf4d252e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_cloud_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c2eee5-b04b-4e29-8dca-16952561440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a42a379-b714-4592-b96f-1dfdab685b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ibm_cloud_api_key is not None and project_id is not None, \"Both WATSONX_APIKEY and WATSONX_PROJECTID must be set\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd563314-cec7-4ba8-9f02-3ace0be7adae",
   "metadata": {},
   "source": [
    "### Set up your WX.AI model IDs and Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e596cb-68af-44c2-a3e9-dcca2d1b22ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a Watson Studio Bearer token \n",
    "token_url = \"https://iam.cloud.ibm.com/identity/token\"\n",
    "token_headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "token_data =  {\"grant_type\": \"urn:ibm:params:oauth:grant-type:apikey\", \"apikey\": ibm_cloud_api_key}\n",
    "\n",
    "response = requests.post(token_url, headers=token_headers, data=token_data)\n",
    "\n",
    "if response.status_code != 200:\n",
    "\traise Exception(\"Non-200 response: \" + str(response.text))\n",
    "\n",
    "access_token = response.json()[\"access_token\"]\n",
    "\n",
    "# Headers for REST API request\n",
    "BASE_HEADERS = {\"Content-Type\": \"application/json\", \"accept\": \"application/json\"}\n",
    "\n",
    "## WX.AI Model IDs\n",
    "SL_MODEL_ID = \"ibm/granite-20b-code-base-schema-linking\"\n",
    "SQL_GEN_MODEL_ID = \"ibm/granite-20b-code-base-sql-gen\"\n",
    "\n",
    "## WXAI API setup\n",
    "PROD_URL = \"https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2024-03-19\"\n",
    "PROD_HEADERS = {\"Content-Type\": \"application/json\", \"accept\": \"application/json\", \"Authorization\": f\"Bearer {access_token}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c364589-aaa1-4bda-bd23-bcda719b325f",
   "metadata": {},
   "source": [
    "### Provide a natural language question input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd0a22b-f2f9-45c4-8288-991e708c8629",
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_question = \"Show me production cost of products in orders with quantity greater than 10\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10fd574-cc79-46de-a86b-3e7e2102b4b6",
   "metadata": {},
   "source": [
    "Samples tested successfully with this notebook:\n",
    "- \"Show me production cost, unit sale price of order with quantity greater than 10\"\n",
    "- \"Show me opening inventory, average cost and closing inventory with shipped quantity less than 5000\"\n",
    "- \"Find order quantity and promotion code of products with top five gross margin\"\n",
    "- \"Find base product with order unit sale price greater than 200 and inventory average unit cost less than 1000\"\n",
    "- \"Find average gross margin of products with product language EN\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66d9b31-f85c-4748-88b8-9b85bee73dda",
   "metadata": {},
   "source": [
    "### Provide an JSON Database Schema\n",
    "\n",
    "For this example, we're using a reduced version of the Gosales database with four tables: inventory_levels, products, product_name_lookup, order_details. We're using Gosales because it's an enterprise datase that is encoded in a JSON schema format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c551d-80a6-4197-82b0-53fd1dca058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Json DB Schema\n",
    "db_json_schema = json.loads('{\"name\": \"GOSALES\", \"tables\": {\"inventory_levels\": {\"name\": \"inventory_levels\", \"columns\": [{\"name\": \"inventory_year\", \"type\": \"SMALLINT\", \"primary_key\": true, \"foreign_key\": null, \"value_samples\": [\"2007\", \"2004\", \"2005\", \"2006\"]}, {\"name\": \"inventory_month\", \"type\": \"SMALLINT\", \"primary_key\": true, \"foreign_key\": null, \"value_samples\": [\"9\", \"12\", \"11\"]}, {\"name\": \"warehouse_branch_code\", \"type\": \"INTEGER\", \"primary_key\": true, \"foreign_key\": null, \"value_samples\": [\"40\", \"28\", \"30\"]}, {\"name\": \"product_number\", \"type\": \"INTEGER\", \"primary_key\": true, \"foreign_key\": [\"product\", \"product_number\"], \"value_samples\": [\"125130\", \"122150\", \"149110\"]}, {\"name\": \"opening_inventory\", \"type\": \"INTEGER\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"2\", \"2152\", \"2148\"]}, {\"name\": \"quantity_shipped\", \"type\": \"INTEGER\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"2\", \"1999\", \"1928\"]}, {\"name\": \"additions\", \"type\": \"INTEGER\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"1129\", \"1787\", \"1770\"]}, {\"name\": \"unit_cost\", \"type\": \"DECIMAL(19, 2)\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"4.45\", \"5.03\", \"5.02\"]}, {\"name\": \"closing_inventory\", \"type\": \"INTEGER\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"2\", \"2192\", \"2152\"]}, {\"name\": \"average_unit_cost\", \"type\": \"DECIMAL(19, 2)\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"2.15\", \"2.75\", \"2.31\"]}]}, \"order_details\": {\"name\": \"order_details\", \"columns\": [{\"name\": \"order_detail_code\", \"type\": \"INTEGER\", \"primary_key\": true, \"foreign_key\": null, \"value_samples\": [\"1000001\", \"1000016\", \"1000015\"]}, {\"name\": \"order_number\", \"type\": \"INTEGER\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"100015\", \"100073\", \"100072\"]}, {\"name\": \"ship_date\", \"type\": \"TIMESTAMP\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"2004-03-05 00:00:00\", \"2004-08-06 00:00:00\", \"2004-08-04 00:00:00\"]}, {\"name\": \"product_number\", \"type\": \"INTEGER\", \"primary_key\": false, \"foreign_key\": [\"product\", \"product_number\"], \"value_samples\": [\"125130\", \"149110\", \"123130\"]}, {\"name\": \"promotion_code\", \"type\": \"INTEGER\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"10203\", \"10223\", \"10213\"]}, {\"name\": \"quantity\", \"type\": \"INTEGER\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"1532\", \"1777\", \"1771\"]}, {\"name\": \"unit_cost\", \"type\": \"DECIMAL(19, 2)\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"43.73\", \"31.24\", \"73.96\"]}, {\"name\": \"unit_price\", \"type\": \"DECIMAL(19, 2)\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"72.0\", \"98.0\", \"34.8\"]}, {\"name\": \"unit_sale_price\", \"type\": \"DECIMAL(19, 2)\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"12.52\", \"96.44\", \"94.8\"]}]}, \"product\": {\"name\": \"product\", \"columns\": [{\"name\": \"product_number\", \"type\": \"INTEGER\", \"primary_key\": true, \"foreign_key\": null, \"value_samples\": [\"1110\", \"6110\", \"5110\"]}, {\"name\": \"base_product_number\", \"type\": \"INTEGER\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"1\", \"6\", \"5\"]}, {\"name\": \"introduction_date\", \"type\": \"TIMESTAMP\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"1999-06-12 00:00:00\", \"2004-01-15 00:00:00\", \"2004-01-13 00:00:00\"]}, {\"name\": \"discontinued_date\", \"type\": \"TIMESTAMP\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"2005-02-28 00:00:00\", \"2006-05-31 00:00:00\", \"2006-03-31 00:00:00\"]}, {\"name\": \"product_type_code\", \"type\": \"INTEGER\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"970\", \"956\", \"971\"]}, {\"name\": \"product_color_code\", \"type\": \"INTEGER\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"900\", \"924\", \"921\"]}, {\"name\": \"product_size_code\", \"type\": \"INTEGER\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"801\", \"812\", \"810\"]}, {\"name\": \"product_brand_code\", \"type\": \"INTEGER\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"703\", \"714\", \"715\"]}, {\"name\": \"production_cost\", \"type\": \"DECIMAL(19, 2)\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"1.0\", \"11.43\", \"9.22\"]}, {\"name\": \"gross_margin\", \"type\": \"DOUBLE\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"0.3\", \"0.7\", \"0.41\"]}, {\"name\": \"product_image\", \"type\": \"VARCHAR(60)\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"\\'P01CE1CG1.jpg\\'\", \"\\'P06CE1CG1.jpg\\'\", \"\\'P05CE1CG1.jpg\\'\"]}]}, \"product_name_lookup\": {\"name\": \"product_name_lookup\", \"columns\": [{\"name\": \"product_number\", \"type\": \"INTEGER\", \"primary_key\": true, \"foreign_key\": [\"product\", \"product_number\"], \"value_samples\": [\"1110\", \"6110\", \"5110\"]}, {\"name\": \"product_language\", \"type\": \"VARCHAR(30)\", \"primary_key\": true, \"foreign_key\": null, \"value_samples\": [\"\\'CS\\'\", \"\\'ES\\'\", \"\\'EN\\'\"]}, {\"name\": \"product_name\", \"type\": \"VARCHAR(150)\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": [\"\\'\\\\\"\\\\u0412\\\\u0435\\\\u0447\\\\u043d\\\\u044b\\\\u0439 \\\\u0441\\\\u0432\\\\u0435\\\\u0442\\\\\" - \\\\u0411\\\\u0443\\\\u0442\\\\u0430\\\\u043d\\\\u043e\\\\u0432\\\\u044b\\\\u0439\\'\", \"\\'\\\\\"\\\\u041c\\\\u0443\\\\u0445\\\\u043e-\\\\u0429\\\\u0438\\\\u0442\\\\\" \\\\u0410\\\\u044d\\\\u0440\\\\u043e\\\\u0437\\\\u043e\\\\u043b\\\\u044c\\'\", \"\\'\\\\\"\\\\u041c\\\\u0443\\\\u0445\\\\u043e-\\\\u0429\\\\u0438\\\\u0442\\\\\" - \\\\u0421\\\\u0443\\\\u043f\\\\u0435\\\\u0440\\'\"]}, {\"name\": \"product_description\", \"type\": \"VARCHAR(765)\", \"primary_key\": false, \"foreign_key\": null, \"value_samples\": []}]}}}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9074b3c4-d2b0-4edb-986c-fcfc7c5d3c1c",
   "metadata": {},
   "source": [
    "A portion of the Gosales JSON schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8e71be-d7f3-479c-a164-4c6106a4e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(json.dumps(db_json_schema, indent=2).split(\"\\n\")[:30]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ef8024-0fa0-45a1-8cd0-4d4a6c4840fb",
   "metadata": {},
   "source": [
    "**Note:** To run this notebook with a new JSON Database schema, the input JSON Database schema must follow the following format.\n",
    "\n",
    "To represent the schema, we assume a structure of following format:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"name\": <schema name>,\n",
    "  \"tables\": {\n",
    "        \"1st_table_name\": { \"name\": \"table_name\",\n",
    "                            \"columns\": [\n",
    "                                        {\n",
    "                                          \"name\": \"column name\",\n",
    "                                          \"type\": \"column data type\",\n",
    "                                          \"primary_key\": \"bool, true means this column is the primary key\",\n",
    "                                          \"foreign_key\": \"null or [table name, column name], e.g ['customer','cst_id']\"\n",
    "                                        },\n",
    "                                        ...\n",
    "                                       ]\n",
    "                           },\n",
    "        ...\n",
    "   }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0eda04-008b-43c5-9176-68891bc196cd",
   "metadata": {},
   "source": [
    "## Create a prompt for the Schema Linking Model \n",
    "<a id=\"schemaprompt\"></a>\n",
    "\n",
    "Create a prompt for the Schema Linking model using the input JSON Database schema, the natural language question, and evidence if it exists. This is the first step in the Text2SQL pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1afde3-f048-4130-9738-69beaf13d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to parse the input JSON DB schema and create prompt for Schema Linking model\n",
    "from typing import Union, List, Mapping, Dict, Tuple\n",
    "def generate_table_representation(schema, linked_schema=None):\n",
    "    col_indent = ' '\n",
    "    table_dict = {}\n",
    "    for tbl_name, tbl in schema[\"tables\"].items():\n",
    "        if linked_schema is not None and tbl_name not in linked_schema:\n",
    "            continue\n",
    "        start = 'CREATE TABLE '+ tbl_name + ' (\\n'\n",
    "        col_strs = []\n",
    "        fk_strs = []\n",
    "        col_num = 0\n",
    "        for col in tbl[\"columns\"]:\n",
    "            if linked_schema is not None and col[\"name\"] not in linked_schema[tbl_name]:\n",
    "                continue\n",
    "            col_num += 1\n",
    "            col_str = f'{col_indent}{col[\"name\"]}'\n",
    "            col_str += f' {col[\"type\"].upper()}'\n",
    "            if col[\"primary_key\"]:\n",
    "                col_str += ' PRIMARY KEY'\n",
    "            col_str += ','\n",
    "            desc = ''\n",
    "            if col.get(\"description\", None):\n",
    "                desc += col[\"description\"] + '\\n'\n",
    "            if desc:\n",
    "                desc = re.sub(r'\\s*\\n\\s*', '\\n', desc.strip())\n",
    "                desc = desc.replace('\\n', '\\n-- ')\n",
    "                col_str += ' -- ' + desc\n",
    "            # TODO: other expansion info\n",
    "            if col[\"foreign_key\"]:\n",
    "                fk_table, fk_col = col[\"foreign_key\"]\n",
    "                if linked_schema is None or (fk_table in linked_schema):\n",
    "                    fk_strs.append(f'{col_indent}FOREIGN KEY({col[\"name\"]}) REFERENCES {fk_table}({fk_col})')\n",
    "            col_strs.append(col_str)\n",
    "        assert len(col_strs) > 0\n",
    "        col_strs.extend(fk_strs)\n",
    "        tbl_str = start + '\\n'.join(col_strs)+'\\n);'\n",
    "        lines = []\n",
    "        for col in tbl[\"columns\"]:\n",
    "            if col[\"value_samples\"]:\n",
    "                lines.append(tbl[\"name\"] + '.' + col[\"name\"] + ': ' + ', '.join(col[\"value_samples\"]))\n",
    "            else:\n",
    "                lines.append(tbl[\"name\"] + '.' + col[\"name\"])\n",
    "        tbl_str += '\\n\\n' + '\\n'.join(lines)\n",
    "        table_dict[tbl_name] = tbl_str\n",
    "    schema_str = '\\n\\n'.join(table_dict.values())\n",
    "    return schema_str, table_dict\n",
    "\n",
    "def qualified_column_list2dict(qual_cols: List[str]) -> Dict[str, List[str]]:\n",
    "    linked_schema = {}\n",
    "    for qual_col in qual_cols:\n",
    "        try:\n",
    "            qual_col = qual_col.strip()  #.lower()\n",
    "            tbl, col = qual_col.split('.')[-2:]\n",
    "            if tbl not in linked_schema:\n",
    "                linked_schema[tbl] = []\n",
    "            linked_schema[tbl].append(col)\n",
    "        except:\n",
    "            print(f\"skipped {qual_col}\")\n",
    "    return linked_schema\n",
    "\n",
    "def create_sl_prompt(question, schema, evidence: Union[List[str],str]=\"\"):\n",
    "    if isinstance(evidence, str):\n",
    "        evidence = [evidence]\n",
    "    evidence_str = '\\n\\nNote:\\n' + '\\n'.join(evidence)\n",
    "    schema_str, _ = generate_table_representation(schema=schema)\n",
    "    pre_question = evidence_str.strip() + '\\n\\nConsider:\\n' + question + '\\n\\n'\n",
    "    schema_link_query = pre_question + \\\n",
    "                        schema_str + \\\n",
    "                         evidence_str + \\\n",
    "                         '\\n\\nTo answer:\\n' + \\\n",
    "                         question + \\\n",
    "                         '\\nWe need columns:\\n'\n",
    "    return schema_link_query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8e1b14-a741-4814-a7d6-22d142d2accc",
   "metadata": {},
   "source": [
    "Create a prompt for the Schema Linking model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ecf848-755a-4efa-b41c-a59d492a6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_prompt = create_sl_prompt(question=nl_question, schema=db_json_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfb7f1f-d7b5-46a6-be60-003381068712",
   "metadata": {},
   "source": [
    "Display the created prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941c9e5-8b5c-47fd-946e-69f344ae548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sl_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89813e3f-f83e-468c-9fd5-327a2084993b",
   "metadata": {},
   "source": [
    "## Perform an inference on the Schema Linking model using the WX.AI endpoint\n",
    "<a id=\"schemainference\"></a>\n",
    "\n",
    "Send a request to the Schema Linking model, generate outputs based on the provided configuration, and return the top-scoring outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b6119-3b57-4767-be16-6ace7cf7a6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to perform inference on Schema Linking model\n",
    "import collections\n",
    "def wxai_generate(payload, wxai_url, wxai_headers, num_samples=5, allow_duplicates=True, temperature_scaling=1.1, max_num_request=10):\n",
    "    # generation params\n",
    "    temperature = payload[\"parameters\"].get('temperature', 1.0)\n",
    "    all_outputs = []\n",
    "    sample_strs = collections.Counter()\n",
    "    num_request = 0\n",
    "    while len(all_outputs) < num_samples and num_request < max_num_request:\n",
    "        payload[\"parameters\"][\"temperature\"] = temperature\n",
    "        response = requests.post(wxai_url, headers=wxai_headers, json=payload, verify=True)\n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(f\"WX.AI model request failed, got code {response.status_code}, {response.json()}\")\n",
    "\n",
    "        is_added = False\n",
    "        for res in response.json()['results']:\n",
    "            if res[\"generated_text\"] not in sample_strs or allow_duplicates:\n",
    "                logprobs = [y.get(\"logprob\", 0.0) for y in res[\"generated_tokens\"]] # extract logprobs, if there is no logprob, set it to 0\n",
    "                cumulative_logprob = sum(logprobs)\n",
    "                score = cumulative_logprob / len(logprobs)\n",
    "                all_outputs.append({\"score\": score, \"text\": res[\"generated_text\"]})\n",
    "                sample_strs[res[\"generated_text\"]] += 1\n",
    "                is_added = True\n",
    "\n",
    "        # apply temperature scaling if we want more diverse output\n",
    "        if not is_added:\n",
    "            temperature = temperature*temperature_scaling\n",
    "        num_request += 1\n",
    "\n",
    "    all_outputs = sorted(all_outputs, key=lambda x: x[\"score\"], reverse=True)\n",
    "    return all_outputs      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3e658",
   "metadata": {},
   "source": [
    "Store the top-scoring outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e8702f-6193-4659-88db-5c292ae97592",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_preds =collections.Counter()\n",
    "\n",
    "all_valid_columns = []\n",
    "for tbl_name, tbl in db_json_schema[\"tables\"].items():\n",
    "    for col in tbl[\"columns\"]:\n",
    "        all_valid_columns.append(f'{tbl_name}.{col[\"name\"]}')\n",
    "\n",
    "# sl inference\n",
    "sl_inference_payload = {\n",
    "    \"model_id\": SL_MODEL_ID,\n",
    "    \"input\": sl_prompt,\n",
    "    \"project_id\": project_id,\n",
    "    \"parameters\": {\n",
    "        \"decoding_method\": \"sample\",\n",
    "        \"max_new_tokens\": 300,\n",
    "        \"temperature\": 1.0,\n",
    "        \"return_options\": {\"generated_tokens\": True, \"token_logprobs\": True}\n",
    "    }\n",
    "}\n",
    "all_sl_outputs = wxai_generate(payload=sl_inference_payload, wxai_url=PROD_URL, wxai_headers=PROD_HEADERS, num_samples=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219e482-2a33-4a80-9add-e98abbfc3e73",
   "metadata": {},
   "source": [
    "## Post the process of the Schema Linking model output\n",
    "<a id=\"schemapost\"></a>\n",
    "\n",
    "Filter and organize information from the outputs into a set of tables and a dictionary in a formatted JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f24d97-1386-427c-a553-9b303ed409ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "def filter_generative_schema_links(\n",
    "                            schema_linker_output_dict: Dict[str, float]=None,\n",
    "                            threshold: float = 1.0,\n",
    "                            schema_top_k_min: int = 3, \n",
    "                            schema_top_k_max: int = 30,\n",
    "                        ) -> Tuple[List, List, List]:\n",
    "    # Note that this method can change the qualified table list\n",
    "    schema_linker_output = []  #List[Tuple[str, float]]\n",
    "    for k, v in schema_linker_output_dict.items():\n",
    "        schema_linker_output.append((k, v))\n",
    "        \n",
    "    schema_linker_output.sort(key=lambda x: x[1], reverse=True)\n",
    "    # links above threshold or at least top_k_min, but at most top_k_max\n",
    "    schema_links_filtered = [qc for qc, score in schema_linker_output if score >= threshold]\n",
    "    score_filtered = [score for qc, score in schema_linker_output if score >= threshold]\n",
    "    \n",
    "    # filter column\n",
    "    if len(schema_links_filtered) < schema_top_k_min:\n",
    "        schema_links_filtered = [qc for qc, score in schema_linker_output][:schema_top_k_min]\n",
    "        score_filtered = [score for qc, score in schema_linker_output][:schema_top_k_min]\n",
    "    elif len(schema_links_filtered) > schema_top_k_max:\n",
    "        schema_links_filtered = schema_links_filtered[:schema_top_k_max]\n",
    "        score_filtered = score_filtered[:schema_top_k_max]\n",
    "    \n",
    "    # re-create qualified tables\n",
    "    qualified_tables_set = set() \n",
    "    for col in schema_links_filtered:\n",
    "        table_name = col.split(\".\")[-2]\n",
    "        qualified_tables_set.add(table_name)\n",
    "    \n",
    "    return schema_links_filtered, score_filtered, sorted(list(qualified_tables_set))\n",
    "\n",
    "def process_generative_sl_api_outputs(col_predictions, threshold=1, schema_name=None):\n",
    "    schema_links_filtered, score_filtered, _ = filter_generative_schema_links(\n",
    "                                                                                schema_linker_output_dict=col_predictions,\n",
    "                                                                                threshold=threshold\n",
    "                                                                            )\n",
    "    return {k:v for k,v in zip(schema_links_filtered, score_filtered)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5990caea-4b08-49f9-a111-920407557fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in all_sl_outputs:\n",
    "    sample_preds = set([p.strip() for p in sample['text'].split(',')])\n",
    "    for sp in sample_preds:\n",
    "        if sp in all_valid_columns:\n",
    "            scored_preds[sp] += 1\n",
    "            \n",
    "\n",
    "col_predictions = {}\n",
    "for vc in all_valid_columns:\n",
    "    col_predictions[vc] = scored_preds[vc] if vc in scored_preds else -10\n",
    "\n",
    "col_predictions_sorted = {k: v for k, v in sorted(col_predictions.items(), key=lambda item: item[1], reverse=True)}\n",
    "print(\"\\n\".join(json.dumps(col_predictions_sorted, indent=2).split(\"\\n\")[:30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca130fb-0a24-40cf-a0bb-f180f6b1ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_predictions = process_generative_sl_api_outputs(col_predictions=col_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e89efb",
   "metadata": {},
   "source": [
    "Create a `qualified_columns` list that contains the names of all columns that have been predicted and scored by the schema linker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c2cf9-68b7-41af-bcf9-dbe8f24fa8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualified_columns = list(col_predictions.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0f83e5-a79e-41ca-860f-d52159fab97d",
   "metadata": {},
   "source": [
    "## Create a prompt for the SQL Generation model \n",
    "<a id=\"sqlprompt\"></a>\n",
    "\n",
    "Create a prompt for the SQL Generation model using the input JSON Database schema, the natural language question, and evidence if it exists. This is the second step in the Text2SQL pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1e1a78-08d9-4e5f-ba30-3c664e008403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sql_gen_prompt(question, schema, evidence: Union[List[str],str]=\"\", qualified_columns:List[str]=None):\n",
    "    if isinstance(evidence, str):\n",
    "        evidence = [evidence]\n",
    "    evidence_str = 'Note:\\n' + '\\n'.join(evidence)\n",
    "    linked_schema = None\n",
    "    if qualified_columns is not None:\n",
    "        if not isinstance(qualified_columns, Mapping):\n",
    "            linked_schema = qualified_column_list2dict(qualified_columns)\n",
    "    schema_str, _ = generate_table_representation(schema=schema, linked_schema=linked_schema)\n",
    "    pre_question = evidence_str + question + '\\n\\n'\n",
    "    return pre_question + schema_str + '\\n\\n' + evidence_str + question + '\\nGenerate SQL:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc0a90e-e9de-4698-95a6-f8353d22e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_gen_prompt = create_sql_gen_prompt(question=nl_question, schema=db_json_schema, qualified_columns=qualified_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392a5eb8-c47f-48bc-9086-ad2e16c4a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sql_gen_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a582166-9d2c-4d2b-b4c5-ad058a1bff1c",
   "metadata": {},
   "source": [
    "## Perform an inference on the SQL Generation model using the WX.AI endpoint\n",
    "<a id=\"sqlinference\"></a>\n",
    "\n",
    "Generate three unique SQL queries based on the prompt string and store the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d4e718-7be8-40fe-8af6-d70e82bb4f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql gen inference\n",
    "sql_gen_inference_payload = {\n",
    "    \"model_id\": SQL_GEN_MODEL_ID,\n",
    "    \"input\": sql_gen_prompt,\n",
    "    \"project_id\": project_id,\n",
    "    \"parameters\": {\n",
    "        \"decoding_method\": \"sample\",\n",
    "        \"max_new_tokens\": 300,\n",
    "        \"temperature\": 1.0,\n",
    "        \"return_options\": {\"generated_tokens\": True, \"token_logprobs\": True}\n",
    "    }\n",
    "}\n",
    "\n",
    "all_sql_gen_outputs = wxai_generate(payload=sql_gen_inference_payload, wxai_url=PROD_URL, wxai_headers=PROD_HEADERS, num_samples=3, allow_duplicates=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5bd4e7-5c0b-47a2-af09-a7b0699d3ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sql_gen_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf161d9",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations, you completed this notebook! You learned how to work with the two Text2SQL pipeline components, the Schema Linking model (SL) and SQL Generation model (SQL Gen)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118b2943-a68e-4ab4-af6d-dd0329b2b31d",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- **Long Vu** lhvu@us.ibm.com\n",
    "- **Nhan Pham** nhp@us.ibm.com\n",
    "- **Michael Glass** mrglass@us.ibm.com\n",
    "- **Shankar Subramanian** dharmash@us.ibm.com\n",
    "\n",
    "IBM TJ Watson Research Center, New York, United States of America"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d767c82",
   "metadata": {},
   "source": [
    "Copyright © 2024 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:autotfm]",
   "language": "python",
   "name": "conda-env-autotfm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
