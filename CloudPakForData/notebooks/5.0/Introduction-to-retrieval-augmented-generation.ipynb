{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "# RAG: A simple introduction", "metadata": {"collapsed": true, "id": "d9aacb5f-7eea-4472-a811-2130d5579f27", "jupyter": {"outputs_hidden": true}}}, {"cell_type": "markdown", "source": "## Notebook content\n\nThis notebook contains the steps and code to demonstrate the retrieval-augmented generation pattern in IBM watsonx.ai.\n\nSome familiarity with Python is helpful. This notebook uses Python 3.11.\n\n\n## Learning goal\n\nThe goal of this notebook is to demonstrate how to apply the retrieval-augmented generation pattern to a question-answering use case in watsonx.ai.\n\n\n## Scenario\nThe website for an online seed catalog has many articles to help customers plan their garden and ultimately select which seeds to purchase. A new widget is being added to the website to answer customer questions based on the contents of the articles.\n\n\n## Contents\n\nThis notebook contains the following parts:\n\n- [Overview of retrieval-augmented generation](#overview)\n- [Step 1: Set up prerequisites](#setup)\n- [Step 2: Create a knowledge base](#knowledgebase)\n- [Step 3: Build a simple search component](#search)\n- [Step 4: Craft prompt text](#prompt)\n- [Step 5: Generate output using the foundation models Python library](#generate)\n- [Step 6: Pull everything together to perform retrieval-augmented generation](#rag)\n- [Summary](#summary)", "metadata": {"id": "67eaff0f-9a2c-44ad-9e20-5b1eb6427a88"}}, {"cell_type": "markdown", "source": "<a id=\"overview\"></a>\n## Overview of retrieval-augmented generation\n\nThe retrieval-augmented generation pattern involves three basic steps:\n1. Search for relevant content in your knowledge base\n2. Pull the most relevant content into your prompt as context\n3. Send the combined prompt text to a foundation model to generate output\n\nThe term _retrieval-augmented generation_ (RAG) was introduced in this paper: <a href=\"https://arxiv.org/abs/2005.11401\" target=\"_blank\" rel=\"noopener no referrer\">Retrieval-augmented generation for knowledge-intensive NLP tasks</a>\n\n> \"We build RAG models where the parametric memory is a pre-trained seq2seq transformer, and the\nnon-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural\nretriever.\"\n\nIn that paper, the term \"RAG models\" refers to a specific implementation of a _retriever_ (a specific query encoder and vector-based document search index) and a _generator_ (a specific pre-trained, generative language model.) \n\nHowever, the basic search-and-generate approach can be generalized to use different retriever components and foundation models.\n\nIn this notebook:\n- The **knowledge base** is a list of two articles\n- The **retrieval component** consists of a simple search function\n- The **generate** component uses the foundation model Python library in watsonx.ai\n", "metadata": {"id": "a925401b-1e8c-4401-941a-c7a48f67f5f5"}}, {"cell_type": "markdown", "source": "<a id=\"setup\"></a>\n# Step 1: Set up prerequisites\n\nBefore you use the sample code in this notebook, you must perform the following setup tasks:\n\n### a. Create a platform API key\n\nFollow these instructions:\n\n1. Click your profile icon.\n1. click **Profile and settings**.\n1. Click **API key > Generate new key**.\n1. Click **Generate**.\n1. Click **Copy**.\n1. Close the dialog box.\n\n### b. Paste the credentials, and run the cell\n\n1. Change the following cell format to be **Code**.\n1. Paste the `platform_apikey`, `url`, and `username` in the appropriate fields.\n1. If necessary, change the version in the `credentials` field.\n1. Run the cell.", "metadata": {"id": "f1852ba3-1820-4ba3-8d09-a08eb1cbf62d"}}, {"cell_type": "code", "source": "# For IBM watsonx.ai on-premises\n\nplatform_apikey = \"<insert-platform-api-key-here\"\n\n# The platform hostname must begin with https://\nurl = \"<insert-hostname-here>\"\n\nusername = \"<insert-username-here>\"\n\ncredentials = {\n    \"username\": username,\n    \"apikey\": platform_apikey,\n    \"instance_id\" : \"openshift\",\n    \"url\": url,\n    \"version\": \"5.0\"\n}", "metadata": {"id": "4f464cec-80d6-4caf-ad09-414cc79bd1a7"}, "outputs": [], "execution_count": 1}, {"cell_type": "markdown", "source": "<a id=\"knowledgebase\"></a>\n# Step 2: Create a knowledge base\n\nIn this notebook, the knowledge base is a collection of two articles.  \n\n(These articles were written as samples for watsonx.ai, they are not real articles published anywhere else.  The authors and publication dates are fictional.)", "metadata": {"id": "87ca962a-16a5-4dfd-bc61-13117bf94396"}}, {"cell_type": "code", "source": "article_01 = \\\n\"Tomatoes are one of the most popular plants for vegetable gardens.  Tip for success: If you select \" \\\n\"varieties that are resistant to disease and pests, growing tomatoes can be quite easy.  For \"        \\\n\"experienced gardeners looking for a challenge, there are endless heirloom and specialty varieties \"  \\\n\"to cultivate.  Tomato plants come in a range of sizes.  There are varieties that stay very small, \"  \\\n\"less than 12 inches, and grow well in a pot or hanging basket on a balcony or patio.  Some grow \"    \\\n\"into bushes that are a few feet high and wide, and can be grown is larger containers.  Other \"       \\\n\"varieties grow into huge bushes that are several feet wide and high in a planter or garden bed.  \"   \\\n\"Still other varieties grow as long vines, six feet or more, and love to climb trellises.  Tomato \"   \\\n\"plants do best in full sun.  You need to water tomatoes deeply and often.  Using mulch prevents \"    \\\n\"soil-borne disease from splashing up onto the fruit when you water.  Pruning suckers and even \"      \\\n\"pinching the tips will encourage the plant to put all its energy into producing fruit.\"", "metadata": {"id": "2fcd2611-9822-41a5-bc8e-eb793e200f4a"}, "outputs": [], "execution_count": 2}, {"cell_type": "code", "source": "article_02 = \\\n\"Cucumbers are fun to grow for beginning gardeners and advanced gardeners alike.  There are two \"     \\\n\"types of cucumbers: slicing and pickling.  Pickling cucumbers are smaller than slicing cucumbers.  \" \\\n\"Cucumber plants come in two types: vining cucumbers, which are more common, and bush cucumbers.  \"   \\\n\"Vining cucumbers, which can grow to more than 5 feet tall, grow fast, yield lots of fruit, and you \" \\\n\"can train them up a trellis.  Growing cucumbers up a trellis or fence can maximize garden space, \"   \\\n\"keep fruit clean, and make it easier to harvest the fruit.  Tropical plants, cucumbers are very \"    \\\n\"sensitive to frost or cold weather. Cucumbers prefer full sun for 6 to 8 hours per day.  Cucumbers \" \\\n\"need constant watering.  Cucumbers can grow quickly and ripen in just 6 weeks.  Harvest cucumbers \"  \\\n\"every day or two because the more you harvest, the more the plant will produce.  If any cucumber \"   \\\n\"is left on the vine to fully mature, the plant will stop producing more cucumbers.  You can extend \" \\\n\"the harvest season by planting cucumbers in batches, 2 weeks apart.\"", "metadata": {"id": "d8ce775a-d156-4908-b601-28a04780a680"}, "outputs": [], "execution_count": 3}, {"cell_type": "code", "source": "knowledge_base = [ \n    { \n        \"title\"     : \"Growing tomatoes\", \n        \"Author\"    : \"A. Rossi\",\n        \"Published\" : \"2010\",\n        \"txt\"       : article_01 \n    }, \n    {\n        \"title\"     : \"Cucumbers for beginners\",\n        \"Author\"    : \"B. Melnyk\",\n        \"Published\" : \"2018\",\n        \"txt\"       : article_02 \n    }\n]", "metadata": {"id": "f087a775-5227-4319-ac22-22eb0bd382f9"}, "outputs": [], "execution_count": 4}, {"cell_type": "markdown", "source": "<a id=\"search\"></a>\n# Step 3: Build a simple search component\n\nMany articles that discuss retrieval-augmented generation assume the retrieval component uses a vector database.  \n\nHowever, to perform the general retrieval-augmented generation pattern, any search-and-retrieve method that can reliably return relevant content from the knowledge base will do.\n\nIn this notebook, the search component is a trivial search function that returns the index of one or the other of the two articles in the knowledge base, based on a simple regular expression match.", "metadata": {"id": "0f783fb2-b815-40d6-b9e3-0afa2c746560"}}, {"cell_type": "code", "source": "import re\n\ndef search( query_in, knowledge_base_in ):\n    if re.match( r\".*tomato.*\", query_in, re.IGNORECASE ):\n        return 0\n    elif re.match( r\".*cucumber.*\", query_in, re.IGNORECASE ):\n        return 1\n    return -1", "metadata": {"id": "a0a158bc-6e36-44dd-ac86-3499b40618cb"}, "outputs": [], "execution_count": 5}, {"cell_type": "code", "source": "index = search( \"How tall do tomatoes grow?\", knowledge_base )\n\nif index >= 0:\n    print( \"Index: \" + str( index ) + \"\\nArticle: \\\"\" + knowledge_base[index][\"title\"] + \"\\\"\" )\nelse:\n    print( \"No matching content was found\" )", "metadata": {"id": "e3374ea7-ed68-46b3-9da2-e1fc0a20bd4c"}, "outputs": [{"name": "stdout", "text": "Index: 0\nArticle: \"Growing tomatoes\"\n", "output_type": "stream"}], "execution_count": 6}, {"cell_type": "markdown", "source": "<a id=\"prompt\"></a>\n# Step 4: Craft prompt text\n\nIn this notebook, the task to be performed is a question-answering task.\n\nThere is no one, best prompt for any given task.  However, models that have been instruction-tuned, such as `bigscience/mt0-xxl-13b`, `google/flan-t5-xxl-11b`, or `google/flan-ul2-20b`, can generally perform this task with the sample prompt below.  Conservative decoding methods tend towards succinct answers.\n\nIn the prompt below, notice two string placeholders (marked with `%s`) that will be replaced at generation time:\n- The first placeholder will be replaced with the text of the relevant article from the knowledge base\n- The second placeholder will be replaced with the question to be answered", "metadata": {"id": "75daf53e-1472-42dc-915f-35e91899747e"}}, {"cell_type": "code", "source": "prompt_template = \"\"\"\nArticle:\n###\n%s\n###\n\nAnswer the following question using only information from the article. \nAnswer in a complete sentence, with proper capitalization and punctuation. \nIf there is no good answer in the article, say \"I don't know\".\n\nQuestion: %s\nAnswer: \n\"\"\"\n\ndef augment( template_in, context_in, query_in ):\n    return template_in % ( context_in,  query_in )\n", "metadata": {"id": "06d295cc-9201-42ad-a6c3-7be92a3ebc05"}, "outputs": [], "execution_count": 7}, {"cell_type": "code", "source": "query = \"How tall do cucumber plants grow?\"\n\narticle_txt = knowledge_base[1][\"txt\"]\n\naugmented_prompt = augment( prompt_template, article_txt, query )\n\nprint( augmented_prompt )", "metadata": {"id": "1dc38529-0d38-4aed-9752-a5be41081faa"}, "outputs": [{"name": "stdout", "text": "\nArticle:\n###\nCucumbers are fun to grow for beginning gardeners and advanced gardeners alike.  There are two types of cucumbers: slicing and pickling.  Pickling cucumbers are smaller than slicing cucumbers.  Cucumber plants come in two types: vining cucumbers, which are more common, and bush cucumbers.  Vining cucumbers, which can grow to more than 5 feet tall, grow fast, yield lots of fruit, and you can train them up a trellis.  Growing cucumbers up a trellis or fence can maximize garden space, keep fruit clean, and make it easier to harvest the fruit.  Tropical plants, cucumbers are very sensitive to frost or cold weather. Cucumbers prefer full sun for 6 to 8 hours per day.  Cucumbers need constant watering.  Cucumbers can grow quickly and ripen in just 6 weeks.  Harvest cucumbers every day or two because the more you harvest, the more the plant will produce.  If any cucumber is left on the vine to fully mature, the plant will stop producing more cucumbers.  You can extend the harvest season by planting cucumbers in batches, 2 weeks apart.\n###\n\nAnswer the following question using only information from the article. \nAnswer in a complete sentence, with proper capitalization and punctuation. \nIf there is no good answer in the article, say \"I don't know\".\n\nQuestion: How tall do cucumber plants grow?\nAnswer: \n\n", "output_type": "stream"}], "execution_count": 8}, {"cell_type": "markdown", "source": "<a id=\"generate\"></a>\n# Step 5: Generate output using the foundation models Python library\n\nYou can prompt foundation models in watsonx.ai programmatically using the Python library.\n\nSee:\n- <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-python-lib.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">Introduction to the foundation models Python library</a>\n- <a href=\"https://ibm.github.io/watson-machine-learning-sdk/foundation_models.html\" target=\"_blank\" rel=\"noopener no referrer\">Foundation models Python library reference</a>\n\n**Important:** If your environment does not have the **google/flan-t5-xxl** foundation model installed, then replace the `model_id` field with an installed foundation model.", "metadata": {"id": "056021f3-1ac3-44a5-ab8b-7c40303f6d69"}}, {"cell_type": "code", "source": "import os\nfrom ibm_watson_machine_learning.foundation_models import Model\n\nmodel_id = \"google/flan-t5-xxl\"\n\ngen_parms = { \n    \"DECODING_METHOD\" : \"greedy\", \n    \"MIN_NEW_TOKENS\" : 1, \n    \"MAX_NEW_TOKENS\" : 50 \n}\n\nproject_id = os.environ[\"PROJECT_ID\"]\n\nmodel = Model( model_id, credentials, gen_parms, project_id )", "metadata": {"id": "b865595f-327c-4375-acdc-55ec324f2aef"}, "outputs": [{"name": "stderr", "text": "Model 'google/flan-t5-xxl' is not supported for this environment. Supported models: []\n", "output_type": "stream"}, {"traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mWMLClientError\u001b[0m                            Traceback (most recent call last)", "Cell \u001b[0;32mIn[11], line 14\u001b[0m\n\u001b[1;32m      6\u001b[0m gen_parms \u001b[38;5;241m=\u001b[39m { \n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDECODING_METHOD\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreedy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMIN_NEW_TOKENS\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAX_NEW_TOKENS\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;241m50\u001b[39m \n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     12\u001b[0m project_id \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROJECT_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m model \u001b[38;5;241m=\u001b[39m Model( model_id, credentials, gen_parms, project_id )\n", "File \u001b[0;32m/opt/conda/envs/Python-RT24.1-Premium/lib/python3.11/site-packages/ibm_watson_machine_learning/foundation_models/model.py:82\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, model_id, credentials, params, project_id, space_id, verify)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     76\u001b[0m              model_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     77\u001b[0m              credentials: \u001b[38;5;28mdict\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m              space_id: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     81\u001b[0m              verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m     ModelInference\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     83\u001b[0m                             model_id\u001b[38;5;241m=\u001b[39mmodel_id,\n\u001b[1;32m     84\u001b[0m                             credentials\u001b[38;5;241m=\u001b[39mcredentials,\n\u001b[1;32m     85\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m     86\u001b[0m                             project_id\u001b[38;5;241m=\u001b[39mproject_id,\n\u001b[1;32m     87\u001b[0m                             space_id\u001b[38;5;241m=\u001b[39mspace_id,\n\u001b[1;32m     88\u001b[0m                             verify\u001b[38;5;241m=\u001b[39mverify\n\u001b[1;32m     89\u001b[0m                             )\n", "File \u001b[0;32m/opt/conda/envs/Python-RT24.1-Premium/lib/python3.11/site-packages/ibm_watson_machine_learning/foundation_models/inference/model_inference.py:148\u001b[0m, in \u001b[0;36mModelInference.__init__\u001b[0;34m(self, model_id, deployment_id, params, credentials, project_id, space_id, verify, api_client)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(error_msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOperation is unsupported for this release.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id:\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference \u001b[38;5;241m=\u001b[39m FMModelInference(model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id,\n\u001b[1;32m    149\u001b[0m                                        params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams,\n\u001b[1;32m    150\u001b[0m                                        api_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference \u001b[38;5;241m=\u001b[39m DeploymentModelInference(deployment_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment_id,\n\u001b[1;32m    153\u001b[0m                                                params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams,\n\u001b[1;32m    154\u001b[0m                                                api_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client)\n", "File \u001b[0;32m/opt/conda/envs/Python-RT24.1-Premium/lib/python3.11/site-packages/ibm_watson_machine_learning/foundation_models/inference/fm_model_inference.py:44\u001b[0m, in \u001b[0;36mFMModelInference.__init__\u001b[0;34m(self, model_id, params, api_client)\u001b[0m\n\u001b[1;32m     42\u001b[0m supported_models \u001b[38;5;241m=\u001b[39m [model_spec[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m model_spec \u001b[38;5;129;01min\u001b[39;00m get_model_specs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mwml_credentials\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresources\u001b[39m\u001b[38;5;124m'\u001b[39m, [])]\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m supported_models:\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(error_msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported for this environment. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m                                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported models: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_models\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# check if model is in constricted mode\u001b[39;00m\n\u001b[1;32m     48\u001b[0m _check_model_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mwml_credentials\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id)\n", "\u001b[0;31mWMLClientError\u001b[0m: Model 'google/flan-t5-xxl' is not supported for this environment. Supported models: []"], "ename": "WMLClientError", "evalue": "Model 'google/flan-t5-xxl' is not supported for this environment. Supported models: []", "output_type": "error"}], "execution_count": 11}, {"cell_type": "code", "source": "import json\n\ndef generate( model_in, augmented_prompt_in ):\n    \n    generated_response = model_in.generate( augmented_prompt_in )\n\n    if ( \"results\" in generated_response ) \\\n       and ( len( generated_response[\"results\"] ) > 0 ) \\\n       and ( \"generated_text\" in generated_response[\"results\"][0] ):\n        return generated_response[\"results\"][0][\"generated_text\"]\n    else:\n        print( \"The model failed to generate an answer\" )\n        print( \"\\nDebug info:\\n\" + json.dumps( generated_response, indent=3 ) )\n        return \"\"", "metadata": {"id": "a5a69476-81e2-4cb5-9649-c57713c48f85"}, "outputs": [], "execution_count": 10}, {"cell_type": "code", "source": "output = generate( model, augmented_prompt )\nprint( output )", "metadata": {"id": "54f812b3-0569-48de-b623-73a95f65f0c5"}, "outputs": [{"output_type": "stream", "text": "more than 5 feet tall\n", "name": "stdout"}], "execution_count": 11}, {"cell_type": "markdown", "source": "<a id=\"rag\"></a>\n# Step 6: Pull everything together to perform retrieval-augmented generation", "metadata": {"id": "a53b88fb-0300-409f-bba7-10d06b44d130"}}, {"cell_type": "code", "source": "def searchAndAnswer( knowledge_base_in, model ):\n    \n    question = input( \"Type your question:\\n\")\n    if not re.match( r\"\\S+\", question ):\n        print( \"No question\")\n        return\n        \n    # Retrieve the relevant content\n    top_matching_index = search( question, knowledge_base_in )\n    if top_matching_index < 0:\n        print( \"No good answer was found in the knowledge base\" )\n        return;\n    asset = knowledge_base_in[top_matching_index]\n    asset_txt = asset[\"txt\"]\n    \n    # Augment a prompt with context\n    augmented_prompt = augment( prompt_template, asset_txt, question )\n    \n    # Generate output\n    output = generate( model, augmented_prompt )\n    if not re.match( r\"\\S+\", output ):\n        print( \"The model failed to generate an answer\")\n    print( \"\\nAnswer:\\n\" + output )\n    print( \"\\nSource: \\\"\" + asset[\"title\"] + \"\\\", \" + asset[\"Author\"] + \" (\" + asset[\"Published\"] + \")\"  )", "metadata": {"id": "517af9ed-07a2-4d5e-bdb0-73fa41190ad5"}, "outputs": [], "execution_count": 12}, {"cell_type": "markdown", "source": "Test the solution by running the following cell multiple times.  \n\n\\*You will be prompted to enter a question each time.", "metadata": {"id": "401ab57b-63cc-4e1c-9abb-db3784368fdc"}}, {"cell_type": "code", "source": "searchAndAnswer( knowledge_base, model )", "metadata": {"id": "aba92a00-12b3-42c5-8203-0306dd60c6a5"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Type your question:\nhow do I grow tomatoes?\n\nAnswer:\nIf you select varieties that are resistant to disease and pests, growing tomatoes can be quite easy.\n\nSource: \"Growing tomatoes\", A. Rossi (2010)\n"}], "execution_count": 13}, {"cell_type": "markdown", "source": "<a id=\"summary\"></a>\n# Summary and next steps\n\nYou successfully completed this notebook!.\n \nYou learned how to apply the general retrieval-augmented generation pattern with a simple search component and a small knowledge base using watonx.ai.\n \nCheck out our <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/welcome-main.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">Documentation</a> for more samples, tutorials, documentation, and how-tos. ", "metadata": {"id": "10550c6b-7d0f-4280-b99f-79639fb49193"}}, {"cell_type": "markdown", "source": "### Authors\n\n**Sarah Packowski**, AI ContentOps - IBM Data and AI.", "metadata": {"id": "1cbc4f38-36d4-46ea-9a69-e85a84f7471d"}}, {"cell_type": "markdown", "source": "Copyright \u00a9 2023-2024 IBM. This notebook and its source code are released under the terms of the MIT License.", "metadata": {"id": "a4af45c7-09ae-4846-b739-f0fae2d1d774"}}]}
