{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Skipping Sample in Scala\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Data skipping](https://cloud.ibm.com/docs/services/AnalyticsEngine?topic=AnalyticsEngine-data-skipping&locale=en) can significantly boost the performance of SQL queries by skipping over irrelevant data objects or files based on a summary metadata associated with each object.\n",
    "\n",
    "For every column in the object, the summary metadata might include minimum and maximum values, a list or bloom filter of the appearing values, or other metadata which succinctly represents the data in that column. This metadata is used during query evaluation to skip over objects which have no relevant data.\n",
    "\n",
    "All Spark native data formats are supported, including Parquet, ORC, CSV, JSON and Avro. Data skipping is a performance optimization feature which means that using data skipping does not affect the content of the query results.\n",
    "\n",
    "To use this feature, you need to create indexes on one or more columns of the data set. After this is done, Spark SQL queries can benefit from data skipping. In general, you should index the columns which are queried most often in the WHERE clause."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents:\n",
    "* [1. Setup the environment](#cell0)\n",
    "* [2. Creating a sample dataset](#cell1)\n",
    "* [3. Setup the DataSkipping library](#cell2)\n",
    "    * [3.1 Indexing a dataset](#cell2.1)\n",
    "* [4. Using the data skipping indexes ](#cell3)\n",
    "    * [4.1 Running queries](#cell3.2)\n",
    "* [Authors](#authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell0\"></a>\n",
    "## Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.ibm.metaindex.metadata.metadatastore.parquet.{Parquet, ParquetMetadataBackend}\n",
    "import com.ibm.metaindex.{MetaIndexManager, Registration}\n",
    "import org.apache.log4j.{Level, LogManager}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(optional)** set log level to DEBUG for the metaindex package - to view the skipped objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogManager.getLogger(\"com.ibm.metaindex\").setLevel(Level.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Stocator\n",
    "For more info on how to config credentials see [here](https://github.com/CODAIT/stocator).\n",
    "\n",
    "See [here](https://cloud.ibm.com/docs/services/cloud-object-storage?topic=cloud-object-storage-endpoints) for the list of endpoints.\n",
    "If you are in Cloud, make sure you choose the private endpoint of your bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.hadoopConfiguration.set(\"fs.cos.service.endpoint\" ,\"https://s3.private.us-east.cloud-object-storage.appdomain.cloud\")\n",
    "spark.sparkContext.hadoopConfiguration.set(\"fs.cos.service.access.key\", \"\")\n",
    "spark.sparkContext.hadoopConfiguration.set(\"fs.cos.service.secret.key\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell1\"></a>\n",
    "## Creating a sample dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a sample dataset consisting of 2 rows each row in a different object to demonstrate data skipping.\n",
    "Please replace `dataset_location` with your own bucket location to save the sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark2 = org.apache.spark.sql.SparkSession@1379d40\n",
       "dataset_location = cos://cloud-object-storage-my-cos-standard-9f6.service/tmp/sampleskipping\n",
       "defined class Record\n",
       "ds = [dt: string, temp: double ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[dt: string, temp: double ... 2 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// trick to import spark implicits\n",
    "import org.apache.spark.sql.SparkSession\n",
    "val spark2: SparkSession = spark\n",
    "import spark2.implicits._\n",
    "\n",
    "val dataset_location = \"cos://<mybucket>.service/tmp/sampleskipping\" // i.e.: dataset_location = cos://guytestssouth.service/tmp/sampleskipping \n",
    "case class Record(dt: String, temp: Double, city: String, vid: String)\n",
    "\n",
    "val ds = Seq(Record(\"2017-07-07\", 20.0, \"Tel-Aviv\", \"a\"), Record(\"2017-07-08\", 30.0, \"Jerusalem\", \"b\")).toDS()\n",
    "\n",
    "// use partitionBy to make sure we have two objects\n",
    "ds.write.partitionBy(\"dt\").mode(\"overwrite\").parquet(dataset_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell2\"></a>\n",
    "## Setup the DataSkipping library\n",
    "In this example, we will set the JVM wide parameter to a base path to store all of the indexes. \n",
    "\n",
    "Metadata can be stored on the same storage system as the data however, not under the same path. For more configuration options, see [Data skipping configuration options](https://cloud.ibm.com/docs/services/AnalyticsEngine?topic=AnalyticsEngine-data-skipping-config-options&locale=en).\\\n",
    "please replace `md_base_path` with a location to save the sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "md_base_path = cos://cloud-object-storage-my-cos-standard-9f6.service/tmp/sampleskippingmetadata\n",
       "jvmParameters = {spark.ibm.metaindex.parquet.mdlocation.type=EXPLICIT_BASE_PATH_LOCATION, spark.ibm.metaindex.parquet.mdlocation=cos://cloud-object-storage-my-cos-standard-9f6.service/tmp/sampleskippingmetadata}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{spark.ibm.metaindex.parquet.mdlocation.type=EXPLICIT_BASE_PATH_LOCATION, spark.ibm.metaindex.parquet.mdlocation=cos://cloud-object-storage-my-cos-standard-9f6.service/tmp/sampleskippingmetadata}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val md_base_path = \"cos://<mybucket>.service/tmp/sampleskippingmetadata\" // i.e. md_base_path = cos://guytestssouth.service/tmp/sampleskipping \n",
    "Registration.setDefaultMetaDataStore(Parquet)\n",
    "val jvmParameters = new java.util.HashMap[String, String]()\n",
    "jvmParameters.put(\"spark.ibm.metaindex.parquet.mdlocation\", md_base_path)\n",
    "jvmParameters.put(\"spark.ibm.metaindex.parquet.mdlocation.type\", \"EXPLICIT_BASE_PATH_LOCATION\")\n",
    "MetaIndexManager.setConf(jvmParameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell2.1\"></a>\n",
    "### Indexing a dataset\n",
    "\n",
    "Skip this step if the data set is already indexed.\n",
    "\n",
    "When creating a data skipping index on a data set, first decide which columns to index, then choose an index type for each column.\\\n",
    "These choices are workload and data dependent. Typically, choose columns to which predicates are applied in many queries.\\\n",
    "Currently the following index types are supported:\\\n",
    "1. Min/max – stores the minimum and maximum values for a column. Applies to all types except complex types.\n",
    "2. Value list – stores the list of values appearing in a column. Applies to all types except complex types.\n",
    "3. Bloom Filter – stores bloom filter with false positive probability of 1%. Applies to ByteType, StringType, LongType, IntegerType, and ShortType.\n",
    "\n",
    "\n",
    "- Choose value list if the number of distinct values in an object is typically much smaller than the total number of values in that object\n",
    "- Bloom filters are recommended for columns with high cardinality.\n",
    "- (otherwise the index can get as big as that column in the data set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+\n",
      "|status |new_entries_added|old_entries_removed|\n",
      "+-------+-----------------+-------------------+\n",
      "|SUCCESS|2                |0                  |\n",
      "+-------+-----------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "reader = org.apache.spark.sql.DataFrameReader@215de63b\n",
       "im = com.ibm.metaindex.MetaIndexManager@2e2147d5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "com.ibm.metaindex.MetaIndexManager@2e2147d5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val reader = spark.read.format(\"parquet\")\n",
    "val im = new MetaIndexManager(spark, dataset_location, ParquetMetadataBackend)\n",
    "\n",
    "// remove existing index first\n",
    "if (im.isIndexed()) {\n",
    "  im.removeIndex()\n",
    "}\n",
    "\n",
    "// indexing\n",
    "im.indexBuilder()\n",
    "  .addMinMaxIndex(\"temp\")\n",
    "  .addValueListIndex(\"city\")\n",
    "  .addBloomFilterIndex(\"vid\")\n",
    "  .build(reader)\n",
    "  .show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that each of the index types has a corresponding method in the indexBuilder class of the form:\n",
    "\n",
    "`add[IndexType]Index(<index_params>)`\n",
    "\n",
    "For example:\n",
    "\n",
    "`addMinMaxIndex(col: String)`\n",
    "\n",
    "`addValueListIndex(col: String)`\n",
    "\n",
    "`addBloomFilterIndex(col: String)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(optional)** to refresh an indexed dataset use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+\n",
      "|status |new_entries_added|old_entries_removed|\n",
      "+-------+-----------------+-------------------+\n",
      "|SUCCESS|0                |0                  |\n",
      "+-------+-----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "im.refreshIndex(reader).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View index status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Data Skipping Index Stats|cloud-object-storage-my-cos-standard-9f6/tmp/sampleskipping                                                                                       |\n",
      "+-------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Status                   |Up to date                                                                                                                                        |\n",
      "|Total objects indexed    |2                                                                                                                                                 |\n",
      "|# Metadata properties    |                                                                                                                                                  |\n",
      "|Metadata location        |cos://cloud-object-storage-my-cos-standard-9f6.service/tmp/sampleskippingmetadata/f27f950c965e8c9f6544d358f57a58daaef569172e0f0c9e8457c307589b3585|\n",
      "|# Index information      |                                                                                                                                                  |\n",
      "|# Index type             |Columns                                                                                                                                           |\n",
      "|minmax                   |temp                                                                                                                                              |\n",
      "|bloomfilter              |vid                                                                                                                                               |\n",
      "|valuelist                |city                                                                                                                                              |\n",
      "+-------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "im.getIndexStats(reader).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell3\"></a>\n",
    "## Using the data skipping indexes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Injecting the data skipping rule and enabling data skipping\n",
    "the rule injection should be done only once per Spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "// inject the data skipping rule\n",
    "MetaIndexManager.injectDataSkippingRule(spark)\n",
    "\n",
    "// enable data skipping\n",
    "MetaIndexManager.enableFiltering(spark)\n",
    "\n",
    "// you can disable the data skipping any time by running:\n",
    "// MetaIndexManager.disableFiltering(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell3.2\"></a>\n",
    "### Running queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [temp: double, city: string ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[temp: double, city: string ... 2 more fields]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = reader.load(dataset_location)\n",
    "df.createOrReplaceTempView(\"metergen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example query which uses the min/max index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       1|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from metergen where temp < 30\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the data skipping statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------------+------------+-----------+----------+\n",
      "|status |isSkippable|skipped_Bytes|skipped_Objs|total_Bytes|total_Objs|\n",
      "+-------+-----------+-------------+------------+-----------+----------+\n",
      "|SUCCESS|true       |863          |1           |1717       |2         |\n",
      "+-------+-----------+-------------+------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MetaIndexManager.getLatestQueryAggregatedStats(spark).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** clear the stats for the next query (otherwise, stats will acummulate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetaIndexManager.clearStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example query which uses value list index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       1|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from metergen where city IN ('Jerusalem', 'Ramat-Gan')\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the data skipping statistics as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------------+------------+-----------+----------+\n",
      "|status |isSkippable|skipped_Bytes|skipped_Objs|total_Bytes|total_Objs|\n",
      "+-------+-----------+-------------+------------+-----------+----------+\n",
      "|SUCCESS|true       |854          |1           |1717       |2         |\n",
      "+-------+-----------+-------------+------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MetaIndexManager.getLatestQueryAggregatedStats(spark).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** clear the stats for the next query (otherwise, stats will acummulate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetaIndexManager.clearStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example query which uses bloom filter index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from metergen where vid = 'abc'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the data skipping statistics as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------------+------------+-----------+----------+\n",
      "|status |isSkippable|skipped_Bytes|skipped_Objs|total_Bytes|total_Objs|\n",
      "+-------+-----------+-------------+------------+-----------+----------+\n",
      "|SUCCESS|true       |1717         |2           |1717       |2         |\n",
      "+-------+-----------+-------------+------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MetaIndexManager.getLatestQueryAggregatedStats(spark).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** clear the stats for the next query (otherwise, stats will acummulate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetaIndexManager.clearStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"authors\"></a> \n",
    "### Authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Guy Khazma**, Cloud Data Researcher of IBM.\n",
    "\n",
    "Copyright © 2020 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n",
    "<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n",
    "<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n",
    "<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n",
    "<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.11 with Spark",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
